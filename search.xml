<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>浅述静态成员与非静态成员</title>
      <link href="/2022/08/05/%E9%9D%99%E6%80%81%E6%88%90%E5%91%98%E4%B8%8D%E8%83%BD%E8%AE%BF%E9%97%AE%E9%9D%9E%E9%9D%99%E6%80%81%E6%88%90%E5%91%98/"/>
      <url>/2022/08/05/%E9%9D%99%E6%80%81%E6%88%90%E5%91%98%E4%B8%8D%E8%83%BD%E8%AE%BF%E9%97%AE%E9%9D%9E%E9%9D%99%E6%80%81%E6%88%90%E5%91%98/</url>
      
        <content type="html"><![CDATA[<ul><li><p>首先<a href="https://so.csdn.net/so/search?q=static&amp;spm=1001.2101.3001.7020">static</a>的成员是在类加载的时候初始化的，JVM的CLASSLOADER的加载，首次主动使用加载，而非static的成员是在创建对象的时候，即new 操作的时候才初始化的；</p></li><li><p>先后顺序是<strong>先加载，才能初始化</strong>，那么加载的时候初始化static的成员，此时非static的成员还没有被加载必然不能使用，而非static的成员是在<a href="https://so.csdn.net/so/search?q=%E7%B1%BB%E5%8A%A0%E8%BD%BD&amp;spm=1001.2101.3001.7020">类加载</a>之后，通过new操作符创建对象的时候初始化，此时static 已经分配内存空间，所以可以访问！</p></li><li><p>简单点说：<a href="https://so.csdn.net/so/search?q=%E9%9D%99%E6%80%81%E6%88%90%E5%91%98&amp;spm=1001.2101.3001.7020">静态成员</a>属于类,不需要生成对象就存在了.而非静态需要生成对象才产生. 所以静态成员不能直接访问.</p></li><li><p><strong>下面说说静态成员的特点</strong>：</p></li></ul><ol><li>随着类的加载而加载 也就是，说静态会随着类的消失而消失，说明静态的生命周期最长</li><li>优先于对象的存在 明确一点：静态是先存在的对象是后存在的</li><li>被所有对象共享</li><li>可以直接被类名多调用</li></ol><p><strong>实例变量和类变量的区别</strong></p><ol><li>存放位置 类变量随着类的加载存在于方法区中，实例变量随着对象的对象的建立存在于堆<a href="https://so.csdn.net/so/search?q=%E5%86%85%E5%AD%98&amp;spm=1001.2101.3001.7020">内存</a>里</li><li>生命周期 类变量生命周期最长，随着“类”的加载而加载，随着类的消失而消失 实例变量随着“对象”的消失而消失</li></ol><p><strong>静态的使用注意事项</strong>：</p><ol><li>静态方法只能访问静态成员（包括成员变量和成员方法） 非静态方法可以访问静态也可以访问非静态</li><li>静态方法中不可以定义this，super关键字 因为静态优先于对象存在，所以静态方法中不可以出现this，super关键字</li><li>主函数是静态的。</li></ol><p><strong>静态的利弊</strong></p><ul><li><strong>利</strong>：对 对象的共享数据进行单独空间的存储，节省空间，没有必要没一个对象中都存储一份 可以直接被类名所调用</li><li><strong>弊</strong>：生命周期过长，访问出现局限性（只能访问静态）</li></ul>]]></content>
      
      
      <categories>
          
          <category> JavaSE </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaSE </tag>
            
            <tag> static关键字 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【UNet3+】遥感影像分割</title>
      <link href="/2022/06/20/%E3%80%90UNet3+%E3%80%91%E9%81%A5%E6%84%9F%E5%BD%B1%E5%83%8F%E5%88%86%E5%89%B2/"/>
      <url>/2022/06/20/%E3%80%90UNet3+%E3%80%91%E9%81%A5%E6%84%9F%E5%BD%B1%E5%83%8F%E5%88%86%E5%89%B2/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 项目准备</h1><h2 id="1-1-问题导入-13">1.1. 问题导入</h2><ul><li><p><strong>图像分割</strong><br>在计算机视觉领域，图像分割指的是将数字图像细分为多个图像子区域的过程，其目的是简化或改变图像的表示形式，使得图像更容易理解和分析。图像分割通常用于定位图像中的物体和边界，更精确的说，它是对图像中的每个像素加标签的一个过程，这一过程使得具有相同标签的像素具有某种共同视觉特性。</p></li><li><p><strong>实验任务</strong><br>本例简要介绍如何使用<code>UNet3+</code>模型实现遥感影像分割，我们需要将遥感影像中存在的建筑物分割、标注出来。</p></li></ul><h2 id="1-2-数据集简介-10">1.2. 数据集简介</h2><p>武汉大学2019年发布了<a href="https://study.rsgis.whu.edu.cn/pages/download/building_dataset.html">Aerial Imagery Dataset</a>，该数据集原始航拍数据来自新西兰土地信息服务网站，数据集共有8,189张具有0.3m分辨率、大小为512×512像素的遥感图像，数据集共包含18,7000座建筑物。数据集包含存放遥感图像的image文件夹和存放分割图像的label文件夹，例图如下图所示：</p><p><img src="https://img-blog.csdnimg.cn/4423d8d485d0403f912d9df7ff006a93.png#pic_center" alt=""></p><blockquote><p>这是数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/69911">Aerial Imagery Dataset - AI Studio</a></p></blockquote><hr><h1>2. UNet3+模型</h1><h2 id="2-1-背景介绍">2.1. 背景介绍</h2><p>Hinton等人（2006）提出了一种<code>Encoder-Decoder</code>结构，当时这个<code>Encoder-Decoder</code>结构提出的主要作用并不是分割，而是压缩图像和去噪声。输入是一幅图，经过下采样的编码，得到一串比原先图像更小的特征，相当于压缩，然后再经过一个解码，理想状况就是能还原到原来的图像。</p><p>后来，Jonathan等人（2015）在<a href="https://arxiv.org/abs/1411.4038">论文</a>中基于该拓扑结构提出了<code>FCN</code>（Fully Convolutional Networks）。自提出以后，<code>FCN</code>就成为了语义分割的基本框架，后续算法（如<code>UNet</code>）其实都是在这个框架中改进而来。其中的<code>UNet</code>由于其对称结构简单易懂，且模型效果优秀，于是就成为了许多网络改进的范本之一。</p><p><code>UNet</code>（2015）是医学影像分割领域应用最广泛的的网络，它使用跳跃连接（skip connection）来结合来自解码器的高级语义特征图和来自编码器的相应尺度的低级语义特征图，其性能和网络中多尺度特征的融合密切相关。为了避免纯跳跃连接在语义上融合不相似的特征，此后的<code>UNet++</code>（2018）引入嵌套结构和密集的跳跃连接对网络进行了改进。而最新的<code>UNet3+</code>（2020）通过全尺度的跳跃连接和深度监督（deep supervisions）来融合深层和浅层特征的同时对各个尺度的特征进行监督，它还可以在减少网络参数的同时提高计算效率。</p><p><img src="https://img-blog.csdnimg.cn/ac6a7f8bfb8b4976a091e6a8805c8847.png#pic_center" alt=""></p><h2 id="2-2-模型介绍-3">2.2. 模型介绍</h2><p>Huang等人（2020）在<a href="https://arxiv.org/abs/2004.08790v1">论文</a>中提出了<code>UNet3+</code>模型，Huang等人使用该模型在肝脏和脾脏数据集上进行广泛的实验，发现它的表现得到了提高并且超过了很多baselines。下面介绍一下<code>UNet3+</code>模型的三个创新点：</p><h3 id="1-全尺度跳跃连接">(1) 全尺度跳跃连接</h3><p><code>UNet3+</code>充分利用多尺度特征，引入全尺度跳跃连接（Full-scale Skip Connections），该连接结合了来自全尺度特征图的低级语义和高级语义，并且参数更少。</p><p>在许多分割实验的研究中，不同尺度的特征图展示着不同的信息：低级语义特征图捕捉丰富的空间信息，能够突出物体的边界；而高级语义特征图则体现了物体所在的位置信息。为此，<code>UNet3+</code>的每个解码器层都融合了来自编码器中的小尺度和同尺度的低级语义特征图，以及来自解码器的大尺度的高级语义特征图，这些特征图捕获了全尺度下的细粒度语义和粗粒度语义。</p><p><img src="https://img-blog.csdnimg.cn/1e0f175977754e399befe5c21533bdd9.png#pic_center" alt=""></p><p>如上图所示，为了构造特征图$X_{De}^3$，第3层解码器不仅需要接收同尺度编码器层的特征图$X_{En}^3$，还需要接收小尺度编码器层的特征图$X_{En}^1$和$X_{En}^2$（为了统一特征图的分辨率，在接收前需进行下采样操作），同时也需要接收大尺度解码器层的特征图$X_{De}^5$和$X_{De}^4$（为了统一特征图的分辨率，在接收前需进行上采样操作）。在统一特征图的分辨率之后，我们还需用64个3×3的卷积核统一特征图的数量，以减少多余信息。在完成上述操作之后，我们就能用“通道维度拼接”的方法融合特征了，融合上述5个特征后便得到了320个特征图。接着，我们用320个3×3的卷积核对其进行卷积操作，最后通过批正则化（Batch Normalize）和ReLU（Rectified Linear Unit）便得到$X_{De}^3$。</p><p>于是，特征图$X_{De}^i$的计算公式可总结为：<br><img src="https://img-blog.csdnimg.cn/a49b28f320994aed8276c3823ec10d67.png#pic_center" alt=""><br>其中，变量$i$表示沿着编码方向的编/解码层的编号，变量$N$表示编码器的总数，函数$C$代表卷积操作，函数$U$和$D$分别代表上采样和下采样操作，函数$H$代表“特征融合”机制（即1个卷积层+1个批正则化层+1个ReLU函数层），$[　]$代表“通道维度拼接”。</p><h3 id="2-全尺度深度监督">(2) 全尺度深度监督</h3><p><code>UNet3+</code>采用全尺度深度监督（Full-scale Deep Supervision），从全面的聚合特征图中学习层次表示，优化了混合损失函数以增强器官边界。</p><p>不同于<code>UNet++</code>对全分辨率特征图进行深度监督，<code>UNet3+</code>中每个解码器都有一个侧输出，它是由真实标准（ground truth）来进行监督的。为实现深度监督，每个解码器的侧输出都会被送入1个3×3卷积层、1个双线性上采样层以及1个sigmoid函数层中。</p><p>为了进一步增强器官边界，<code>UNet3+</code>提出了一种多尺度结构相似指数（Multi-Scale Structural Similarity index，MS-SSIM）损失函数来赋予模糊边界更大的权重。由于区域分布差异越大，MS-SSIM值越高，故<code>UNet3+</code>将更加关注模糊边界。假设我们从分割结果<code>P</code>和真实标准<code>G</code>中分别裁剪了两个N×N的块$p$和$g$，并且有$p =｛p_j : j = 1,…,N^2｝$和$g =｛g_j : j = 1,…,N^2｝$，那么我们可定义$p$和$g$的MS-SSIM损失函数为：<br><img src="https://img-blog.csdnimg.cn/14c9344c45ab44279ad53039cb5b7bb8.png#pic_center" alt=""><br>其中，$M$表示尺度的总数（原作者将尺度总数设为5），$μ_p, μ_g$和$σ_p, σ_g$分别表示$p$和$g$的均值和方差，$σ_{pg}$则表示$p$和$g$的协方差。$β_m, γ_m$分别表示这两部分在每个尺度中的相对重要性程度，而设置小常量$C_1 = {0.01}^2, C_2 = {0.03}^2$的目的是避免出现除以0的异常情况。</p><p><code>UNet3+</code>融合了focal损失函数、MS-SSIM损失函数和IoU损失函数，提出了一种用于三个不同层次级别（像素级、块级、图像级）分割的混合损失函数，它能捕获边界清晰的大尺度结构和精细结构。该混合损失函数的定义为：<br><img src="https://img-blog.csdnimg.cn/02b64f073c794e2080035e39fb0cd251.png#pic_center" alt=""></p><h3 id="3-分类指导模块">(3) 分类指导模块</h3><p><code>UNet3+</code>提出分类指导模块（Classification-guided Module，CGM），通过图像级分类联合训练，减少非器官图像的过度分割。</p><p>在大多数医学图像分割实验中，由于来自背景的噪声信息停留在较浅层次中，这导致非器官图像出现过度分割的现象。为解决这一问题，<code>UNet3+</code>增加了一个预测输入图像是否有器官的额外分类任务。</p><p><img src="https://img-blog.csdnimg.cn/e74da177f4204550bd3304614368e06a.png#pic_center" alt=""></p><p>如上图所示，最深层的特征图$X_{De}^5$依次通过Dropout层、1×1卷积层、最大池化层和Sigmoid函数层，以得到代表$X_{De}^5$中有/无器官概率的二维张量。然后，我们可以用argmax函数处理二维张量，以得到仅包含0和1的二分类结果。接着，我们用这些分类结果与每个侧边分割输出相乘，以得到修正后的侧边分割输出。我们可以通过优化二分类的交叉损失函数，来获得更准确的分类结果，以此指导模型避免对非器官图像过度分割。</p><hr><h1>3. 代码实现</h1><h2 id="3-0-前期准备-7">3.0. 前期准备</h2><ul><li><strong>导入模块</strong></li></ul><blockquote><p>注意：本案例仅适用于<code>Paddle 2.0+</code>版本，建议在<strong>显存不小于18GB的GPU环境</strong>下开展实验！</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageEnhance</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> LinearSegmentedColormap <span class="keyword">as</span> LSC</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> paddle.framework <span class="keyword">import</span> ParamAttr</span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> initializer <span class="keyword">as</span> I, functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer.lr <span class="keyword">import</span> CosineAnnealingDecay</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">8</span>           <span class="comment"># 每批次的样本数</span></span><br><span class="line">EPOCHS = <span class="number">10</span>              <span class="comment"># 模型训练的总轮数</span></span><br><span class="line">LOG_GAP = <span class="number">360</span>            <span class="comment"># 输出训练信息的间隔</span></span><br><span class="line"></span><br><span class="line">N_CLASSES = <span class="number">2</span>            <span class="comment"># 图像分类种类数量</span></span><br><span class="line">IMG_SIZE = (<span class="number">256</span>, <span class="number">256</span>)    <span class="comment"># 图像缩放尺寸</span></span><br><span class="line"></span><br><span class="line">INIT_LR = <span class="number">2e-4</span>           <span class="comment"># 初始学习率</span></span><br><span class="line">T_MAX = <span class="number">3000</span>             <span class="comment"># 余弦周期的一半</span></span><br><span class="line"></span><br><span class="line">SRC_PATH = <span class="string">&quot;./data/data69911/BuildData.zip&quot;</span>  <span class="comment"># 压缩包路径</span></span><br><span class="line">DST_PATH = <span class="string">&quot;./data&quot;</span>                          <span class="comment"># 解压路径</span></span><br><span class="line">DATA_PATH = &#123;                                <span class="comment"># 实验数据集路径</span></span><br><span class="line">    <span class="string">&quot;img&quot;</span>: DST_PATH + <span class="string">&quot;/image&quot;</span>,    <span class="comment"># 正常图像</span></span><br><span class="line">    <span class="string">&quot;lab&quot;</span>: DST_PATH + <span class="string">&quot;/label&quot;</span>,    <span class="comment"># 分割图像</span></span><br><span class="line">&#125;</span><br><span class="line">INFER_PATH = &#123;                               <span class="comment"># 预测数据集路径</span></span><br><span class="line">    <span class="string">&quot;img&quot;</span>: [<span class="string">&quot;./work/1.jpg&quot;</span>, <span class="string">&quot;./work/2.jpg&quot;</span>],   <span class="comment"># 正常图像</span></span><br><span class="line">    <span class="string">&quot;lab&quot;</span>: [<span class="string">&quot;./work/1.png&quot;</span>, <span class="string">&quot;./work/2.png&quot;</span>],   <span class="comment"># 分割图像</span></span><br><span class="line">&#125;</span><br><span class="line">MODEL_PATH = <span class="string">&quot;UNet3+.pdparams&quot;</span>               <span class="comment"># 模型参数保存路径</span></span><br></pre></td></tr></table></figure><h2 id="3-1-数据准备-6">3.1. 数据准备</h2><ul><li><strong>解压数据集</strong><br>由于数据集中的数据是以压缩包的形式存放的，因此我们需要先解压数据压缩包。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(DATA_PATH[<span class="string">&quot;img&quot;</span>]) <span class="keyword">or</span> <span class="keyword">not</span> os.path.isdir(DATA_PATH[<span class="string">&quot;lab&quot;</span>]):</span><br><span class="line">    z = zipfile.ZipFile(SRC_PATH, <span class="string">&quot;r&quot;</span>)   <span class="comment"># 以只读模式打开zip文件</span></span><br><span class="line">    z.extractall(path=DST_PATH)          <span class="comment"># 解压zip文件至目标路径</span></span><br><span class="line">    z.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The dataset has been unpacked successfully!&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>划分数据集</strong><br>我们需要按9:1比例划分训练集和测试集，分别生成两个包含数据路径和标签路径映射关系的列表。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train_list, test_list = [], []         <span class="comment"># 存放图像路径与标签路径的映射</span></span><br><span class="line">images = os.listdir(DATA_PATH[<span class="string">&quot;img&quot;</span>])  <span class="comment"># 统计数据集下的图像文件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">    lab = os.path.join(DATA_PATH[<span class="string">&quot;lab&quot;</span>], img.replace(<span class="string">&quot;.jpg&quot;</span>, <span class="string">&quot;.png&quot;</span>))</span><br><span class="line">    img = os.path.join(DATA_PATH[<span class="string">&quot;img&quot;</span>], img)</span><br><span class="line">    <span class="keyword">if</span> idx % <span class="number">10</span> != <span class="number">0</span>:                  <span class="comment"># 按照1:9的比例划分数据集</span></span><br><span class="line">        train_list.append((img, lab))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        test_list.append((img, lab))</span><br></pre></td></tr></table></figure><ul><li><strong>数据增强</strong><br>数据増广（Data Augmentation），即数据增强，数据增强的目的主要是减少网络的过拟合现象，通过对训练图片进行变换可以得到泛化能力更强的网络，更好地适应应用场景。<br>由于实验模型较为复杂，直接训练容易发生过拟合，故在处理实验数据集时采用数据增强的方法扩充数据集的多样性。本实验中用到的数据增强方法有：随机改变亮度，随机改变对比度，随机改变饱和度，随机改变清晰度，随机旋转图像，随机翻转图像，随机加高斯噪声等。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">random_brightness</span>(<span class="params">img, lab, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变亮度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Brightness(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img, lab</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_contrast</span>(<span class="params">img, lab, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变对比度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Contrast(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img, lab</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_color</span>(<span class="params">img, lab, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变饱和度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Color(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img, lab</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_sharpness</span>(<span class="params">img, lab, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变清晰度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Sharpness(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img, lab</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_rotate</span>(<span class="params">img, lab, low=<span class="number">0</span>, high=<span class="number">360</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机旋转图像(0~360度) &#x27;&#x27;&#x27;</span></span><br><span class="line">    angle = random.choice(<span class="built_in">range</span>(low, high))</span><br><span class="line">    img, lab = img.rotate(angle), lab.rotate(angle)</span><br><span class="line">    <span class="keyword">return</span> img, lab</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_flip</span>(<span class="params">img, lab, prob=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机翻转图像(p=0.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> random.random() &lt; prob:   <span class="comment"># 上下翻转</span></span><br><span class="line">        img = img.transpose(Image.FLIP_TOP_BOTTOM)</span><br><span class="line">        lab = lab.transpose(Image.FLIP_TOP_BOTTOM)</span><br><span class="line">    <span class="keyword">if</span> random.random() &lt; prob:   <span class="comment"># 左右翻转</span></span><br><span class="line">        img = img.transpose(Image.FLIP_LEFT_RIGHT)</span><br><span class="line">        lab = lab.transpose(Image.FLIP_LEFT_RIGHT)</span><br><span class="line">    <span class="keyword">return</span> img, lab</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_noise</span>(<span class="params">img, lab, low=<span class="number">0</span>, high=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机加高斯噪声(0~10) &#x27;&#x27;&#x27;</span></span><br><span class="line">    img = np.asarray(img)</span><br><span class="line">    sigma = np.random.uniform(low, high)</span><br><span class="line">    noise = np.random.randn(img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>], <span class="number">3</span>) * sigma</span><br><span class="line">    img = img + np.<span class="built_in">round</span>(noise).astype(<span class="string">&#x27;uint8&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将矩阵中的所有元素值限制在0~255之间：</span></span><br><span class="line">    img[img &gt; <span class="number">255</span>], img[img &lt; <span class="number">0</span>] = <span class="number">255</span>, <span class="number">0</span></span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    <span class="keyword">return</span> img, lab</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_augment</span>(<span class="params">img, lab, prob=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 叠加多种数据增强方法 &#x27;&#x27;&#x27;</span></span><br><span class="line">    opts = [random_brightness, random_contrast, random_color, random_flip,</span><br><span class="line">            random_noise, random_rotate, random_sharpness,]  <span class="comment"># 数据增强方法</span></span><br><span class="line">    <span class="keyword">for</span> func <span class="keyword">in</span> opts:</span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; prob:</span><br><span class="line">            img, lab = func(img, lab)   <span class="comment"># 处理图像和标签</span></span><br><span class="line">    <span class="keyword">return</span> img, lab</span><br></pre></td></tr></table></figure><ul><li><strong>数据预处理</strong><br>我们需要对数据集图像进行缩放和归一化处理。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 自定义的数据集类</span></span><br><span class="line"><span class="string">    * `label_list`: 图像路径和标签路径的映射列表</span></span><br><span class="line"><span class="string">    * `transform`: 图像处理函数</span></span><br><span class="line"><span class="string">    * `augment`: 数据增强函数</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, label_list, transform, augment=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MyDataset, self).__init__()</span><br><span class="line">        random.shuffle(label_list)       <span class="comment"># 打乱映射列表</span></span><br><span class="line">        self.label_list = label_list</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.augment = augment</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 根据位序获取对应数据 &#x27;&#x27;&#x27;</span></span><br><span class="line">        img_path, lab_path = self.label_list[index]</span><br><span class="line">        img, lab = self.transform(img_path, lab_path, self.augment)</span><br><span class="line">        <span class="keyword">return</span> img, lab</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 获取数据集的样本总数 &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.label_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_mapper</span>(<span class="params">img_path, lab_path, augment=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 图像处理函数 &#x27;&#x27;&#x27;</span></span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">    lab = cv2.cvtColor(cv2.imread(lab_path), cv2.COLOR_RGB2GRAY)</span><br><span class="line">    <span class="comment"># 将标签文件进行灰度二值化：</span></span><br><span class="line">    _, lab = cv2.threshold(src=lab,                     <span class="comment"># 待处理图片</span></span><br><span class="line">                           thresh=<span class="number">170</span>,                  <span class="comment"># 起始阈值</span></span><br><span class="line">                           maxval=<span class="number">255</span>,                  <span class="comment"># 最大阈值</span></span><br><span class="line">                           <span class="built_in">type</span>=cv2.THRESH_BINARY_INV)  <span class="comment"># 算法类型</span></span><br><span class="line">    lab = Image.fromarray(lab).convert(<span class="string">&quot;L&quot;</span>)       <span class="comment"># 转换为PIL.Image</span></span><br><span class="line">    <span class="comment"># 将图像缩放为IMG_SIZE大小的高质量图像：</span></span><br><span class="line">    img = img.resize(IMG_SIZE, Image.ANTIALIAS)</span><br><span class="line">    lab = lab.resize(IMG_SIZE, Image.ANTIALIAS)</span><br><span class="line">    <span class="keyword">if</span> augment <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:    <span class="comment"># 数据增强</span></span><br><span class="line">        img, lab = augment(img, lab)</span><br><span class="line">    <span class="comment"># 将图像转为numpy数组，并转换图像的格式：</span></span><br><span class="line">    img = np.array(img).astype(<span class="string">&quot;float32&quot;</span>).transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    lab = np.array(lab).astype(<span class="string">&quot;int64&quot;</span>)</span><br><span class="line">    <span class="comment"># 将图像数据归一化，并转换成Tensor格式：</span></span><br><span class="line">    img = paddle.to_tensor(img / <span class="number">255.0</span>)</span><br><span class="line">    lab = paddle.to_tensor(lab // <span class="number">255</span>)</span><br><span class="line">    <span class="keyword">return</span> img, lab</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = MyDataset(train_list, data_mapper, image_augment)  <span class="comment"># 训练集</span></span><br><span class="line">test_dataset = MyDataset(test_list, data_mapper, augment=<span class="literal">None</span>)     <span class="comment"># 测试集</span></span><br></pre></td></tr></table></figure><ul><li><strong>定义数据提供器</strong><br>我们需要分别构建用于训练和测试的数据提供器，其中训练数据提供器是乱序、按批次提供数据的。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(train_dataset,          <span class="comment"># 训练数据集</span></span><br><span class="line">                          batch_size=BATCH_SIZE,  <span class="comment"># 每批次的样本数</span></span><br><span class="line">                          num_workers=<span class="number">2</span>,          <span class="comment"># 加载数据的子进程数</span></span><br><span class="line">                          shuffle=<span class="literal">True</span>,           <span class="comment"># 打乱数据集</span></span><br><span class="line">                          drop_last=<span class="literal">False</span>)        <span class="comment"># 不丢弃不完整的样本批次</span></span><br><span class="line">test_loader = DataLoader(test_dataset,            <span class="comment"># 测试数据集</span></span><br><span class="line">                         batch_size=BATCH_SIZE,   <span class="comment"># 每批次的样本数</span></span><br><span class="line">                         num_workers=<span class="number">2</span>,           <span class="comment"># 加载数据的子进程数</span></span><br><span class="line">                         shuffle=<span class="literal">False</span>,           <span class="comment"># 不打乱数据集</span></span><br><span class="line">                         drop_last=<span class="literal">False</span>)         <span class="comment"># 不丢弃不完整的样本批次</span></span><br></pre></td></tr></table></figure><h2 id="3-2-网络配置-6">3.2. 网络配置</h2><p>本次实验使用的是<code>UNet3+</code>模型，<code>UNet</code>系列模型包含下采样（编码器，特征提取）和上采样（解码器，分辨率还原）两个阶段，因模型结构比较像U型而得名。</p><ul><li><strong>定义网络初始化函数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">init_weights</span>(<span class="params">net, init_type=<span class="string">&quot;normal&quot;</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 初始化网络的权重与偏置</span></span><br><span class="line"><span class="string">    * `net`: 需要初始化的神经网络层</span></span><br><span class="line"><span class="string">    * `init_type`: 初始化机制（normal/xavier/kaiming/truncated）</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> init_type == <span class="string">&quot;normal&quot;</span>:</span><br><span class="line">        attr = ParamAttr(initializer=I.Normal())</span><br><span class="line">    <span class="keyword">elif</span> init_type == <span class="string">&quot;xavier&quot;</span>:</span><br><span class="line">        attr = ParamAttr(initializer=I.XavierNormal())</span><br><span class="line">    <span class="keyword">elif</span> init_type == <span class="string">&quot;kaiming&quot;</span>:</span><br><span class="line">        attr = ParamAttr(initializer=I.KaimingNormal())</span><br><span class="line">    <span class="keyword">elif</span> init_type == <span class="string">&quot;truncated&quot;</span>:</span><br><span class="line">        attr = ParamAttr(initializer=I.TruncatedNormal())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        error = <span class="string">&quot;Initialization method [%s] is not implemented!&quot;</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError(error % init_type)</span><br><span class="line">    <span class="comment"># 初始化网络层net的权重系数和偏置系数：</span></span><br><span class="line">    net.param_attr, net.bias_attr = attr, deepcopy(attr)</span><br></pre></td></tr></table></figure><ul><li><strong>构建编码器</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Layer):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 用于构建编码器模块</span></span><br><span class="line"><span class="string">    * `in_size`: 输入通道数</span></span><br><span class="line"><span class="string">    * `out_size`: 输出通道数</span></span><br><span class="line"><span class="string">    * `is_batchnorm`: 是否批正则化</span></span><br><span class="line"><span class="string">    * `n`: 卷积层数量（默认为2）</span></span><br><span class="line"><span class="string">    * `ks`: 卷积核大小（默认为3）</span></span><br><span class="line"><span class="string">    * `s`: 卷积运算步长（默认为1）</span></span><br><span class="line"><span class="string">    * `p`: 卷积填充大小（默认为1）</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_size, out_size, is_batchnorm, </span></span><br><span class="line"><span class="params">                 n=<span class="number">2</span>, ks=<span class="number">3</span>, s=<span class="number">1</span>, p=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()</span><br><span class="line">        self.n = n</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, self.n+<span class="number">1</span>):    <span class="comment"># 定义多层卷积神经网络</span></span><br><span class="line">            <span class="keyword">if</span> is_batchnorm:</span><br><span class="line">                block = nn.Sequential(nn.Conv2D(in_size, out_size, ks, s, p),</span><br><span class="line">                                      nn.BatchNorm2D(out_size),</span><br><span class="line">                                      nn.ReLU())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                block = nn.Sequential(nn.Conv2D(in_size, out_size, ks, s, p),</span><br><span class="line">                                      nn.ReLU())</span><br><span class="line">            <span class="built_in">setattr</span>(self, <span class="string">&quot;block%d&quot;</span> % i, block)</span><br><span class="line">            in_size = out_size</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.children():       <span class="comment"># 初始化各层网络的系数</span></span><br><span class="line">            init_weights(m, init_type=<span class="string">&quot;kaiming&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, self.n+<span class="number">1</span>):</span><br><span class="line">            block = <span class="built_in">getattr</span>(self, <span class="string">&quot;block%d&quot;</span> % i)</span><br><span class="line">            x = block(x)                <span class="comment"># 进行前向传播运算</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><ul><li><strong>构建解码器</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Layer):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 用于构建解码器模块</span></span><br><span class="line"><span class="string">    * `cur_stage`(int): 当前解码器所在层数</span></span><br><span class="line"><span class="string">    * `cat_size`(int): 统一后的特征图通道数</span></span><br><span class="line"><span class="string">    * `up_size`(int): 特征融合后的通道总数</span></span><br><span class="line"><span class="string">    * `filters`(list): 各卷积网络的卷积核数</span></span><br><span class="line"><span class="string">    * `ks`: 卷积核大小（默认为3）</span></span><br><span class="line"><span class="string">    * `s`: 卷积运算步长（默认为1）</span></span><br><span class="line"><span class="string">    * `p`: 卷积填充大小（默认为1）</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cur_stage, cat_size, up_size,</span></span><br><span class="line"><span class="params">                 filters, ks=<span class="number">3</span>, s=<span class="number">1</span>, p=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.n = <span class="built_in">len</span>(filters)      <span class="comment"># 卷积网络模块的个数</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(filters):</span><br><span class="line">            idx += <span class="number">1</span>               <span class="comment"># 待处理输出所在层数</span></span><br><span class="line">            <span class="keyword">if</span> idx &lt; cur_stage:</span><br><span class="line">                <span class="comment"># he[idx]_PT_hd[cur_stage], Pool [ps] times</span></span><br><span class="line">                ps = <span class="number">2</span> ** (cur_stage - idx)</span><br><span class="line">                block = nn.Sequential(nn.MaxPool2D(ps, ps, ceil_mode=<span class="literal">True</span>),</span><br><span class="line">                                      nn.Conv2D(num, cat_size, ks, s, p),</span><br><span class="line">                                      nn.BatchNorm2D(cat_size),</span><br><span class="line">                                      nn.ReLU())</span><br><span class="line">            <span class="keyword">elif</span> idx == cur_stage:</span><br><span class="line">                <span class="comment"># he[idx]_Cat_hd[cur_stage], Concatenate</span></span><br><span class="line">                block = nn.Sequential(nn.Conv2D(num, cat_size, ks, s, p),</span><br><span class="line">                                      nn.BatchNorm2D(cat_size),</span><br><span class="line">                                      nn.ReLU())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># hd[idx]_UT_hd[cur_stage], Upsample [us] times</span></span><br><span class="line">                us = <span class="number">2</span> ** (idx - cur_stage)</span><br><span class="line">                num = num <span class="keyword">if</span> idx == <span class="number">5</span> <span class="keyword">else</span> up_size</span><br><span class="line">                block = nn.Sequential(nn.Upsample(scale_factor=us, mode=<span class="string">&quot;bilinear&quot;</span>),</span><br><span class="line">                                      nn.Conv2D(num, cat_size, ks, s, p),</span><br><span class="line">                                      nn.BatchNorm2D(cat_size),</span><br><span class="line">                                      nn.ReLU())</span><br><span class="line">            <span class="built_in">setattr</span>(self, <span class="string">&quot;block%d&quot;</span> % idx, block)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># fusion(he[]_PT_hd[], ..., he[]_Cat_hd[], ..., hd[]_UT_hd[])</span></span><br><span class="line">        self.fusion = nn.Sequential(nn.Conv2D(up_size, up_size, ks, s, p),</span><br><span class="line">                                    nn.BatchNorm2D(up_size),</span><br><span class="line">                                    nn.ReLU())</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.children():       <span class="comment"># 初始化各层网络的系数</span></span><br><span class="line">            init_weights(m, init_type=<span class="string">&quot;kaiming&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        outputs = []       <span class="comment"># 记录各层的输出，以便于拼接起来</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.n):</span><br><span class="line">            block = <span class="built_in">getattr</span>(self, <span class="string">&quot;block%d&quot;</span> % (i+<span class="number">1</span>))</span><br><span class="line">            outputs.append( block(inputs[i]) )</span><br><span class="line">        hd = self.fusion(paddle.concat(outputs, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> hd</span><br></pre></td></tr></table></figure><ul><li><strong>定义网络结构</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">UNet3Plus</span>(nn.Layer):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; UNet3+ with Deep Supervision and Class-guided Module</span></span><br><span class="line"><span class="string">    * `in_channels`: 输入通道数（默认为3）</span></span><br><span class="line"><span class="string">    * `n_classes`: 物体的分类种数（默认为2）</span></span><br><span class="line"><span class="string">    * `is_batchnorm`: 是否批正则化（默认为True）</span></span><br><span class="line"><span class="string">    * `deep_sup`: 是否开启深度监督机制（Deep Supervision）</span></span><br><span class="line"><span class="string">    * `set_cgm`: 是否设置分类引导模块（Class-guided Module）</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, n_classes=<span class="number">2</span>, </span></span><br><span class="line"><span class="params">                 is_batchnorm=<span class="literal">True</span>, deep_sup=<span class="literal">True</span>, set_cgm=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(UNet3Plus, self).__init__()</span><br><span class="line">        self.deep_sup = deep_sup</span><br><span class="line">        self.set_cgm = set_cgm</span><br><span class="line">        filters = [<span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>]      <span class="comment"># 各模块的卷积核大小</span></span><br><span class="line">        cat_channels = filters[<span class="number">0</span>]                <span class="comment"># 统一后的特征图通道数</span></span><br><span class="line">        cat_blocks = <span class="number">5</span>                           <span class="comment"># 编（解）码器的层数</span></span><br><span class="line">        up_channels = cat_channels * cat_blocks  <span class="comment"># 特征融合后的通道数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ====================== Encoders ======================</span></span><br><span class="line">        self.conv_e1 = Encoder(in_channels, filters[<span class="number">0</span>], is_batchnorm)</span><br><span class="line">        self.pool_e1 = nn.MaxPool2D(kernel_size=<span class="number">2</span>)</span><br><span class="line">        self.conv_e2 = Encoder(filters[<span class="number">0</span>], filters[<span class="number">1</span>], is_batchnorm)</span><br><span class="line">        self.pool_e2 = nn.MaxPool2D(kernel_size=<span class="number">2</span>)</span><br><span class="line">        self.conv_e3 = Encoder(filters[<span class="number">1</span>], filters[<span class="number">2</span>], is_batchnorm)</span><br><span class="line">        self.pool_e3 = nn.MaxPool2D(kernel_size=<span class="number">2</span>)</span><br><span class="line">        self.conv_e4 = Encoder(filters[<span class="number">2</span>], filters[<span class="number">3</span>], is_batchnorm)</span><br><span class="line">        self.pool_e4 = nn.MaxPool2D(kernel_size=<span class="number">2</span>)</span><br><span class="line">        self.conv_e5 = Encoder(filters[<span class="number">3</span>], filters[<span class="number">4</span>], is_batchnorm)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ====================== Decoders ======================</span></span><br><span class="line">        self.conv_d4 = Decoder(<span class="number">4</span>, cat_channels, up_channels, filters)</span><br><span class="line">        self.conv_d3 = Decoder(<span class="number">3</span>, cat_channels, up_channels, filters)</span><br><span class="line">        self.conv_d2 = Decoder(<span class="number">2</span>, cat_channels, up_channels, filters)</span><br><span class="line">        self.conv_d1 = Decoder(<span class="number">1</span>, cat_channels, up_channels, filters)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ======================= Output =======================</span></span><br><span class="line">        <span class="keyword">if</span> self.set_cgm:</span><br><span class="line">            <span class="comment"># -------------- Class-guided Module ---------------</span></span><br><span class="line">            self.cls = nn.Sequential(nn.Dropout(p=<span class="number">0.5</span>),</span><br><span class="line">                                     nn.Conv2D(filters[<span class="number">4</span>], <span class="number">2</span>, <span class="number">1</span>),</span><br><span class="line">                                     nn.AdaptiveMaxPool2D(<span class="number">1</span>),</span><br><span class="line">                                     nn.Sigmoid())</span><br><span class="line">        <span class="keyword">if</span> self.deep_sup:</span><br><span class="line">            <span class="comment"># -------------- Bilinear Upsampling ---------------</span></span><br><span class="line">            self.upscore5 = nn.Upsample(scale_factor=<span class="number">16</span>, mode=<span class="string">&quot;bilinear&quot;</span>)</span><br><span class="line">            self.upscore4 = nn.Upsample(scale_factor=<span class="number">8</span>, mode=<span class="string">&quot;bilinear&quot;</span>)</span><br><span class="line">            self.upscore3 = nn.Upsample(scale_factor=<span class="number">4</span>, mode=<span class="string">&quot;bilinear&quot;</span>)</span><br><span class="line">            self.upscore2 = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&quot;bilinear&quot;</span>)</span><br><span class="line">            <span class="comment"># ---------------- Deep Supervision ----------------</span></span><br><span class="line">            self.outconv5 = nn.Conv2D(filters[<span class="number">4</span>], n_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            self.outconv4 = nn.Conv2D(up_channels, n_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            self.outconv3 = nn.Conv2D(up_channels, n_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            self.outconv2 = nn.Conv2D(up_channels, n_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        self.outconv1 = nn.Conv2D(up_channels, n_classes, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># ================= Initialize Weights =================</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.sublayers():</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(m, nn.Conv2D) <span class="keyword">or</span> <span class="built_in">isinstance</span>(m, nn.BatchNorm):</span><br><span class="line">                init_weights(m, init_type=<span class="string">&#x27;kaiming&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">dot_product</span>(<span class="params">self, seg, cls</span>):</span><br><span class="line">        B, N, H, W = seg.shape</span><br><span class="line">        seg = seg.reshape((B, N, H * W))</span><br><span class="line">        clssp = paddle.ones((<span class="number">1</span>, N))</span><br><span class="line">        ecls = (cls * clssp).reshape((B, N, <span class="number">1</span>))</span><br><span class="line">        final = (seg * ecls).reshape((B, N, H, W))</span><br><span class="line">        <span class="keyword">return</span> final</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># ====================== Encoders ======================</span></span><br><span class="line">        e1 = self.conv_e1(x)                  <span class="comment"># e1: 320*320*64</span></span><br><span class="line">        e2 = self.pool_e1(self.conv_e2(e1))   <span class="comment"># e2: 160*160*128</span></span><br><span class="line">        e3 = self.pool_e2(self.conv_e3(e2))   <span class="comment"># e3: 80*80*256</span></span><br><span class="line">        e4 = self.pool_e3(self.conv_e4(e3))   <span class="comment"># e4: 40*40*512</span></span><br><span class="line">        e5 = self.pool_e4(self.conv_e5(e4))   <span class="comment"># e5: 20*20*1024</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ================ Class-guided Module =================</span></span><br><span class="line">        <span class="keyword">if</span> self.set_cgm:</span><br><span class="line">            cls_branch = self.cls(e5).squeeze(<span class="number">3</span>).squeeze(<span class="number">2</span>)</span><br><span class="line">            cls_branch_max = cls_branch.argmax(axis=<span class="number">1</span>)</span><br><span class="line">            cls_branch_max = cls_branch_max[:, np.newaxis].astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ====================== Decoders ======================</span></span><br><span class="line">        d5 = e5</span><br><span class="line">        d4 = self.conv_d4((e1, e2, e3, e4, d5))</span><br><span class="line">        d3 = self.conv_d3((e1, e2, e3, d4, d5))</span><br><span class="line">        d2 = self.conv_d2((e1, e2, d3, d4, d5))</span><br><span class="line">        d1 = self.conv_d1((e1, d2, d3, d4, d5))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># ======================= Output =======================</span></span><br><span class="line">        <span class="keyword">if</span> self.deep_sup:</span><br><span class="line">            y5 = self.upscore5( self.outconv5(d5) )  <span class="comment"># 16 =&gt; 256</span></span><br><span class="line">            y4 = self.upscore4( self.outconv4(d4) )  <span class="comment"># 32 =&gt; 256</span></span><br><span class="line">            y3 = self.upscore3( self.outconv3(d3) )  <span class="comment"># 64 =&gt; 256</span></span><br><span class="line">            y2 = self.upscore2( self.outconv2(d2) )  <span class="comment"># 128 =&gt; 256</span></span><br><span class="line">            y1 = self.outconv1(d1)                   <span class="comment"># 256</span></span><br><span class="line">            <span class="keyword">if</span> self.set_cgm:</span><br><span class="line">                y5 = self.dot_product(y5, cls_branch_max)</span><br><span class="line">                y4 = self.dot_product(y4, cls_branch_max)</span><br><span class="line">                y3 = self.dot_product(y3, cls_branch_max)</span><br><span class="line">                y2 = self.dot_product(y2, cls_branch_max)</span><br><span class="line">                y1 = self.dot_product(y1, cls_branch_max)</span><br><span class="line">            <span class="keyword">return</span> F.sigmoid(y1), F.sigmoid(y2), F.sigmoid(y3),\</span><br><span class="line">                   F.sigmoid(y4), F.sigmoid(y5)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            y1 = self.outconv1(d1)                   <span class="comment"># 320*320*n_classes</span></span><br><span class="line">            <span class="keyword">if</span> self.set_cgm:</span><br><span class="line">                y1 = self.dot_product(y1, cls_branch_max)</span><br><span class="line">            <span class="keyword">return</span> F.sigmoid(y1)</span><br></pre></td></tr></table></figure><ul><li><strong>实例化模型</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = UNet3Plus(n_classes=N_CLASSES, deep_sup=<span class="literal">False</span>, set_cgm=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># paddle.Model(model).summary((1, 3) + IMG_SIZE)  # 可视化模型结构</span></span><br></pre></td></tr></table></figure><h2 id="3-模型训练">3. 模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">model.train()                <span class="comment"># 开启训练模式</span></span><br><span class="line">scheduler = CosineAnnealingDecay(</span><br><span class="line">    learning_rate=INIT_LR,</span><br><span class="line">    T_max=T_MAX,</span><br><span class="line">)                            <span class="comment"># 定义学习率衰减器</span></span><br><span class="line">optimizer = Adam(</span><br><span class="line">    learning_rate=scheduler,</span><br><span class="line">    parameters=model.parameters()</span><br><span class="line">)                            <span class="comment"># 定义Adam优化器</span></span><br><span class="line">loss_arr = []                <span class="comment"># 记录每批训练的误差</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">        image, label = data</span><br><span class="line">        pred = model(image)                          <span class="comment"># 预测结果</span></span><br><span class="line">        loss = F.cross_entropy(pred, label, axis=<span class="number">1</span>)  <span class="comment"># 计算损失函数值</span></span><br><span class="line">        <span class="keyword">if</span> batch_id % LOG_GAP == <span class="number">0</span>:                  <span class="comment"># 定期输出训练结果</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch：%d，Batch：%3d，Loss：%.5f&quot;</span> % (ep, batch_id, loss))</span><br><span class="line">        loss_arr.append(loss.item())</span><br><span class="line">        optimizer.clear_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        scheduler.step()       <span class="comment"># 衰减一次学习率</span></span><br><span class="line">    paddle.save(model.state_dict(), MODEL_PATH)  <span class="comment"># 保存训练好的模型</span></span><br></pre></td></tr></table></figure><p>模型训练的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">Epoch：0，Batch：  0，Loss：1.39092</span><br><span class="line">Epoch：0，Batch：360，Loss：0.17174</span><br><span class="line">Epoch：0，Batch：720，Loss：0.16681</span><br><span class="line">Epoch：1，Batch：  0，Loss：0.11368</span><br><span class="line">Epoch：1，Batch：360，Loss：0.11665</span><br><span class="line">Epoch：1，Batch：720，Loss：0.06234</span><br><span class="line">Epoch：2，Batch：  0，Loss：0.12535</span><br><span class="line">Epoch：2，Batch：360，Loss：0.12542</span><br><span class="line">Epoch：2，Batch：720，Loss：0.11362</span><br><span class="line">Epoch：3，Batch：  0，Loss：0.12906</span><br><span class="line">Epoch：3，Batch：360，Loss：0.11927</span><br><span class="line">Epoch：3，Batch：720，Loss：0.11524</span><br><span class="line">Epoch：4，Batch：  0，Loss：0.07827</span><br><span class="line">Epoch：4，Batch：360，Loss：0.15802</span><br><span class="line">Epoch：4，Batch：720，Loss：0.09502</span><br><span class="line">Epoch：5，Batch：  0，Loss：0.13487</span><br><span class="line">Epoch：5，Batch：360，Loss：0.09628</span><br><span class="line">Epoch：5，Batch：720，Loss：0.10007</span><br><span class="line">Epoch：6，Batch：  0，Loss：0.07204</span><br><span class="line">Epoch：6，Batch：360，Loss：0.11167</span><br><span class="line">Epoch：6，Batch：720，Loss：0.13266</span><br><span class="line">Epoch：7，Batch：  0，Loss：0.05692</span><br><span class="line">Epoch：7，Batch：360，Loss：0.16079</span><br><span class="line">Epoch：7，Batch：720，Loss：0.10594</span><br><span class="line">Epoch：8，Batch：  0，Loss：0.05400</span><br><span class="line">Epoch：8，Batch：360，Loss：0.06496</span><br><span class="line">Epoch：8，Batch：720，Loss：0.09775</span><br><span class="line">Epoch：9，Batch：  0，Loss：0.07335</span><br><span class="line">Epoch：9，Batch：360，Loss：0.07723</span><br><span class="line">Epoch：9，Batch：720，Loss：0.06590</span><br></pre></td></tr></table></figure><ul><li><strong>可视化训练过程</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=[<span class="number">10</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练误差图像：</span></span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;Loss&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(loss_arr)), loss_arr, color=<span class="string">&quot;orangered&quot;</span>)</span><br><span class="line">ax.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/5e6031b2df5e46acb1e7d31bf04fc5be.png#pic_center" alt=""></p><h2 id="3-4-模型评估-6">3.4. 模型评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">test_costs = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):</span><br><span class="line">    image, label = data</span><br><span class="line">    pred = model(image)                          <span class="comment"># 预测结果</span></span><br><span class="line">    loss = F.cross_entropy(pred, label, axis=<span class="number">1</span>)  <span class="comment"># 计算损失函数值</span></span><br><span class="line">    test_costs.append(loss.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Eval \t Avg_Loss：%.5f&quot;</span> % (np.mean(test_costs)))</span><br></pre></td></tr></table></figure><p>模型评估的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Eval  Avg_Loss：0.07250</span><br></pre></td></tr></table></figure><h2 id="3-5-模型预测-6">3.5. 模型预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_result</span>(<span class="params">img_path, lab_path, pred</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 展示原图、标签以及预测结果 &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_subimg</span>(<span class="params">img, loc, title, cmap=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 添加子图以展示图像 &#x27;&#x27;&#x27;</span></span><br><span class="line">        plt.subplot(loc)</span><br><span class="line">        plt.title(title)</span><br><span class="line">        plt.imshow(img, cmap)</span><br><span class="line">        plt.xticks([])         <span class="comment"># 去除X刻度</span></span><br><span class="line">        plt.yticks([])         <span class="comment"># 去除Y刻度</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">colormap</span>(<span class="params">colors=[<span class="string">&#x27;#A0C185&#x27;</span>, <span class="string">&#x27;#A6A6A6&#x27;</span>]</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 自定义ColorMap &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> LSC.from_list(<span class="string">&#x27;cmap&#x27;</span>, colors, <span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path).resize(IMG_SIZE)</span><br><span class="line">    lab = Image.<span class="built_in">open</span>(lab_path).resize(IMG_SIZE)</span><br><span class="line">    pred = pred.argmax(axis=<span class="number">1</span>).numpy().reshape(IMG_SIZE)</span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">4</span>))</span><br><span class="line">    add_subimg(img, <span class="number">131</span>, <span class="string">&quot;Image&quot;</span>)</span><br><span class="line">    add_subimg(lab, <span class="number">132</span>, <span class="string">&quot;Label&quot;</span>)</span><br><span class="line">    add_subimg(pred, <span class="number">133</span>, <span class="string">&quot;Predict&quot;</span>, colormap())</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line">    plt.close()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">model.set_state_dict(</span><br><span class="line">    paddle.load(MODEL_PATH)</span><br><span class="line">)   <span class="comment"># 载入预训练模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(INFER_PATH[<span class="string">&quot;img&quot;</span>])):</span><br><span class="line">    img_path, lab_path = INFER_PATH[<span class="string">&quot;img&quot;</span>][i], INFER_PATH[<span class="string">&quot;lab&quot;</span>][i]</span><br><span class="line">    img, lab = data_mapper(img_path, lab_path)  <span class="comment"># 处理预测图像</span></span><br><span class="line">    pred = model(img[np.newaxis, ...])          <span class="comment"># 开始模型预测</span></span><br><span class="line">    show_result(img_path, lab_path, pred)</span><br></pre></td></tr></table></figure><p>第1组图像分割结果如下：<br><img src="https://img-blog.csdnimg.cn/aca437d7e7e94dedb3e5edff6951580a.png#pic_center" alt=""></p><p>第2组图像分割结果如下：<br><img src="https://img-blog.csdnimg.cn/46249f15fce84743b92f939e7dfe7719.png#pic_center" alt=""></p><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/4132877?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分割 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【ResNet】肺炎CT影像识别</title>
      <link href="/2022/05/31/%E3%80%90ResNet%E3%80%91%E8%82%BA%E7%82%8ECT%E5%BD%B1%E5%83%8F%E8%AF%86%E5%88%AB/"/>
      <url>/2022/05/31/%E3%80%90ResNet%E3%80%91%E8%82%BA%E7%82%8ECT%E5%BD%B1%E5%83%8F%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 项目准备</h1><h2 id="1-1-问题导入-8">1.1. 问题导入</h2><p>图像分类是计算机视觉的重要领域，它的目标是将图像分类到预定义的标签。许多研究者提出了很多不同种类的神经网络，并极大地提升了分类算法的性能。本次实践将训练ResNet模型实现对胸部CT影像的分类，以区分新冠肺炎患者、病毒性肺炎患者以及正常人。</p><h2 id="1-2-数据集简介-6">1.2. 数据集简介</h2><p>新冠肺炎在全球爆发以后，来自卡塔尔、孟加拉国、巴基斯坦以及马来西亚的研究人员与医生合作，建立了一个包含正常人、病毒性肺炎患者、新冠肺炎患者的胸部CT影像的数据集。数据集包含1200个新冠阳性患者的影像、1341个正常人的影像和1345个病毒性肺炎患者的影像。</p><blockquote><p>这是数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/84451">COVID-19胸部X射线图像数据库 - AI Studio</a></p></blockquote><hr><h1>2. ResNet模型</h1><h2 id="2-1-模型背景">2.1. 模型背景</h2><p><code>VGG</code>和<code>GoogleNet</code>等模型证明，更深的网络可以抽象出表达能力更强的特征，进而获得更强的分类能力。从理论上说，在没有残差的深度网络中，随着网络层数的加深，网络的表征能力越来越强，但是在实际操作过程中，这么做会导致模型效果越来越差。一方面，在深度网络中进行反向传播时，过长的反向传播链会使得近输入端的梯度接近0，从而导致梯度消失，使得网络的训练失效；另一方面，深度网络存在退化问题（Degradation of Deep Network），这使得网络表征能学习到的最优点与实际的最优点往往是越来越远的。</p><p>为了解决上述问题，何恺明和孙剑等人（2015）在<a href="https://arxiv.org/pdf/1512.03385.pdf">论文</a>中提出了<code>ResNet</code>，这是一种深度残差卷积网络。下图展示了<code>VGG-19</code>与<code>ResNet-34</code>的网络结构，我们可以看到，与<code>VGG</code>模型的各层网络直接简单串接不同的是，<code>ResNet</code>模型会将残差块的输入也作为下一个残差块的输入，这样可以使得深层网络能够融合浅层网络所提取的特征，提升深度卷积网络的整体性能。</p><p><img src="https://img-blog.csdnimg.cn/550dd600119b4b7698702ae0c8a17e91.png#pic_center" alt=""></p><h2 id="2-2-模型介绍">2.2. 模型介绍</h2><p><code>ResNet</code>由一系列残差块（如下图Figure 2所示）构成，它会把每个残差块的输入$x$与卷积层输出$F(x)$进行相加，在使用ReLU函数处理相加结果之后，我们便得到了该残差块的输出。需要注意的是，如果$x$与$F(x)$的通道数不一样，那么在进行相加之前，我们还需对$x$进行相应的卷积运算，以实现下采样（downsample），统一$x$与$F(x)$的通道数。</p><p><img src="https://img-blog.csdnimg.cn/436a17d364f047018d79cae813db4d1b.png#pic_center" alt=""></p><p>如上图Figure 5所示，<code>ResNet</code>模型一共有两种不同的残差块。其中，50层以下的<code>ResNet</code>采用的是左侧的Basic残差块，而50层及以上的<code>ResNet</code>采用的是右侧的Bottleneck残差块。</p><p>下表展示了<code>ResNet</code>模型的网络结构，其中，$\left[\begin{array}{c} 3×3, a \ 3×3, a \end{array}\right]$代表Basic残差块，$\left[\begin{array}{c} 1×1, b \ 3×3, b \ 1×1, 4b \end{array}\right]$代表Bottleneck残差块。<code>ResNet</code>一共有五个版本，即<code>ResNet-18</code>、<code>ResNet-34</code>、<code>ResNet-50</code>、<code>ResNet-101</code>和<code>ResNet-152</code>，其中最常用的版本是<code>ResNet-50</code>和<code>ResNet-101</code>。</p><p><img src="https://img-blog.csdnimg.cn/2e8d62cf9f33423cadedf616ec23ea88.png#pic_center" alt=""></p><hr><h1>3. 实验步骤</h1><p><img src="https://img-blog.csdnimg.cn/20210208110405937.png#pic_center" alt=""></p><h2 id="3-0-前期准备-4">3.0. 前期准备</h2><ul><li><strong>导入模块</strong></li></ul><blockquote><p>注意：本案例仅适用于<code>PaddlePaddle 2.0+</code>版本</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageEnhance</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> metric <span class="keyword">as</span> M</span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer.lr <span class="keyword">import</span> NaturalExpDecay</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">64</span>      <span class="comment"># 每批次的样本数</span></span><br><span class="line">EPOCHS = <span class="number">8</span>           <span class="comment"># 训练轮数</span></span><br><span class="line">LOG_GAP = <span class="number">30</span>         <span class="comment"># 输出训练信息的间隔</span></span><br><span class="line"></span><br><span class="line">CLASS_DIM = <span class="number">3</span>        <span class="comment"># 图像种类</span></span><br><span class="line">LAB_DICT = &#123;         <span class="comment"># 记录标签和数字的关系</span></span><br><span class="line">    <span class="string">&quot;0&quot;</span>: <span class="string">&quot;正常肺部&quot;</span>,</span><br><span class="line">    <span class="string">&quot;1&quot;</span>: <span class="string">&quot;病毒性肺炎&quot;</span>,</span><br><span class="line">    <span class="string">&quot;2&quot;</span>: <span class="string">&quot;新冠肺炎&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">INIT_LR = <span class="number">3e-4</span>       <span class="comment"># 初始学习率</span></span><br><span class="line">LR_DECAY = <span class="number">0.6</span>       <span class="comment"># 学习率衰减率</span></span><br><span class="line"></span><br><span class="line">SRC_PATH = <span class="string">&quot;./data/input_data.zip&quot;</span>  <span class="comment"># 压缩包路径</span></span><br><span class="line">DST_PATH = <span class="string">&quot;./data&quot;</span>                 <span class="comment"># 解压路径</span></span><br><span class="line">DATA_PATH = &#123;                       <span class="comment"># 实验数据集路径</span></span><br><span class="line">    <span class="string">&quot;0&quot;</span>: DST_PATH + <span class="string">&quot;/input_data/NORMAL&quot;</span>,</span><br><span class="line">    <span class="string">&quot;1&quot;</span>: DST_PATH + <span class="string">&quot;/input_data/Viral_Pneumonia&quot;</span>,</span><br><span class="line">    <span class="string">&quot;2&quot;</span>: DST_PATH + <span class="string">&quot;/input_data/COVID&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line">MODEL_PATH = <span class="string">&quot;ResNet.pdparams&quot;</span>      <span class="comment"># 模型参数保存路径</span></span><br></pre></td></tr></table></figure><h2 id="3-1-数据准备-3">3.1. 数据准备</h2><ul><li><strong>解压数据集</strong><br>由于数据集中的数据是以压缩包的形式存放的，因此我们需要先解压数据压缩包。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(DATA_PATH[<span class="string">&quot;0&quot;</span>]) <span class="keyword">or</span>\</span><br><span class="line">   <span class="keyword">not</span> os.path.isdir(DATA_PATH[<span class="string">&quot;1&quot;</span>]) <span class="keyword">or</span>\</span><br><span class="line">   <span class="keyword">not</span> os.path.isdir(DATA_PATH[<span class="string">&quot;2&quot;</span>]):</span><br><span class="line">    z = zipfile.ZipFile(SRC_PATH, <span class="string">&quot;r&quot;</span>)   <span class="comment"># 打开压缩文件，创建zip对象</span></span><br><span class="line">    z.extractall(path=DST_PATH)          <span class="comment"># 解压zip文件至目标路径</span></span><br><span class="line">    z.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;数据集解压完成！&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>划分数据集</strong><br>我们需要按1:9比例划分测试集和训练集，分别生成两个包含数据路径和标签映射关系的列表。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_data_list</span>(<span class="params">lab_no, path</span>):   <span class="comment"># 划分path路径下的数据集</span></span><br><span class="line">    tmp_train_list, tmp_test_list = [], []   <span class="comment"># 临时存放数据集位置及标签</span></span><br><span class="line">    <span class="keyword">for</span> idx, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(os.listdir(path)[:-<span class="number">1</span>]):</span><br><span class="line">        img_path = os.path.join(path, img)</span><br><span class="line">        <span class="keyword">if</span> idx % <span class="number">10</span> == <span class="number">0</span>:     <span class="comment"># 按照1:9的比例划分数据集</span></span><br><span class="line">            tmp_test_list.append([img_path, lab_no])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            tmp_train_list.append([img_path, lab_no])</span><br><span class="line">    <span class="keyword">return</span> tmp_train_list, tmp_test_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_infer_data</span>(<span class="params">data_path</span>):  <span class="comment"># 将数据集中最后一个数据作为预测集</span></span><br><span class="line">    tmp_infer_list = []</span><br><span class="line">    <span class="keyword">for</span> lab_no <span class="keyword">in</span> data_path.keys():</span><br><span class="line">        path, lab_no = data_path[lab_no], <span class="built_in">int</span>(lab_no)</span><br><span class="line">        img_path = os.path.join(path, os.listdir(path)[-<span class="number">1</span>])</span><br><span class="line">        tmp_infer_list.append([img_path, lab_no])</span><br><span class="line">    <span class="keyword">return</span> tmp_infer_list</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_lt0, test_lt0 = get_data_list(<span class="number">0</span>, DATA_PATH[<span class="string">&quot;0&quot;</span>])  <span class="comment"># 划分“正常肺部”</span></span><br><span class="line">train_lt1, test_lt1 = get_data_list(<span class="number">1</span>, DATA_PATH[<span class="string">&quot;1&quot;</span>])  <span class="comment"># 划分“病毒性肺炎”</span></span><br><span class="line">train_lt2, test_lt2 = get_data_list(<span class="number">2</span>, DATA_PATH[<span class="string">&quot;2&quot;</span>])  <span class="comment"># 划分“新冠肺炎”</span></span><br><span class="line">train_list = train_lt0 + train_lt1 + train_lt2</span><br><span class="line">test_list = test_lt0 + test_lt1 + test_lt2</span><br><span class="line">infer_list = get_infer_data(DATA_PATH)</span><br></pre></td></tr></table></figure><ul><li><strong>数据增强</strong><br>数据増广（Data Augmentation），即数据增强，数据增强的目的主要是减少网络的过拟合现象，通过对训练图片进行变换可以得到泛化能力更强的网络，更好地适应应用场景。<br>由于实验模型较为复杂，直接训练容易发生过拟合，故在处理实验数据集时采用数据增强的方法扩充数据集的多样性。本实验中用到的数据增强方法有：随机改变亮度，随机改变对比度，随机改变饱和度，随机改变清晰度，随机旋转图像，随机加高斯噪声等。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">random_brightness</span>(<span class="params">img, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变亮度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Brightness(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_contrast</span>(<span class="params">img, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变对比度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Contrast(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_color</span>(<span class="params">img, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变饱和度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Color(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_sharpness</span>(<span class="params">img, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变清晰度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Sharpness(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_rotate</span>(<span class="params">img, low=-<span class="number">30</span>, high=<span class="number">30</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机旋转图像(-30~30) &#x27;&#x27;&#x27;</span></span><br><span class="line">    angle = random.choice(<span class="built_in">range</span>(low, high))</span><br><span class="line">    img = img.rotate(angle)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_noise</span>(<span class="params">img, low=<span class="number">0</span>, high=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机加高斯噪声(0~10) &#x27;&#x27;&#x27;</span></span><br><span class="line">    img = np.asarray(img)</span><br><span class="line">    sigma = np.random.uniform(low, high)</span><br><span class="line">    noise = np.random.randn(img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>], <span class="number">3</span>) * sigma</span><br><span class="line">    img = img + np.<span class="built_in">round</span>(noise).astype(<span class="string">&#x27;uint8&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将矩阵中的所有元素值限制在0~255之间：</span></span><br><span class="line">    img[img &gt; <span class="number">255</span>], img[img &lt; <span class="number">0</span>] = <span class="number">255</span>, <span class="number">0</span></span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_augment</span>(<span class="params">img, prob=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 叠加多种数据增强方法 &#x27;&#x27;&#x27;</span></span><br><span class="line">    opts = [random_brightness, random_contrast, random_color,</span><br><span class="line">            random_rotate, random_noise, random_sharpness,]  <span class="comment"># 数据增强方法</span></span><br><span class="line">    random.shuffle(opts)</span><br><span class="line">    <span class="keyword">for</span> opt <span class="keyword">in</span> opts:</span><br><span class="line">        img = opt(img) <span class="keyword">if</span> random.random() &lt; prob <span class="keyword">else</span> img     <span class="comment"># 处理图像</span></span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><ul><li><strong>数据预处理</strong><br>我们需要对数据集图像进行缩放和归一化处理。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 自定义的数据集类 &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, label_list, transform, augment=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `label_list`: 标签与文件路径的映射列表</span></span><br><span class="line"><span class="string">        * `transform`: 数据处理函数</span></span><br><span class="line"><span class="string">        * `augment`: 数据增强函数（默认为空）</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(MyDataset, self).__init__()</span><br><span class="line">        random.shuffle(label_list)      <span class="comment"># 打乱映射列表</span></span><br><span class="line">        self.label_list = label_list</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.augment = augment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 根据位序获取对应数据 &#x27;&#x27;&#x27;</span></span><br><span class="line">        img_path, label = self.label_list[index]</span><br><span class="line">        img = self.transform(img_path, self.augment)</span><br><span class="line">        <span class="keyword">return</span> img, <span class="built_in">int</span>(label)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 获取数据集样本总数 &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.label_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_mapper</span>(<span class="params">img_path, augment=<span class="literal">None</span>, show=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 图像处理函数 &#x27;&#x27;&#x27;</span></span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&quot;RGB&quot;</span>)   <span class="comment"># 以RGB模式打开图片</span></span><br><span class="line">    <span class="comment"># 将其缩放为224*224的高质量图像：</span></span><br><span class="line">    img = img.resize((<span class="number">224</span>, <span class="number">224</span>), Image.ANTIALIAS)</span><br><span class="line">    <span class="keyword">if</span> show:                  <span class="comment"># 展示图像</span></span><br><span class="line">        display(img)</span><br><span class="line">    <span class="keyword">if</span> augment <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:   <span class="comment"># 数据增强</span></span><br><span class="line">        img = augment(img)</span><br><span class="line">    <span class="comment"># 把图像变成一个numpy数组以匹配数据馈送格式：</span></span><br><span class="line">    img = np.array(img).astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">    <span class="comment"># 将图像矩阵由“rgb,rgb,rbg...”转置为“rr...,gg...,bb...”：</span></span><br><span class="line">    img = img.transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 将图像数据归一化，并转换成Tensor格式：</span></span><br><span class="line">    img = paddle.to_tensor(img / <span class="number">255.0</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = MyDataset(train_list, data_mapper, image_augment) <span class="comment"># 训练集</span></span><br><span class="line">test_dataset = MyDataset(test_list, data_mapper, augment=<span class="literal">None</span>)    <span class="comment"># 测试集</span></span><br></pre></td></tr></table></figure><ul><li><strong>定义数据提供器</strong><br>我们需要分别构建用于训练和测试的数据提供器，其中训练数据提供器是乱序、按批次提供数据的。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(train_dataset,            <span class="comment"># 训练数据集</span></span><br><span class="line">                          batch_size=BATCH_SIZE,    <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                          num_workers=<span class="number">0</span>,            <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                          shuffle=<span class="literal">True</span>,             <span class="comment"># 打乱训练数据集</span></span><br><span class="line">                          drop_last=<span class="literal">False</span>)          <span class="comment"># 不丢弃不完整的样本</span></span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(test_dataset,              <span class="comment"># 测试数据集</span></span><br><span class="line">                         batch_size=BATCH_SIZE,     <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                         num_workers=<span class="number">0</span>,             <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                         shuffle=<span class="literal">False</span>,             <span class="comment"># 不打乱测试数据集</span></span><br><span class="line">                         drop_last=<span class="literal">False</span>)           <span class="comment"># 不丢弃不完整的样本</span></span><br></pre></td></tr></table></figure><h2 id="3-2-网络配置-3">3.2. 网络配置</h2><ul><li><strong>注意事项</strong><br>在<code>ResNet</code>的残差块中，作者采用了大量的小尺寸卷积核。其中，对于包含1×1卷积核的卷积层而言，它只能改变特征图的通道数；对于包含3×3卷积核的卷积层而言，当且仅当运算步长（stride）不为1时，它才可以改变特征图的尺寸。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBN2d</span>(nn.Layer):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Conv2d with BatchNorm2d and ReLU &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span>, out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, act=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_channels`: 输入通道数</span></span><br><span class="line"><span class="string">        * `out_channels`: 输出通道数</span></span><br><span class="line"><span class="string">        * `kernel_size`: 卷积核大小</span></span><br><span class="line"><span class="string">        * `stride`: 卷积运算的步长</span></span><br><span class="line"><span class="string">        * `padding`: 卷积填充的大小</span></span><br><span class="line"><span class="string">        * `act`: 激活函数（None / relu）</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(ConvBN2d, self).__init__()</span><br><span class="line">        self.act = act</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Conv2D(in_channels, out_channels, kernel_size, stride, padding),</span><br><span class="line">            nn.BatchNorm2D(out_channels)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">if</span> self.act == <span class="string">&quot;relu&quot;</span>:</span><br><span class="line">            <span class="keyword">return</span> F.relu(self.net(x))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.net(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Layer):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; A Residual Block for ResNet-18/34 &#x27;&#x27;&#x27;</span></span><br><span class="line">    expansion = <span class="number">1</span>       <span class="comment"># 最后一层输出的通道扩展倍数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_size, out_size, stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_size`: 第一层卷积层的输入通道数</span></span><br><span class="line"><span class="string">        * `out_size`: 第一层卷积层的输出通道数</span></span><br><span class="line"><span class="string">        * `stride`: 第一层卷积层的运算步长</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        end_size = self.expansion * out_size    <span class="comment"># 最后一层卷积层的输出通道数</span></span><br><span class="line"></span><br><span class="line">        self.layers = nn.Sequential(</span><br><span class="line">            ConvBN2d(in_size, out_size, <span class="number">3</span>, stride, <span class="number">1</span>, <span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            ConvBN2d(out_size, end_size, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="literal">None</span>),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> in_size != end_size:     <span class="comment"># 进行拼接之前需要统一通道数和尺寸</span></span><br><span class="line">            self.shortcut = ConvBN2d(in_size, end_size, <span class="number">1</span>, stride, act=<span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.shortcut = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        fx = self.layers(x)</span><br><span class="line">        <span class="keyword">if</span> self.shortcut <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.shortcut(x)</span><br><span class="line">        y = F.relu(fx + x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Bottleneck</span>(nn.Layer):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; A Residual Block for ResNet-50/101/152 &#x27;&#x27;&#x27;</span></span><br><span class="line">    expansion = <span class="number">4</span>       <span class="comment"># 最后一层输出的通道扩展倍数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_size, out_size, stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_size`: 第一层卷积层的输入通道数</span></span><br><span class="line"><span class="string">        * `out_size`: 第一层卷积层的输出通道数</span></span><br><span class="line"><span class="string">        * `stride`: 第一层卷积层的运算步长</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(Bottleneck, self).__init__()</span><br><span class="line">        end_size = self.expansion * out_size    <span class="comment"># 最后一层卷积层的输出通道数</span></span><br><span class="line"></span><br><span class="line">        self.layers = nn.Sequential(</span><br><span class="line">            ConvBN2d(in_size, out_size, <span class="number">1</span>, act=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            ConvBN2d(out_size, out_size, <span class="number">3</span>, stride, <span class="number">1</span>, <span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            ConvBN2d(out_size, end_size, <span class="number">1</span>, act=<span class="literal">None</span>),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> in_size != end_size:     <span class="comment"># 进行拼接之前需要统一通道数和尺寸</span></span><br><span class="line">            self.shortcut = ConvBN2d(in_size, end_size, <span class="number">1</span>, stride, act=<span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.shortcut = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        fx = self.layers(x)</span><br><span class="line">        <span class="keyword">if</span> self.shortcut <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.shortcut(x)</span><br><span class="line">        y = F.relu(fx + x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, n_classes=<span class="number">2</span>, mtype=<span class="number">50</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_channels`: 输入的通道数</span></span><br><span class="line"><span class="string">        * `n_classes`: 输出分类数量</span></span><br><span class="line"><span class="string">        * `mtype`: ResNet类型（18/34/50/101/152）</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> mtype == <span class="number">18</span>:         <span class="comment"># ResNet-18</span></span><br><span class="line">            self.Block, n_blocks = BasicBlock, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="number">34</span>:       <span class="comment"># ResNet-34</span></span><br><span class="line">            self.Block, n_blocks = BasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>]</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="number">50</span>:       <span class="comment"># ResNet-50</span></span><br><span class="line">            self.Block, n_blocks = Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>]</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="number">101</span>:      <span class="comment"># ResNet-101</span></span><br><span class="line">            self.Block, n_blocks = Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>]</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="number">152</span>:      <span class="comment"># ResNet-152</span></span><br><span class="line">            self.Block, n_blocks = Bottleneck, [<span class="number">3</span>, <span class="number">8</span>, <span class="number">36</span>, <span class="number">3</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">&quot;`mtype` must in [18, 34, 50, 101, 152]&quot;</span>)</span><br><span class="line">        self.e = self.Block.expansion       <span class="comment"># 残差结构输出通道数的扩展倍数</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = ConvBN2d(in_channels, <span class="number">64</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        self.pool1 = nn.MaxPool2D(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">        self.conv2 = self._res_blocks(n_blocks[<span class="number">0</span>], <span class="number">64</span>, <span class="number">64</span>, <span class="number">1</span>)   <span class="comment"># 本层不改变尺寸</span></span><br><span class="line">        self.conv3 = self._res_blocks(n_blocks[<span class="number">1</span>], <span class="number">64</span> * self.e, <span class="number">128</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv4 = self._res_blocks(n_blocks[<span class="number">2</span>], <span class="number">128</span> * self.e, <span class="number">256</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv5 = self._res_blocks(n_blocks[<span class="number">3</span>], <span class="number">256</span> * self.e, <span class="number">512</span>, <span class="number">2</span>)</span><br><span class="line">        self.pool2 = nn.AdaptiveAvgPool2D((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.linear = nn.Sequential(nn.Flatten(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                                    nn.Linear(<span class="number">512</span> * self.e, n_classes))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)   <span class="comment"># 64*112*112</span></span><br><span class="line">        x = self.pool1(x)   <span class="comment"># 64*56*56</span></span><br><span class="line">        x = self.conv2(x)   <span class="comment"># 64*56*56  or 256*56*56</span></span><br><span class="line">        x = self.conv3(x)   <span class="comment"># 128*28*28 or 512*28*28</span></span><br><span class="line">        x = self.conv4(x)   <span class="comment"># 256*14*14 or 1024*14*14</span></span><br><span class="line">        x = self.conv5(x)   <span class="comment"># 512*7*7   or 2048*7*7</span></span><br><span class="line">        x = self.pool2(x)   <span class="comment"># 512*1*1   or 2048*1*1</span></span><br><span class="line">        y = self.linear(x)  <span class="comment"># n_classes</span></span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_res_blocks</span>(<span class="params">self, n_block, in_size, out_size, stride</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `n_block`: 残差块的数量</span></span><br><span class="line"><span class="string">        * `in_size`: 第一层卷积层的输入通道数</span></span><br><span class="line"><span class="string">        * `out_size`: 第一层卷积层的输出通道数</span></span><br><span class="line"><span class="string">        * `stride`: 第一个残差块卷积运算的步长</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        blocks = [self.Block(in_size, out_size, stride),]</span><br><span class="line">        in_size = out_size * self.e     <span class="comment"># 后续残差块的输入通道数</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, n_block):</span><br><span class="line">            blocks.append( self.Block(in_size, out_size, stride=<span class="number">1</span>) )</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*blocks)</span><br></pre></td></tr></table></figure><ul><li><strong>实例化模型</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = ResNet(in_channels=<span class="number">3</span>, n_classes=CLASS_DIM, mtype=<span class="number">50</span>)    <span class="comment"># ResNet-50</span></span><br></pre></td></tr></table></figure><h2 id="3-3-模型训练-3">3.3. 模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">model.train()                <span class="comment"># 开启训练模式</span></span><br><span class="line">scheduler = NaturalExpDecay(</span><br><span class="line">    learning_rate=INIT_LR,</span><br><span class="line">    gamma=LR_DECAY</span><br><span class="line">)                            <span class="comment"># 定义学习率衰减器</span></span><br><span class="line">optimizer = Adam(</span><br><span class="line">    learning_rate=scheduler,</span><br><span class="line">    parameters=model.parameters()</span><br><span class="line">)                            <span class="comment"># 定义Adam优化器</span></span><br><span class="line">loss_arr, acc_arr = [], []   <span class="comment"># 用于可视化</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">        x_data, y_data = data</span><br><span class="line">        y_data = y_data[:, np.newaxis]          <span class="comment"># 增加一维维度</span></span><br><span class="line">        y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">        acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">        loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">        <span class="keyword">if</span> batch_id % LOG_GAP == <span class="number">0</span>:        <span class="comment"># 定期输出训练结果</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch：%d，Batch：%2d，Loss：%.5f，Acc：%.5f&quot;</span>\</span><br><span class="line">                % (ep, batch_id, loss, acc))</span><br><span class="line">        acc_arr.append(acc.item())</span><br><span class="line">        loss_arr.append(loss.item())</span><br><span class="line">        optimizer.clear_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    scheduler.step()       <span class="comment"># 每轮衰减一次学习率</span></span><br><span class="line"></span><br><span class="line">paddle.save(model.state_dict(), MODEL_PATH)  <span class="comment"># 保存训练好的模型</span></span><br></pre></td></tr></table></figure><p>模型训练结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Epoch：0，Batch： 0，Loss：1.28814，Acc：0.40625</span><br><span class="line">Epoch：0，Batch：30，Loss：0.50501，Acc：0.81250</span><br><span class="line">Epoch：1，Batch： 0，Loss：0.47952，Acc：0.79688</span><br><span class="line">Epoch：1，Batch：30，Loss：0.28905，Acc：0.87500</span><br><span class="line">Epoch：2，Batch： 0，Loss：0.53422，Acc：0.78125</span><br><span class="line">Epoch：2，Batch：30，Loss：0.23787，Acc：0.89062</span><br><span class="line">Epoch：3，Batch： 0，Loss：0.21741，Acc：0.92188</span><br><span class="line">Epoch：3，Batch：30，Loss：0.21679，Acc：0.93750</span><br><span class="line">Epoch：4，Batch： 0，Loss：0.22656，Acc：0.90625</span><br><span class="line">Epoch：4，Batch：30，Loss：0.29999，Acc：0.89062</span><br><span class="line">Epoch：5，Batch： 0，Loss：0.14857，Acc：0.95312</span><br><span class="line">Epoch：5，Batch：30，Loss：0.07505，Acc：1.00000</span><br><span class="line">Epoch：6，Batch： 0，Loss：0.18624，Acc：0.89062</span><br><span class="line">Epoch：6，Batch：30，Loss：0.10810，Acc：0.96875</span><br><span class="line">Epoch：7，Batch： 0，Loss：0.16827，Acc：0.93750</span><br><span class="line">Epoch：7，Batch：30，Loss：0.11762，Acc：0.95312</span><br></pre></td></tr></table></figure><ul><li><strong>可视化训练过程</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=[<span class="number">10</span>, <span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练误差图像：</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">211</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&quot;Loss&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax1.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(loss_arr)), loss_arr, color=<span class="string">&quot;orangered&quot;</span>)</span><br><span class="line">ax1.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练准确率图像：</span></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">212</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&quot;Training Steps&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&quot;Accuracy&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax2.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(acc_arr)), acc_arr, color=<span class="string">&quot;dodgerblue&quot;</span>)</span><br><span class="line">ax2.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/e06e71899e844101b4df153fe51bf342.png#pic_center" alt=""></p><h2 id="3-4-模型评估-3">3.4. 模型评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">test_costs, test_accs = [], []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):</span><br><span class="line">    x_data, y_data = data</span><br><span class="line">    y_data = y_data[:, np.newaxis]          <span class="comment"># 增加一维维度</span></span><br><span class="line">    y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">    acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">    loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">    test_accs.append(acc.item())</span><br><span class="line">    test_costs.append(loss.item())</span><br><span class="line">test_loss = np.mean(test_costs)    <span class="comment"># 每轮测试的平均误差</span></span><br><span class="line">test_acc = np.mean(test_accs)      <span class="comment"># 每轮测试的平均准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Eval \t Loss：%.5f，Acc：%.5f&quot;</span> % (test_loss, test_acc))</span><br></pre></td></tr></table></figure><p>模型评估结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Eval  Loss：0.12486，Acc：0.95536</span><br></pre></td></tr></table></figure><h2 id="3-5-模型预测-3">3.5. 模型预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">model.set_state_dict(</span><br><span class="line">    paddle.load(MODEL_PATH)</span><br><span class="line">)   <span class="comment"># 载入预训练模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, (img_path, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(infer_list):</span><br><span class="line">    truth_lab = LAB_DICT[<span class="built_in">str</span>(label)]               <span class="comment"># 获取真实标签</span></span><br><span class="line">    image = data_mapper(img_path, show=<span class="literal">True</span>)       <span class="comment"># 获取预测图片</span></span><br><span class="line">    result = model(image[np.newaxis, :, :, :])     <span class="comment"># 开始模型预测</span></span><br><span class="line">    infer_lab = LAB_DICT[<span class="built_in">str</span>(np.argmax(result))]   <span class="comment"># 获取预测结果</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;图%d的真实标签：%s，预测结果：%s&quot;</span> % (idx+<span class="number">1</span>, truth_lab, infer_lab))</span><br></pre></td></tr></table></figure><p>模型预测结果如下：</p><p><img src="https://img-blog.csdnimg.cn/92a3c7ea92e14c49ae79ef1efcc0379b.png" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图1的真实标签：正常肺部，预测结果：正常肺部</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/6c8422a3447142fb98889080f60e89e7.png" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图2的真实标签：病毒性肺炎，预测结果：病毒性肺炎</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/884d276cf82a4e2a98a7720f8c5708a4.png" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图3的真实标签：新冠肺炎，预测结果：新冠肺炎</span><br></pre></td></tr></table></figure><h1>4. 内容总结</h1><p><img src="https://img-blog.csdnimg.cn/fc3bff49cc1e43eaa55778577f9acbdd.png#pic_center" alt=""></p><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/4258916?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【DQN】基于价值的强化学习方法</title>
      <link href="/2021/07/24/%E3%80%90DQN%E3%80%91%E5%9F%BA%E4%BA%8E%E4%BB%B7%E5%80%BC%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
      <url>/2021/07/24/%E3%80%90DQN%E3%80%91%E5%9F%BA%E4%BA%8E%E4%BB%B7%E5%80%BC%E7%9A%84%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1>1. 项目准备</h1><h2 id="1-1-问题导入-3">1.1. 问题导入</h2><p>深度强化学习是将深度学习和强化学习相结合起来的方法，本文将使用深度强化学习DQN算法训练智能体解决小车上山（Mountain Car）问题。</p><h2 id="1-2-环境介绍">1.2. 环境介绍</h2><p>本次实验所用的训练环境为<code>gym</code>库的“小车上山”（<code>MountainCar-v0</code>）环境。</p><p><img src="https://img-blog.csdnimg.cn/bce72fde0cac424892829c773db99b36.gif#pic_center" alt=""></p><p>如上图所示，为了解决该问题，智能体需要通过前后移动车，让它到达旗帜的位置。</p><hr><h1>2. DQN算法</h1><ul><li><p><strong>相关背景</strong><br>（1）传统Q表格难以装下过多的Q值，并且Q值越多查表速度越慢；<br>（2）使用神经网络建立值函数可以模拟Q表格，只需要存储少量参数；<br>（3）神经网络能够自动提取输入的特征，具有较好的泛化能力。</p></li><li><p><strong>算法介绍</strong><br>深度Q学习网络（Deep Q-Learning Network，DQN）算法是DeepMind团队于2014年提出的强化学习算法，它成功开启了深度强化学习的新时代。DQN算法本质上是对Q-learning算法的改进，并且它们的更新方式一致。</p></li><li><p><strong>算法特点</strong><br>（1）经验回放 (Experience replay)<br>（2）固定Q目标 (Fixed Q target)<br>（3）用Q网络代替Q表格</p></li></ul><p><img src="https://img-blog.csdnimg.cn/ace46920533346a886bf1d80efd324c1.png#pic_center" alt=""></p><hr><h1>3. 实验步骤</h1><h2 id="3-0-前期准备-2">3.0. 前期准备</h2><ul><li><strong>导入模块</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gym</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddle.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> paddle.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> deepcopy</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> parl <span class="keyword">import</span> Model <span class="keyword">as</span> parlModel</span><br><span class="line"><span class="keyword">from</span> parl <span class="keyword">import</span> Algorithm <span class="keyword">as</span> parlAlg</span><br><span class="line"><span class="keyword">from</span> parl <span class="keyword">import</span> Agent <span class="keyword">as</span> parlAgent</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#================== 强化学习通用参数 ====================#</span></span><br><span class="line">GAMMA = <span class="number">0.999</span>                 <span class="comment"># reward的衰减因子</span></span><br><span class="line">MODEL_LR = <span class="number">1e-4</span>               <span class="comment"># 神经网络学习率</span></span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">128</span>              <span class="comment"># 每批经验的数量</span></span><br><span class="line">MEMORY_SIZE = <span class="number">400_000</span>         <span class="comment"># 经验池的最大容量</span></span><br><span class="line">MEMORY_WARMUP = <span class="number">50</span>            <span class="comment"># 经验池初始经验的数量</span></span><br><span class="line"></span><br><span class="line">EVAL_EPOCHS = <span class="number">5</span>               <span class="comment"># 每次评估的轮数</span></span><br><span class="line">EVAL_GAP = <span class="number">200</span>                <span class="comment"># 评估间隔</span></span><br><span class="line">TRAIN_EPOCHS = <span class="number">3000</span>           <span class="comment"># 训练总轮数</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#================== DQN算法特有参数 ====================#</span></span><br><span class="line">UPDATE_FREQ = <span class="number">10_000</span>          <span class="comment"># 更新目标网络的间隔</span></span><br><span class="line">EPSILON = &#123;                   <span class="comment"># ε-greedy相关参数</span></span><br><span class="line">    <span class="string">&quot;value&quot;</span>: <span class="number">0.50</span>,            <span class="comment"># 初始值</span></span><br><span class="line">    <span class="string">&quot;decay&quot;</span>: <span class="number">1e-6</span>,            <span class="comment"># 衰减率</span></span><br><span class="line">    <span class="string">&quot;final&quot;</span>: <span class="number">0.01</span>,            <span class="comment"># 最终值</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">MODEL_PATH = <span class="string">&quot;DQN.pdparams&quot;</span>   <span class="comment"># 模型保存路径</span></span><br></pre></td></tr></table></figure><h2 id="3-1-搭建网络模型（Model）">3.1. 搭建网络模型（Model）</h2><p><code>Model</code>用来定义前向(<code>forward</code>)网络，用户可以自由的定制自己的网络结构。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(<span class="title class_ inherited__">parlModel</span>):     <span class="comment"># 构建神经网络模型</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, obs_dim, act_dim, hidden_size=<span class="number">128</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        <span class="comment"># nn.Linear(输入维度，输出维度)</span></span><br><span class="line">        self.fc1 = nn.Linear(obs_dim, hidden_size)</span><br><span class="line">        self.fc2 = nn.Linear(hidden_size, hidden_size)</span><br><span class="line">        self.fc3 = nn.Linear(hidden_size, act_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, obs</span>):   <span class="comment"># 前向传播函数</span></span><br><span class="line">        s = F.relu(self.fc1(obs))</span><br><span class="line">        s = F.relu(self.fc2(s))</span><br><span class="line">        Q = self.fc3(s)</span><br><span class="line">        <span class="keyword">return</span> Q</span><br></pre></td></tr></table></figure><h2 id="3-2-搭建算法（Algorithm）">3.2. 搭建算法（Algorithm）</h2><p><code>Algorithm</code>定义了具体的算法来更新前向网络(<code>Model</code>)，也就是通过定义损失函数来更新<code>Model</code>，和算法相关的计算都放在<code>algorithm</code>中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DQN</span>(<span class="title class_ inherited__">parlAlg</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model, gamma, model_lr</span>):</span><br><span class="line">        self.model = model</span><br><span class="line">        self.tgt_model = deepcopy(model)    <span class="comment"># 复制生成目标模型</span></span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.optimizer = Adam(</span><br><span class="line">            learning_rate=model_lr,</span><br><span class="line">            parameters=self.model.parameters()</span><br><span class="line">        )   <span class="comment"># 创建Adam优化器</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 利用神经网络根据当前状态值预测Q值：</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, obs</span>):</span><br><span class="line">        <span class="keyword">return</span> self.model(obs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 利用DQN学习算法训练并更新神经网络：</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learn</span>(<span class="params">self, obs, action, reward, next_obs, done</span>):</span><br><span class="line">        pred_vals = self.model(obs)   <span class="comment"># 使用主网络获取Q的预测值</span></span><br><span class="line">        act_onehot = F.one_hot(</span><br><span class="line">            paddle.squeeze(action, axis=-<span class="number">1</span>),    <span class="comment"># 拉伸数据</span></span><br><span class="line">            num_classes=pred_vals.shape[-<span class="number">1</span>]     <span class="comment"># 动作的维度</span></span><br><span class="line">        )   <span class="comment"># 对动作进行独热编码</span></span><br><span class="line">        pred_Q = paddle.<span class="built_in">sum</span>(</span><br><span class="line">            paddle.multiply(pred_vals, act_onehot),</span><br><span class="line">            axis=<span class="number">1</span>, keepdim=<span class="literal">True</span></span><br><span class="line">        )   <span class="comment"># 逐元素相乘再相加，以获取动作对应的Q值</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从tgt_model中获取max(Q[t+1])的值，用于计算目标Q值：</span></span><br><span class="line">        <span class="keyword">with</span> paddle.no_grad():  <span class="comment"># 阻止梯度传播，以固定目标Q</span></span><br><span class="line">            max_val = self.tgt_model(next_obs).<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">            tgt_Q = reward + (<span class="number">1</span> - done) * self.gamma * max_val</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取损失值并用优化函数进行优化，同时反向传播更新参数：</span></span><br><span class="line">        loss = F.mse_loss(pred_Q, tgt_Q)</span><br><span class="line">        self.optimizer.clear_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 把主网络的参数同步到目标网络：</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sync_target</span>(<span class="params">self</span>):</span><br><span class="line">        self.model.sync_weights_to(self.tgt_model)</span><br></pre></td></tr></table></figure><h2 id="3-3-搭建智能体（Agent）">3.3. 搭建智能体（Agent）</h2><p><code>Agent</code>负责算法与环境的交互，在交互过程中把生成的数据提供给<code>Algorithm</code>来更新模型(<code>Model</code>)，数据的预处理流程也一般定义在这里。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Agent</span>(<span class="title class_ inherited__">parlAgent</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, alg, act_dim, epsilon, update_freq</span>):</span><br><span class="line">        <span class="built_in">super</span>(Agent, self).__init__(algorithm=alg)</span><br><span class="line">        self.act_dim = act_dim</span><br><span class="line">        self.epsilon = epsilon           <span class="comment"># ε-greedy参数</span></span><br><span class="line">        self.update_freq = update_freq   <span class="comment"># 网络更新频率</span></span><br><span class="line">        self.steps = <span class="number">0</span>                   <span class="comment"># 记录步数，以便更新目标网络</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample</span>(<span class="params">self, obs</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 根据当前状态探索动作 &#x27;&#x27;&#x27;</span></span><br><span class="line">        self.steps += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> np.random.rand() &lt; self.epsilon[<span class="string">&quot;value&quot;</span>]:</span><br><span class="line">            act = np.random.choice(self.act_dim)  <span class="comment"># 随机探索选动作</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            act = self.predict(obs)               <span class="comment"># 根据模型选最优动作</span></span><br><span class="line">        <span class="comment"># 随着训练次数增加，随机探索的概率逐渐减少：</span></span><br><span class="line">        self.epsilon[<span class="string">&quot;value&quot;</span>] = <span class="built_in">max</span>(self.epsilon[<span class="string">&quot;final&quot;</span>],</span><br><span class="line">                                    self.epsilon[<span class="string">&quot;value&quot;</span>] - self.epsilon[<span class="string">&quot;decay&quot;</span>])</span><br><span class="line">        <span class="keyword">return</span> act</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, obs</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 根据当前状态预测最优动作 &#x27;&#x27;&#x27;</span></span><br><span class="line">        obs = paddle.to_tensor(obs, dtype=<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">        pred_Q = self.alg.predict(obs)      <span class="comment"># 用DQN算法获取左右动作</span></span><br><span class="line">        <span class="keyword">return</span> pred_Q.argmax().numpy()[<span class="number">0</span>]   <span class="comment"># 返回Q值最大的动作</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learn</span>(<span class="params">self, obs, act, reward, next_obs, done</span>):</span><br><span class="line">        <span class="keyword">if</span> self.steps % self.update_freq == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 每隔一些steps同步一次两个模型中的参数</span></span><br><span class="line">            self.alg.sync_target()</span><br><span class="line"></span><br><span class="line">        act = np.expand_dims(act, -<span class="number">1</span>)           <span class="comment"># 添加一个数据维度</span></span><br><span class="line">        reward = np.expand_dims(reward, -<span class="number">1</span>)</span><br><span class="line">        done = np.expand_dims(done, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        loss = self.alg.learn(</span><br><span class="line">            paddle.to_tensor(obs, dtype=<span class="string">&quot;float32&quot;</span>),</span><br><span class="line">            paddle.to_tensor(act, dtype=<span class="string">&quot;int32&quot;</span>),</span><br><span class="line">            paddle.to_tensor(reward, dtype=<span class="string">&quot;float32&quot;</span>),</span><br><span class="line">            paddle.to_tensor(next_obs, dtype=<span class="string">&quot;float32&quot;</span>),</span><br><span class="line">            paddle.to_tensor(done, dtype=<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">        )   <span class="comment"># 使用DQN算法学习参数，并获取本轮学习的误差</span></span><br><span class="line">        <span class="keyword">return</span> loss.numpy()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><h2 id="3-4-搭建经验回放池">3.4. 搭建经验回放池</h2><p>经验回放池<code>ReplayMemory</code>用于存储多条经验，实现经验回放，供智能体进行学习。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ReplayMemory</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, max_size</span>):   <span class="comment"># 初始化经验池（队列）</span></span><br><span class="line">        self.buffer = collections.deque(maxlen=max_size)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):              <span class="comment"># 获取当前池内的经验数</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.buffer)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_memory</span>(<span class="params">self, env, agent, warmup</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 向经验池内加入初始数据，避免开始训练时的样本数不够</span></span><br><span class="line"><span class="string">            * `env`(gym.Env): 训练环境</span></span><br><span class="line"><span class="string">            * `agent`(Agent): 强化学习智能体</span></span><br><span class="line"><span class="string">            * `warmup`(int): 需要探索的轮数</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\033[33m Start to initialize replay memory... \033[0m&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(warmup):</span><br><span class="line">            obs, done = env.reset(), <span class="literal">False</span></span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">                act = agent.sample(obs)</span><br><span class="line">                next_obs, reward, done, _ = env.step(act)</span><br><span class="line">                self.buffer.append((obs, act, reward, next_obs, done))</span><br><span class="line">                obs = next_obs</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\033[33m Initialize replay memory successfully! \033[0m&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">append</span>(<span class="params">self, exp</span>):          <span class="comment"># 向经验池里添加新的经验</span></span><br><span class="line">        self.buffer.append(exp)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample</span>(<span class="params">self, batch_size</span>):   <span class="comment"># 从池中随机抽取经验</span></span><br><span class="line">        <span class="comment"># 随机从经验池中选取数量为batch_size的经验：</span></span><br><span class="line">        mini_batch = random.sample(self.buffer, batch_size)</span><br><span class="line">        obs_batch, act_batch, reward_batch = [], [], []</span><br><span class="line">        next_obs_batch, done_batch = [], []</span><br><span class="line">        <span class="comment"># 把经验中的s,a,r,s&#x27;,done取出来分别存入列表中：</span></span><br><span class="line">        <span class="keyword">for</span> experience <span class="keyword">in</span> mini_batch:</span><br><span class="line">            obs, act, reward, next_obs, done = experience</span><br><span class="line">            obs_batch.append(obs)</span><br><span class="line">            act_batch.append(act)</span><br><span class="line">            reward_batch.append(reward)</span><br><span class="line">            next_obs_batch.append(next_obs)</span><br><span class="line">            done_batch.append(done)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> (np.array(obs_batch).astype(<span class="string">&quot;float32&quot;</span>),</span><br><span class="line">                np.array(act_batch).astype(<span class="string">&quot;int32&quot;</span>),</span><br><span class="line">                np.array(reward_batch).astype(<span class="string">&quot;float32&quot;</span>),</span><br><span class="line">                np.array(next_obs_batch).astype(<span class="string">&quot;float32&quot;</span>),</span><br><span class="line">                np.array(done_batch).astype(<span class="string">&quot;float32&quot;</span>))</span><br></pre></td></tr></table></figure><h2 id="3-5-训练与评估">3.5. 训练与评估</h2><ul><li><strong>定义训练函数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_episode</span>(<span class="params">env, agent, rpm</span>):</span><br><span class="line">    total_reward = <span class="number">0</span>        <span class="comment"># 记录总的reward值</span></span><br><span class="line">    step, done = <span class="number">0</span>, <span class="literal">False</span>   <span class="comment"># step记录本轮step数，done记录是否结束</span></span><br><span class="line">    obs = env.reset()       <span class="comment"># 每轮训练前需要重置一下环境</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">        step += <span class="number">1</span></span><br><span class="line">        act = agent.sample(obs)  <span class="comment"># 采样动作，所有动作都有概率被选择</span></span><br><span class="line">        next_obs, reward, done, _ = env.step(act)</span><br><span class="line">        rpm.append((obs, act, reward, next_obs, done))</span><br><span class="line">        (batch_obs, batch_action, batch_reward,</span><br><span class="line">         batch_next_obs, batch_done) = rpm.sample(BATCH_SIZE)</span><br><span class="line">        agent.learn(batch_obs, batch_action, batch_reward, </span><br><span class="line">                    batch_next_obs, batch_done)     <span class="comment"># s,a,r,s&#x27;,done</span></span><br><span class="line">        total_reward += reward</span><br><span class="line">        obs = next_obs</span><br><span class="line">    <span class="keyword">return</span> total_reward</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">env, agent, render=<span class="literal">False</span></span>):</span><br><span class="line">    eval_reward = []</span><br><span class="line">    <span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(EVAL_EPOCHS):</span><br><span class="line">        obs = env.reset()</span><br><span class="line">        done, ep_reward = <span class="literal">False</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">            act = agent.predict(obs)  <span class="comment"># 预测动作，只选最优动作</span></span><br><span class="line">            obs, reward, done, _ = env.step(act)</span><br><span class="line">            ep_reward += reward</span><br><span class="line">            <span class="keyword">if</span> render:</span><br><span class="line">                env.render()</span><br><span class="line">        eval_reward.append(ep_reward)</span><br><span class="line">    <span class="keyword">return</span> np.mean(eval_reward)</span><br></pre></td></tr></table></figure><ul><li><strong>初始化并开始训练</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">env = gym.make(<span class="string">&#x27;MountainCar-v0&#x27;</span>)    <span class="comment"># 创建“小车爬山”环境</span></span><br><span class="line">obs_dim = env.observation_space.shape[<span class="number">0</span>]    <span class="comment"># 状态的维度</span></span><br><span class="line">act_dim = env.action_space.n                <span class="comment"># 动作的维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建强化学习智能体：</span></span><br><span class="line">model = Model(obs_dim, act_dim)</span><br><span class="line">alg = DQN(model, GAMMA, MODEL_LR)</span><br><span class="line">agent = Agent(alg, act_dim, EPSILON, UPDATE_FREQ)</span><br><span class="line"><span class="comment"># 构建并初始化经验回放池：</span></span><br><span class="line">rpm = ReplayMemory(MEMORY_SIZE)</span><br><span class="line">rpm.init_memory(env, agent, MEMORY_WARMUP)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> episode <span class="keyword">in</span> <span class="built_in">range</span>(TRAIN_EPOCHS + <span class="number">1</span>):</span><br><span class="line">    <span class="comment"># (1)开始模型训练：</span></span><br><span class="line">    train_reward = run_episode(env, agent, rpm)</span><br><span class="line">    <span class="comment"># (2)开始模型测试：</span></span><br><span class="line">    <span class="keyword">if</span> episode % EVAL_GAP == <span class="number">0</span>:  <span class="comment"># 每隔一段时间评估一次</span></span><br><span class="line">        test_reward = evaluate(env, agent, render=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;【Eval】Episode: %d; ε_greed: %.3f; Reward: %.1f&#x27;</span> %</span><br><span class="line">                (episode, agent.epsilon[<span class="string">&quot;value&quot;</span>], test_reward))</span><br><span class="line">        agent.save(MODEL_PATH)   <span class="comment"># 保存模型</span></span><br></pre></td></tr></table></figure><p>训练及评估的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">【Eval】Episode:    0; ε_greed: 0.490; Reward: -200.0</span><br><span class="line">【Eval】Episode:  200; ε_greed: 0.450; Reward: -123.6</span><br><span class="line">【Eval】Episode:  400; ε_greed: 0.410; Reward: -110.0</span><br><span class="line">【Eval】Episode:  600; ε_greed: 0.370; Reward: -139.4</span><br><span class="line">【Eval】Episode:  800; ε_greed: 0.330; Reward: -124.0</span><br><span class="line">【Eval】Episode: 1000; ε_greed: 0.290; Reward: -200.0</span><br><span class="line">【Eval】Episode: 1200; ε_greed: 0.250; Reward: -200.0</span><br><span class="line">【Eval】Episode: 1400; ε_greed: 0.210; Reward: -200.0</span><br><span class="line">【Eval】Episode: 1600; ε_greed: 0.171; Reward: -133.8</span><br><span class="line">【Eval】Episode: 1800; ε_greed: 0.136; Reward: -134.4</span><br><span class="line">【Eval】Episode: 2000; ε_greed: 0.103; Reward: -200.0</span><br><span class="line">【Eval】Episode: 2200; ε_greed: 0.071; Reward: -200.0</span><br><span class="line">【Eval】Episode: 2400; ε_greed: 0.041; Reward: -123.6</span><br><span class="line">【Eval】Episode: 2600; ε_greed: 0.011; Reward: -110.0</span><br><span class="line">【Eval】Episode: 2800; ε_greed: 0.010; Reward: -139.4</span><br><span class="line">【Eval】Episode: 3000; ε_greed: 0.010; Reward: -124.0</span><br></pre></td></tr></table></figure><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/2205309?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 强化学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【Sarsa＆Q-learning】表格型方法</title>
      <link href="/2021/07/17/%E3%80%90Sarsa&amp;Q-learning%E3%80%91%E8%A1%A8%E6%A0%BC%E5%9E%8B%E6%96%B9%E6%B3%95/"/>
      <url>/2021/07/17/%E3%80%90Sarsa&amp;Q-learning%E3%80%91%E8%A1%A8%E6%A0%BC%E5%9E%8B%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 项目准备</h1><h2 id="1-1-问题导入-6">1.1. 问题导入</h2><p>Sarsa算法和Q-learning算法是两种基于表格的经典强化学习方法，本文将对比探究这两种方法在解决悬崖行走（Cliff Walking）问题时的表现。</p><h2 id="1-2-环境介绍-2">1.2. 环境介绍</h2><p>本次实验所用的训练环境为<code>gym</code>库的“悬崖行走”（<code>CliffWalking-v0</code>）环境。</p><p><img src="https://img-blog.csdnimg.cn/20201114092322733.png#pic_center" alt=""></p><p>如上图所示，该问题需要智能体从起点S点出发，到达终点G，同时避免掉进悬崖（cliff）。智能体每走一步就有<code>-1</code>分的惩罚，掉进悬崖会有<code>−100</code>分的惩罚，但游戏不会结束，智能体会回到出发点，然后游戏继续，直到智能体到达重点结束游戏。</p><hr><h1>2. SARSA算法</h1><h2 id="2-1-算法简介">2.1. 算法简介</h2><ul><li><p><code>SARSA</code>全称是<code>state-action-reward-state'-action'</code>，目的是学习特定的<code>state</code>下，特定<code>action</code>的价值Q，最终建立和优化一个Q表格，以<code>state</code>为行，<code>action</code>为列，根据与环境交互得到的<code>reward</code>来更新Q表格，更新公式为：<br><img src="https://img-blog.csdnimg.cn/img_convert/2ffeab4daf2b0dea32b1e8dd987e0c97.png" alt=""></p></li><li><p>SARSA在训练中为了更好的探索环境，采用<code>ε-greedy</code>方式来训练，有一定概率随机选择动作输出。</p></li></ul><h2 id="2-2-算法伪码">2.2. 算法伪码</h2><p><img src="https://img-blog.csdnimg.cn/20201126204105242.png#pic_center" alt=""></p><h2 id="2-3-算法实现">2.3. 算法实现</h2><h3 id="1-前期准备">(1) 前期准备</h3><ul><li><strong>导入模块</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> gym</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TRAIN_EPOCHS = <span class="number">500</span>             <span class="comment"># 训练轮数</span></span><br><span class="line">LOG_GAP = <span class="number">50</span>                   <span class="comment"># 日志打印间隔</span></span><br><span class="line"></span><br><span class="line">LEARNING_RATE = <span class="number">0.1</span>            <span class="comment"># 学习率</span></span><br><span class="line">GAMMA = <span class="number">0.95</span>                   <span class="comment"># 奖励衰减因子</span></span><br><span class="line">EPSILON = <span class="number">0.1</span>                  <span class="comment"># 随机选取动作的概率</span></span><br><span class="line"></span><br><span class="line">MODEL_PATH = <span class="string">&quot;./sarsa.npy&quot;</span>     <span class="comment"># Q表格保存路径</span></span><br></pre></td></tr></table></figure><h3 id="2-构建智能体">(2) 构建智能体</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SarsaAgent</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, obs_dim, act_dim, learning_rate=<span class="number">0.01</span>,</span></span><br><span class="line"><span class="params">                 gamma=<span class="number">0.9</span>, epsilon=<span class="number">0.1</span></span>):</span><br><span class="line">        self.act_dim = act_dim      <span class="comment"># 动作维度，即可选动作数</span></span><br><span class="line">        self.lr = learning_rate     <span class="comment"># 学习率</span></span><br><span class="line">        self.gamma = gamma          <span class="comment"># reward衰减因子</span></span><br><span class="line">        self.epsilon = epsilon      <span class="comment"># 随机选取动作的概率</span></span><br><span class="line">        self.Q = np.zeros((obs_dim, act_dim))   <span class="comment"># Q表格</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 依据输入的状态，采样输出的动作值，包含探索</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample</span>(<span class="params">self, obs</span>):</span><br><span class="line">        <span class="keyword">if</span> np.random.uniform(<span class="number">0</span>, <span class="number">1</span>) &lt; self.epsilon:</span><br><span class="line">            <span class="keyword">return</span> np.random.choice(self.act_dim)   <span class="comment"># 随机探索选取动作</span></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 根据table的Q值选动作</span></span><br><span class="line">            <span class="keyword">return</span> self.predict(obs)                <span class="comment"># 根据表格的Q值选动作</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 依据输入的观察值，预测输出的动作值</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, obs</span>):</span><br><span class="line">        Q_list = self.Q[obs, :]</span><br><span class="line">        maxQ = np.<span class="built_in">max</span>(Q_list)</span><br><span class="line">        act_list = np.where(Q_list == maxQ)[<span class="number">0</span>]  <span class="comment"># 找出最大Q值对应的动作</span></span><br><span class="line">        <span class="keyword">return</span> np.random.choice(act_list)       <span class="comment"># 随机选取一个动作</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新Q-Table的学习方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learn</span>(<span class="params">self, obs, action, reward, next_obs, next_act, done</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;【On-Policy】</span></span><br><span class="line"><span class="string">            obs：交互前的状态，即s[t]；</span></span><br><span class="line"><span class="string">            action：本次交互选择的动作，即a[t]；</span></span><br><span class="line"><span class="string">            reward：本次动作获得的奖励，即r；</span></span><br><span class="line"><span class="string">            next_obs：本次交互后的状态，即s[t+1]；</span></span><br><span class="line"><span class="string">            next_act：根据当前Q表格，针对next_obs会选择的动作，即a[t+1]；</span></span><br><span class="line"><span class="string">            done：episode是否结束；</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        current_Q = self.Q[obs, action]     <span class="comment"># 当前的Q值</span></span><br><span class="line">        <span class="keyword">if</span> done:    <span class="comment"># 如果没有下一个状态了，即当前episode已结束</span></span><br><span class="line">            target_Q = reward       <span class="comment"># 目标值就是本次动作的奖励值</span></span><br><span class="line">        <span class="keyword">else</span>:       <span class="comment"># 否则采用SARSA的公式获取目标值</span></span><br><span class="line">            target_Q = reward + self.gamma * self.Q[next_obs, next_act]</span><br><span class="line">        self.Q[obs, action] += self.lr * (target_Q - current_Q)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存Q表格的数据到文件</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, path</span>):</span><br><span class="line">        np.save(path, self.Q)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\033[1;32m Save data into file: `%s`. \033[0m&quot;</span> % path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从文件中读取数据到Q表格</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">restore</span>(<span class="params">self, path</span>):</span><br><span class="line">        self.Q = np.load(path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\033[1;33m Load data from file: `%s`. \033[0m&quot;</span> % path)</span><br></pre></td></tr></table></figure><h3 id="3-训练与测试">(3) 训练与测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run_episode()是agent在一个episode中训练学习的函数，</span></span><br><span class="line"><span class="comment"># 它使用agent.sample()与环境交互，使用agent.learn()训练Q表格</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_episode</span>(<span class="params">env, agent, render=<span class="literal">False</span></span>):</span><br><span class="line">    done, total_steps, total_reward = <span class="literal">False</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    obs = env.reset()           <span class="comment"># 重置环境，开始新的episode</span></span><br><span class="line">    action = agent.sample(obs)  <span class="comment"># 根据状态选择动作</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">        next_obs, reward, done, _ = env.step(action)    <span class="comment"># 与环境进行一个交互</span></span><br><span class="line">        next_act = agent.sample(next_obs)               <span class="comment"># 根据状态选取动作</span></span><br><span class="line">        agent.learn(obs, action, reward, next_obs, next_act, done)  <span class="comment"># 学习</span></span><br><span class="line"></span><br><span class="line">        obs, action = next_obs, next_act    <span class="comment"># 记录新的状态和动作</span></span><br><span class="line">        total_reward += reward</span><br><span class="line">        total_steps += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> render:      <span class="comment"># 如果需要渲染一帧图形</span></span><br><span class="line">            env.render()</span><br><span class="line">    <span class="keyword">return</span> total_reward, total_steps</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># test_episode()是agent在一个episode中测试效果的函数，</span></span><br><span class="line"><span class="comment"># 需要评估agent能在一个episode中拿到多少奖励total_reward</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_episode</span>(<span class="params">env, agent, render=<span class="literal">False</span></span>):</span><br><span class="line">    agent.restore(MODEL_PATH)     <span class="comment"># 读取训练好的模型参数</span></span><br><span class="line">    done, total_reward = <span class="literal">False</span>, <span class="number">0</span></span><br><span class="line">    obs = env.reset()   <span class="comment"># 重置环境，开始新的episode</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">        action = agent.predict(obs)                     <span class="comment"># 根据状态预测动作</span></span><br><span class="line">        next_obs, reward, done, _ = env.step(action)    <span class="comment"># 与环境进行一个交互</span></span><br><span class="line">        total_reward += reward</span><br><span class="line">        obs = next_obs</span><br><span class="line">        <span class="keyword">if</span> render:      <span class="comment"># 如果需要渲染一帧图形</span></span><br><span class="line">            env.render()</span><br><span class="line">    <span class="keyword">return</span> total_reward</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">env = gym.make(<span class="string">&quot;CliffWalking-v0&quot;</span>)   <span class="comment"># 创建悬崖环境</span></span><br><span class="line"></span><br><span class="line">agent = SarsaAgent(</span><br><span class="line">    env.observation_space.n,        <span class="comment"># 状态的数量</span></span><br><span class="line">    env.action_space.n,             <span class="comment"># 动作的种类数</span></span><br><span class="line">    learning_rate=LEARNING_RATE,    <span class="comment"># 学习率</span></span><br><span class="line">    gamma=GAMMA,                    <span class="comment"># 奖励衰减因子</span></span><br><span class="line">    epsilon=EPSILON,                <span class="comment"># 随机选取动作的概率</span></span><br><span class="line">)   <span class="comment"># 创建SARSA智能体</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(TRAIN_EPOCHS + <span class="number">1</span>):</span><br><span class="line">    ep_reward, ep_steps = run_episode(env, agent, <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">if</span> ep % LOG_GAP == <span class="number">0</span>:   <span class="comment"># 定期输出一次分数</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Episode: %3d; Steps: %3d; Reward: %.1f&quot;</span> %</span><br><span class="line">                (ep, ep_steps, ep_reward))</span><br><span class="line"></span><br><span class="line">agent.save(MODEL_PATH)   <span class="comment"># 保存模型参数（Q表格）</span></span><br><span class="line">test_reward = test_episode(env, agent, <span class="literal">False</span>)  <span class="comment"># 测试模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;【Eval】\t Reward: %.1f&quot;</span> % test_reward)</span><br></pre></td></tr></table></figure><p>实验结果如下（Reward值越大，说明学习效果越好）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Episode:   0; Steps: 857; Reward: -2144.0</span><br><span class="line">Episode:  50; Steps:  33; Reward: -33.0</span><br><span class="line">Episode: 100; Steps:  30; Reward: -129.0</span><br><span class="line">Episode: 150; Steps:  44; Reward: -44.0</span><br><span class="line">Episode: 200; Steps:  15; Reward: -15.0</span><br><span class="line">Episode: 250; Steps:  19; Reward: -118.0</span><br><span class="line">Episode: 300; Steps:  26; Reward: -125.0</span><br><span class="line">Episode: 350; Steps:  19; Reward: -19.0</span><br><span class="line">Episode: 400; Steps:  17; Reward: -17.0</span><br><span class="line">Episode: 450; Steps:  22; Reward: -22.0</span><br><span class="line">Episode: 500; Steps:  19; Reward: -19.0</span><br><span class="line"></span><br><span class="line">【Eval】  Reward: -15.0</span><br></pre></td></tr></table></figure><hr><h1>3. Q-learning算法</h1><h2 id="3-1-算法简介">3.1. 算法简介</h2><ul><li><p><code>Q-learning</code>也是采用Q表格的方式存储Q值（状态动作价值），决策部分与SARSA是一样的，采用ε-greedy方式增加探索。</p></li><li><p><code>Q-learning</code>跟<code>SARSA</code>不一样的地方是更新Q表格的方式。</p></li></ul><blockquote><ul><li>SARSA是on-policy的更新方式，先做出动作再更新。</li><li>Q-learning是off-policy的更新方式，更新learn()时无需获取下一步实际做出的动作next_action，并假设下一步动作是取最大Q值的动作。</li></ul></blockquote><ul><li>Q-learning的更新公式为：<br><img src="https://img-blog.csdnimg.cn/img_convert/24e2bcce50ade8fa620ba5d24c5bb4e9.png" alt=""></li></ul><h2 id="3-2-算法伪码">3.2. 算法伪码</h2><p><img src="https://img-blog.csdnimg.cn/20201127200236272.png#pic_center" alt=""></p><h2 id="3-3-算法实现">3.3. 算法实现</h2><h3 id="1-前期准备-2">(1) 前期准备</h3><ul><li><strong>导入模块</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> gym</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">TRAIN_EPOCHS = <span class="number">500</span>               <span class="comment"># 训练轮数</span></span><br><span class="line">LOG_GAP = <span class="number">50</span>                     <span class="comment"># 日志打印间隔</span></span><br><span class="line"></span><br><span class="line">LEARNING_RATE = <span class="number">0.1</span>              <span class="comment"># 学习率</span></span><br><span class="line">GAMMA = <span class="number">0.95</span>                     <span class="comment"># 奖励衰减因子</span></span><br><span class="line">EPSILON = <span class="number">0.1</span>                    <span class="comment"># 随机选取动作的概率</span></span><br><span class="line"></span><br><span class="line">MODEL_PATH = <span class="string">&quot;./q_learning.npy&quot;</span>  <span class="comment"># Q表格保存路径</span></span><br></pre></td></tr></table></figure><h3 id="2-构建智能体-2">(2) 构建智能体</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">QLearningAgent</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, obs_dim, act_dim, learning_rate=<span class="number">0.01</span>,</span></span><br><span class="line"><span class="params">                 gamma=<span class="number">0.9</span>, epsilon=<span class="number">0.1</span></span>):</span><br><span class="line">        self.act_dim = act_dim      <span class="comment"># 动作维度，即可选动作数</span></span><br><span class="line">        self.lr = learning_rate     <span class="comment"># 学习率</span></span><br><span class="line">        self.gamma = gamma          <span class="comment"># 奖励衰减因子</span></span><br><span class="line">        self.epsilon = epsilon      <span class="comment"># 随机选取动作的概率</span></span><br><span class="line">        self.Q = np.zeros((obs_dim, act_dim))   <span class="comment"># Q表格</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 依据输入的状态，采样输出的动作值，包含探索</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">sample</span>(<span class="params">self, obs</span>):</span><br><span class="line">        <span class="keyword">if</span> np.random.uniform(<span class="number">0</span>, <span class="number">1</span>) &lt; self.epsilon:</span><br><span class="line">            <span class="keyword">return</span> np.random.choice(self.act_dim)   <span class="comment"># 随机探索选取动作</span></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 根据table的Q值选动作</span></span><br><span class="line">            <span class="keyword">return</span> self.predict(obs)                <span class="comment"># 根据表格的Q值选动作</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 依据输入的观察值，预测输出的动作值</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, obs</span>):</span><br><span class="line">        Q_list = self.Q[obs, :]</span><br><span class="line">        maxQ = np.<span class="built_in">max</span>(Q_list)</span><br><span class="line">        act_list = np.where(Q_list == maxQ)[<span class="number">0</span>]  <span class="comment"># 找出最大Q值对应的动作</span></span><br><span class="line">        <span class="keyword">return</span> np.random.choice(act_list)       <span class="comment"># 随机选取一个动作</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新Q-Table的学习方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">learn</span>(<span class="params">self, obs, action, reward, next_obs, done</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;【Off-Policy】</span></span><br><span class="line"><span class="string">            obs：交互前的状态，即s[t]；</span></span><br><span class="line"><span class="string">            action：本次交互选择的动作，即a[t]；</span></span><br><span class="line"><span class="string">            reward：本次动作获得的奖励，即r；</span></span><br><span class="line"><span class="string">            next_obs：本次交互后的状态，即s[t+1]；</span></span><br><span class="line"><span class="string">            done：episode是否结束；</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        cur_Q = self.Q[obs, action]</span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            target_Q = reward</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            target_Q = reward + self.gamma * np.<span class="built_in">max</span>(self.Q[next_obs, :])</span><br><span class="line">        self.Q[obs, action] += self.lr * (target_Q - cur_Q)    <span class="comment"># 更新表格</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存Q表格的数据到文件</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save</span>(<span class="params">self, path</span>):</span><br><span class="line">        np.save(path, self.Q)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\033[1;32m Save data into file: `%s`. \033[0m&quot;</span> % path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从文件中读取数据到Q表格</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">restore</span>(<span class="params">self, path</span>):</span><br><span class="line">        self.Q = np.load(path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\033[1;33m Load data from file: `%s`. \033[0m&quot;</span> % path)</span><br></pre></td></tr></table></figure><h3 id="3-训练与测试-2">(3) 训练与测试</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run_episode()是agent在一个episode中训练学习的函数，</span></span><br><span class="line"><span class="comment"># 它使用agent.sample()与环境交互，使用agent.learn()训练Q表格</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_episode</span>(<span class="params">env, agent, render=<span class="literal">False</span></span>):</span><br><span class="line">    done, total_steps, total_reward = <span class="literal">False</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    obs = env.reset()   <span class="comment"># 重开一局，重置环境</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">        action = agent.sample(obs)                      <span class="comment"># 根据状态选择动作</span></span><br><span class="line">        next_obs, reward, done, _ = env.step(action)    <span class="comment"># 与环境进行一次交互</span></span><br><span class="line">        agent.learn(obs, action, reward, next_obs, done)    <span class="comment"># 学习</span></span><br><span class="line"></span><br><span class="line">        obs = next_obs              <span class="comment"># 记录新的状态</span></span><br><span class="line">        total_reward += reward</span><br><span class="line">        total_steps += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> render:      <span class="comment"># 如果需要渲染一帧图形</span></span><br><span class="line">            env.render()</span><br><span class="line">    <span class="keyword">return</span> total_reward, total_steps</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># test_episode()是agent在一个episode中测试效果的函数，</span></span><br><span class="line"><span class="comment"># 需要评估agent能在一个episode中拿到多少奖励total_reward</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_episode</span>(<span class="params">env, agent, render=<span class="literal">False</span></span>):</span><br><span class="line">    agent.restore(MODEL_PATH)     <span class="comment"># 读取训练好的模型参数</span></span><br><span class="line">    done, total_reward = <span class="literal">False</span>, <span class="number">0</span></span><br><span class="line">    obs = env.reset()   <span class="comment"># 重开一局，重置环境</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> done:</span><br><span class="line">        action = agent.predict(obs)                     <span class="comment"># 根据状态选取动作</span></span><br><span class="line">        next_obs, reward, done, _ = env.step(action)    <span class="comment"># 与环境进行一次交互</span></span><br><span class="line">        total_reward += reward</span><br><span class="line">        obs = next_obs              <span class="comment"># 记录新的状态</span></span><br><span class="line">        <span class="keyword">if</span> render:</span><br><span class="line">            env.render()</span><br><span class="line">    <span class="keyword">return</span> total_reward</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">env = gym.make(<span class="string">&quot;CliffWalking-v0&quot;</span>)   <span class="comment"># 创建悬崖环境</span></span><br><span class="line"></span><br><span class="line">agent = QLearningAgent(</span><br><span class="line">    env.observation_space.n,        <span class="comment"># 状态维度</span></span><br><span class="line">    env.action_space.n,             <span class="comment"># 动作维度</span></span><br><span class="line">    learning_rate=LEARNING_RATE,    <span class="comment"># 学习率</span></span><br><span class="line">    gamma=GAMMA,                    <span class="comment"># 奖励衰减因子</span></span><br><span class="line">    epsilon=EPSILON,                <span class="comment"># 随机选取动作的概率</span></span><br><span class="line">)   <span class="comment"># 创建Q-learning智能体</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(TRAIN_EPOCHS + <span class="number">1</span>):</span><br><span class="line">    ep_reward, ep_steps = run_episode(env, agent, <span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">if</span> ep % LOG_GAP == <span class="number">0</span>:   <span class="comment"># 定期输出一次分数</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Episode: %3d; Steps: %3d; Reward: %.1f&quot;</span> %</span><br><span class="line">                (ep, ep_steps, ep_reward))</span><br><span class="line"></span><br><span class="line">agent.save(MODEL_PATH)    <span class="comment"># 保存模型参数（Q表格）</span></span><br><span class="line">test_reward = test_episode(env, agent, <span class="literal">False</span>)  <span class="comment"># 测试模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;【Eval】\t Reward: %.1f&quot;</span> % test_reward)</span><br></pre></td></tr></table></figure><p>实验结果如下（Reward值越大，说明学习效果越好）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Episode:   0; Steps: 519; Reward: -1608.0</span><br><span class="line">Episode:  50; Steps:  20; Reward: -20.0</span><br><span class="line">Episode: 100; Steps:  21; Reward: -21.0</span><br><span class="line">Episode: 150; Steps:  47; Reward: -146.0</span><br><span class="line">Episode: 200; Steps:  18; Reward: -18.0</span><br><span class="line">Episode: 250; Steps:  30; Reward: -228.0</span><br><span class="line">Episode: 300; Steps:  20; Reward: -20.0</span><br><span class="line">Episode: 350; Steps:  13; Reward: -13.0</span><br><span class="line">Episode: 400; Steps:  17; Reward: -17.0</span><br><span class="line">Episode: 450; Steps:  14; Reward: -14.0</span><br><span class="line">Episode: 500; Steps:  50; Reward: -248.0</span><br><span class="line">   </span><br><span class="line">【Eval】  Reward: -13.0</span><br></pre></td></tr></table></figure><h1>4. 实验结论</h1><p>在解决悬崖行走问题的过程中，我们发现：</p><ul><li>Q-learning对环境的探索比较激进胆大，更倾向于最优路线</li><li>SARSA对环境的探索就比较谨慎胆小，更倾向于安全路线</li></ul><p><img src="https://img-blog.csdnimg.cn/20201204154957110.png#pic_center" alt=""></p><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/2250312?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 强化学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习相关理论基础</title>
      <link href="/2021/07/10/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"/>
      <url>/2021/07/10/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 强化学习</h1><h2 id="1-1-核心思想">1.1. 核心思想</h2><p>强化学习（Reinforcement Learning，RL）研究的是智能体如何决策以获得最大效益。</p><p><img src="https://img-blog.csdnimg.cn/456a06e277cc4bcab0b9a21fd18a6847.webp#pic_center" alt=""></p><p>如上图所示，智能体<code>agent</code>在训练环境<code>environment</code>中学习，根据环境的全局状态<code>state</code>或观测到的局部观测值<code>observation</code>，执行相应的动作<code>action</code>，并根据环境的反馈<code>reward</code>来指导自己。智能体通过不断的试错探索、吸取经验教训，持续不断地优化策略，不断提升模型的正确决策的能力，以便从环境中拿到更好的反馈，最终实现“最小化风险、最大化收益”的目标。</p><h2 id="1-2-区别联系">1.2. 区别联系</h2><p>如下图所示，机器学习（Machine Learning，ML）算法通常可以分为监督学习（Supervised Learning）、无监督学习（Unsupervised Learning）和强化学习，深度学习通常可以与这些方法一起使用。</p><p><img src="https://img-blog.csdnimg.cn/f11f98a89178491583279140afeb7559.png#pic_center" alt=""></p><ul><li><p><strong>监督学习</strong><br>监督学习使用带标签的数据进行学习，主要寻找输入与输出之间的映射关系，它主要用于处理认知问题，适用于解决分类问题、回归问题等。</p></li><li><p><strong>无监督学习</strong><br>无监督学习使用无标签的数据进行学习，主要寻找数据之间隐藏的关系，它适用于解决聚类问题等。</p></li><li><p><strong>强化学习</strong><br>强化学习主要处理如何基于环境进行最优决策的问题，“试错”是强化学习的核心特点，它适用于解决马尔科夫决策问题、动态规划问题等。</p></li></ul><h2 id="1-3-算法分类">1.3. 算法分类</h2><p>（1）按照环境是否已知可以分为<code>Model-Based</code>和<code>Model-Free</code>。<br>比较常用的是后者，因为大多数情况下，智能体所处的环境是未知的。</p><p>（2）按照应用环境可以分为<code>基于离散控制场景的强化学习算法</code>和<code>基于连续控制场景的强化学习算法</code>。<br>如下图所示，前者常见的有：DQN算法、DDQN算法等，后者常见的有DDPG算法、TD3算法、SAC算法等。<br><img src="https://img-blog.csdnimg.cn/313ed5b4f5c54e2da535c8edb6dfdda8.png#pic_center" alt=""><br>（图片来源：<a href="https://zhuanlan.zhihu.com/p/342919579">曾伊言 - 如何选择深度强化学习算法？</a>）</p><p>（3）按照学习方式可以分为<code>On-Policy</code>和<code>Off-Policy</code>。<br>Sarsa算法就属于On-Policy算法，Q-learning算法就属于Off-Policy算法。</p><p>（4）按照学习目标可以分为<code>Value-Based</code>和<code>Policy-Based</code>。</p><ul><li>基于价值（Value Based）的算法需要先将Q函数优化到最优，然后再选最优策略；</li><li>基于策略（Policy Based）的算法直接优化策略函数输出最优动作。</li></ul><hr><h1>2. 应用场景举例</h1><p>接下来，介绍强化学习领域的两个前景广阔的应用场景：</p><h2 id="2-1-个性化推荐">2.1. 个性化推荐</h2><p><img src="https://img-blog.csdnimg.cn/8b187f516b3a4e95a3e4747a9dded0bf.png#pic_center" alt=""></p><ul><li><p><strong>设计思路</strong><br>在强化学习的框架之下，推荐系统被视作一个智能体（agent），用户当前的行为特征被抽象成为状态（state），待推荐的对象（如商品/新闻）则被当作动作（action）。在每次推荐交互中，系统依据用户的状态，选择合适的动作，以最大化特定的长效目标（如点击总数或停留时长）。推荐系统与用户交互过程中所产生的行为数据被组织成为经验（experience），用以记录相应动作产生的奖励（reward）以及状态转移（state-transition）。基于不断积累的经验，强化学习算法得出策略（policy），用以指导特定状态下最优的动作选取。</p></li><li><p><strong>应用场景</strong><br>适用于构建资讯推荐系统、商品推荐系统等</p></li><li><p><strong>主要挑战</strong><br>推荐场景下的可获取的交互数据往往规模有限且奖励信号稀疏（reward-sparsity），这就使得简单地套用既有算法难以取得令人满意的实际效果。如何运用有限的用户交互得到有效的决策模型将是算法进一步提升的主要方向。</p></li></ul><h2 id="2-2-投资组合决策">2.2. 投资组合决策</h2><p><img src="https://img-blog.csdnimg.cn/7db292d26b854658abc0a86c1160bdec.png#pic_center" alt=""></p><ul><li><p><strong>设计思路</strong><br>监督学习模型可用来预测未来的价格，然而它们并不适用于在特定价格下做出决策。强化学习正是一种擅长“动态规划”和“决策”的算法，我们可以构建虚拟交易环境，通过市场基准标准对智能体的行为进行评估，确保智能体正确做出持有、购买或是出售的决定，以保证最佳收益。</p></li><li><p><strong>应用场景</strong><br>适用于解决多股票/基金交易问题、项目投资组合问题等</p></li></ul><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 强化学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【GoogLeNet】海洋生物识别</title>
      <link href="/2021/03/25/%E3%80%90GoogLeNet%E3%80%91%E6%B5%B7%E6%B4%8B%E7%94%9F%E7%89%A9%E8%AF%86%E5%88%AB/"/>
      <url>/2021/03/25/%E3%80%90GoogLeNet%E3%80%91%E6%B5%B7%E6%B4%8B%E7%94%9F%E7%89%A9%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 项目准备</h1><h2 id="1-1-问题导入-7">1.1. 问题导入</h2><p>图像分类是根据图像的语义信息将不同类别图像区分开来，是计算机视觉中重要的基本问题。本实践使用卷积神经网络GoogLeNet模型构建深度学习模型，自动提取高质量的特征，来解决海洋鱼类识别的问题。</p><h2 id="1-2-数据集简介-5">1.2. 数据集简介</h2><p>本次实验使用的是台湾电力公司、台湾海洋研究所和垦丁国家公园在2010年10月1日至2013年9月30日期间，在中国台湾南湾海峡、兰屿岛和胡比湖的水下观景台收集的鱼类图像数据集。该数据集包括23类鱼种，共27370张鱼的图像，本次实验将取其中的90%作为训练集，剩下的10%作为测试集。</p><p><img src="https://img-blog.csdnimg.cn/5b00468b44174c78b95f3c3bc8ca6daf.png#pic_center" alt=""></p><blockquote><p>这是数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/14492">Fish4Knowledge 23种鱼类数据集 - AI Studio</a></p></blockquote><h1>2. GoogLeNet模型</h1><p><code>GoogLeNet</code>模型是由Google团队在<a href="https://arxiv.org/pdf/1409.4842.pdf">论文</a>中提出的卷积神经网络，是2014年ILSVRC竞赛的冠军模型。相比于<code>AlexNet</code>模型，<code>GoogLeNet</code>模型的网络结构更深，共包括87层。尽管模型结构变得更复杂，但它的参数量仅为<code>AlexNet</code>模型参数量的1/10，这主要归功于它创新性地采用了<code>Inception</code>模块。如下图所示，<code>Inception</code>模块是一种多路并联结构，它能够提取并整合不同视野范围的特征，能极大地提升分类模型的性能。<br><img src="https://img-blog.csdnimg.cn/9f218ae8511648949b5a9f0275e447df.png#pic_center" alt=""></p><p><code>GoogLeNet</code>模型由多个模块串联而成，其网络结构如下图所示。以前的模型是将二维的卷积层输出的特征图直接拉成一维的全连接层输入，而在<code>GoogLeNet</code>模型中，作者在卷积层和全连接层之间插入一个全局平均池化层，直接生成一维的全连接层输入，这样做还能减少模型参数。需要注意的是，原始的<code>GoogLeNet</code>模型包含两个辅助分类器，由于辅助分类器在后续的深度卷积网络演化中并没有被再次使用，故我们去除了这两个辅助分类器。<br><img src="https://img-blog.csdnimg.cn/27bf41d903e4457cbc2347c173a5b940.png#pic_center" alt=""></p><hr><h1>3. 实验步骤</h1><p><img src="https://img-blog.csdnimg.cn/20210208110405937.png#pic_center" alt=""></p><h2 id="3-0-前期准备-3">3.0. 前期准备</h2><ul><li><strong>导入模块</strong></li></ul><blockquote><p>注意：本案例仅适用于<code>PaddlePaddle 2.0+</code>版本</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> metric <span class="keyword">as</span> M</span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer.lr <span class="keyword">import</span> NaturalExpDecay</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">64</span>      <span class="comment"># 每批次的样本数</span></span><br><span class="line">EPOCHS = <span class="number">5</span>           <span class="comment"># 训练轮数</span></span><br><span class="line">LOG_GAP = <span class="number">200</span>        <span class="comment"># 输出训练信息的间隔</span></span><br><span class="line"></span><br><span class="line">INIT_LR = <span class="number">3e-4</span>       <span class="comment"># 初始学习率</span></span><br><span class="line">LR_DECAY = <span class="number">0.5</span>       <span class="comment"># 学习率衰减率</span></span><br><span class="line"></span><br><span class="line">SRC_PATH = <span class="string">&quot;./data/data14492/fish_image23.zip&quot;</span>          <span class="comment"># 压缩包路径</span></span><br><span class="line">DST_PATH = <span class="string">&quot;./data&quot;</span>                                     <span class="comment"># 解压路径</span></span><br><span class="line">DATA_PATH = DST_PATH + <span class="string">&quot;/fish_image&quot;</span>                    <span class="comment"># 实验数据集路径</span></span><br><span class="line">INFER_LIST = [(<span class="string">&quot;./work/pm.jpg&quot;</span>, <span class="string">&quot;Pomacentrus moluccensis&quot;</span>),</span><br><span class="line">              (<span class="string">&quot;./work/ac.jpg&quot;</span>, <span class="string">&quot;Amphiprion clarkii&quot;</span>)]  <span class="comment"># 预测数据</span></span><br><span class="line">MODEL_PATH = <span class="string">&quot;GoogLeNet.pdparams&quot;</span>                       <span class="comment"># 模型参数保存路径</span></span><br><span class="line"></span><br><span class="line">LAB_DICT = &#123;<span class="string">&#x27;fish_1&#x27;</span>: <span class="string">&#x27;Dascyllus reticulatus&#x27;</span>, <span class="string">&#x27;fish_2&#x27;</span>: <span class="string">&#x27;Plectroglyphidodon dickii&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_3&#x27;</span>: <span class="string">&#x27;Chromis chrysura&#x27;</span>, <span class="string">&#x27;fish_4&#x27;</span>: <span class="string">&#x27;Amphiprion clarkii&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_5&#x27;</span>: <span class="string">&#x27;Chaetodon lunulatus&#x27;</span>, <span class="string">&#x27;fish_6&#x27;</span>: <span class="string">&#x27;Chaetodon trifascialis&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_7&#x27;</span>: <span class="string">&#x27;Myripristis kuntee&#x27;</span>, <span class="string">&#x27;fish_8&#x27;</span>: <span class="string">&#x27;Acanthurus nigrofuscus&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_9&#x27;</span>: <span class="string">&#x27;Hemigymnus fasciatus&#x27;</span>, <span class="string">&#x27;fish_10&#x27;</span>: <span class="string">&#x27;Neoniphon sammara&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_11&#x27;</span>: <span class="string">&#x27;Abudefduf vaigiensis&#x27;</span>, <span class="string">&#x27;fish_12&#x27;</span>: <span class="string">&#x27;Canthigaster valentini&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_13&#x27;</span>: <span class="string">&#x27;Pomacentrus moluccensis&#x27;</span>, <span class="string">&#x27;fish_14&#x27;</span>: <span class="string">&#x27;Zebrasoma scopas&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_15&#x27;</span>: <span class="string">&#x27;Hemigymnus melapterus&#x27;</span>, <span class="string">&#x27;fish_16&#x27;</span>: <span class="string">&#x27;Lutjanus fulvus&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_17&#x27;</span>: <span class="string">&#x27;Scolopsis bilineata&#x27;</span>, <span class="string">&#x27;fish_18&#x27;</span>: <span class="string">&#x27;Scaridae&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_19&#x27;</span>: <span class="string">&#x27;Pempheris vanicolensis&#x27;</span>, <span class="string">&#x27;fish_20&#x27;</span>: <span class="string">&#x27;Zanclus cornutus&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_21&#x27;</span>: <span class="string">&#x27;Neoglyphidodon nigroris&#x27;</span>, <span class="string">&#x27;fish_22&#x27;</span>: <span class="string">&#x27;Balistapus undulatus&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;fish_23&#x27;</span>: <span class="string">&#x27;Siganus fuscescens&#x27;</span>&#125;     <span class="comment"># 用于将文件名和标签相对应</span></span><br></pre></td></tr></table></figure><h2 id="3-1-数据准备-2">3.1. 数据准备</h2><ul><li><strong>解压数据集</strong><br>由于数据集中的数据是以压缩包的形式存放的，因此我们需要先解压数据压缩包。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(DATA_PATH):</span><br><span class="line">    z = zipfile.ZipFile(SRC_PATH, <span class="string">&quot;r&quot;</span>)   <span class="comment"># 打开压缩文件，创建zip对象</span></span><br><span class="line">    z.extractall(path=DST_PATH)          <span class="comment"># 解压zip文件至目标路径</span></span><br><span class="line">    z.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;数据集解压完成！&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>划分数据集</strong><br>我们需要按1:9比例划分测试集和训练集，分别生成两个包含数据路径和标签映射关系的列表。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">type_num, lab_dict = <span class="number">0</span>, &#123;&#125;          <span class="comment"># 方便动物类别在字符型和整型之间转换</span></span><br><span class="line">train_list, test_list = [], []           <span class="comment"># 存放数据的路径及标签的映射关系</span></span><br><span class="line">file_folders = os.listdir(DATA_PATH)     <span class="comment"># 统计数据集下的文件夹</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> folder <span class="keyword">in</span> file_folders:</span><br><span class="line">    lab_dict[<span class="built_in">str</span>(type_num)] = LAB_DICT[folder]   <span class="comment"># 记录标签和数字代号的对应关系</span></span><br><span class="line">    imgs = os.listdir(os.path.join(DATA_PATH, folder))</span><br><span class="line">    <span class="keyword">for</span> idx, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(imgs):</span><br><span class="line">        path = os.path.join(DATA_PATH, folder, img)</span><br><span class="line">        <span class="keyword">if</span> idx % <span class="number">10</span> == <span class="number">0</span>:      <span class="comment"># 按照1:9的比例划分数据集</span></span><br><span class="line">            test_list.append([path, type_num])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            train_list.append([path, type_num])</span><br><span class="line">    type_num += <span class="number">1</span></span><br></pre></td></tr></table></figure><ul><li><strong>数据预处理</strong><br>我们需要对数据集图像进行缩放和归一化处理。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 自定义的数据集类 &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, label_list, transform</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `label_list`: 标签与文件路径的映射列表</span></span><br><span class="line"><span class="string">        * `transform`：数据处理函数</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(MyDataset, self).__init__()</span><br><span class="line">        random.shuffle(label_list)      <span class="comment"># 打乱映射列表</span></span><br><span class="line">        self.label_list = label_list</span><br><span class="line">        self.transform = transform        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 根据位序获取对应数据 &#x27;&#x27;&#x27;</span></span><br><span class="line">        img_path, label = self.label_list[index]</span><br><span class="line">        img = self.transform(img_path)</span><br><span class="line">        <span class="keyword">return</span> img, <span class="built_in">int</span>(label)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 获取数据集样本总数 &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.label_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_mapper</span>(<span class="params">img_path, show=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 图像处理函数 &#x27;&#x27;&#x27;</span></span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    <span class="keyword">if</span> show:     <span class="comment"># 展示图像</span></span><br><span class="line">        display(img)</span><br><span class="line">    <span class="comment"># 将其缩放为224*224的高质量图像：</span></span><br><span class="line">    img = img.resize((<span class="number">224</span>, <span class="number">224</span>), Image.ANTIALIAS)</span><br><span class="line">    <span class="comment"># 把图像变成一个numpy数组以匹配数据馈送格式：</span></span><br><span class="line">    img = np.array(img).astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">    <span class="comment"># 将图像矩阵由“rgb,rgb,rbg...”转置为“rr...,gg...,bb...”：</span></span><br><span class="line">    img = img.transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 将图像数据归一化，并转换成Tensor格式：</span></span><br><span class="line">    img = paddle.to_tensor(img / <span class="number">255.0</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = MyDataset(train_list, data_mapper)  <span class="comment"># 训练集</span></span><br><span class="line">test_dataset = MyDataset(test_list, data_mapper)    <span class="comment"># 测试集</span></span><br></pre></td></tr></table></figure><ul><li><strong>定义数据提供器</strong><br>我们需要分别构建用于训练和测试的数据提供器，其中训练数据提供器是乱序、按批次提供数据的。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(train_dataset,            <span class="comment"># 训练数据集</span></span><br><span class="line">                          batch_size=BATCH_SIZE,    <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                          num_workers=<span class="number">0</span>,            <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                          shuffle=<span class="literal">True</span>,             <span class="comment"># 打乱训练数据集</span></span><br><span class="line">                          drop_last=<span class="literal">False</span>)          <span class="comment"># 不丢弃不完整的样本</span></span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(test_dataset,              <span class="comment"># 测试数据集</span></span><br><span class="line">                         batch_size=BATCH_SIZE,     <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                         num_workers=<span class="number">0</span>,             <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                         shuffle=<span class="literal">False</span>,             <span class="comment"># 不打乱测试数据集</span></span><br><span class="line">                         drop_last=<span class="literal">False</span>)           <span class="comment"># 不丢弃不完整的样本</span></span><br></pre></td></tr></table></figure><h2 id="3-2-网络配置-2">3.2. 网络配置</h2><p><code>GoogLeNet</code>模型的网络参数设置如下表所示：<br><img src="https://img-blog.csdnimg.cn/b940a5a812484d4a810f58511c8d0b19.png#pic_center" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBN</span>(nn.Layer):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Conv2D with BatchNorm2D and ReLU &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span>, out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_channels`: 输入通道数</span></span><br><span class="line"><span class="string">        * `out_channels`: 输出通道数</span></span><br><span class="line"><span class="string">        * `kernel_size`: 卷积核大小</span></span><br><span class="line"><span class="string">        * `stride`: 卷积运算的步长</span></span><br><span class="line"><span class="string">        * `padding`: 卷积填充的大小</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(ConvBN, self).__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Conv2D(in_channels, out_channels, kernel_size, stride, padding),</span><br><span class="line">            nn.BatchNorm2D(out_channels),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Inception</span>(nn.Layer):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Inception v1 in GoogLeNet &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span>, c1: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 c2: <span class="built_in">tuple</span>, c3: <span class="built_in">tuple</span>, c4: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_channels`: 输入通道数</span></span><br><span class="line"><span class="string">        * `c1`: 第1路卷积层的通道参数</span></span><br><span class="line"><span class="string">        * `c2`: 第2路卷积层的通道参数</span></span><br><span class="line"><span class="string">        * `c3`: 第3路卷积层的通道参数</span></span><br><span class="line"><span class="string">        * `c4`: 第4路卷积层的通道参数</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(Inception, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            ConvBN(in_channels, c1, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.conv2 = nn.Sequential(</span><br><span class="line">            ConvBN(in_channels, c2[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            ConvBN(c2[<span class="number">0</span>], c2[<span class="number">1</span>], <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.conv3 = nn.Sequential(</span><br><span class="line">            ConvBN(in_channels, c3[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            ConvBN(c3[<span class="number">0</span>], c3[<span class="number">1</span>], <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        self.conv4 = nn.Sequential(</span><br><span class="line">            nn.MaxPool2D(<span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            ConvBN(in_channels, c4, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y1 = self.conv1(x)</span><br><span class="line">        y2 = self.conv2(x)</span><br><span class="line">        y3 = self.conv3(x)</span><br><span class="line">        y4 = self.conv4(x)</span><br><span class="line">        y = paddle.concat([y1, y2, y3, y4], axis=<span class="number">1</span>)  <span class="comment"># Depth Concat</span></span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GoogLeNet</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, n_classes=<span class="number">2</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_channels`: 输入的通道数</span></span><br><span class="line"><span class="string">        * `n_classes`: 输出分类数量</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(GoogLeNet, self).__init__()</span><br><span class="line">        <span class="comment"># Conv2D(输入通道数,输出通道数,卷积核大小,卷积步长,填充长度)</span></span><br><span class="line">        <span class="comment"># MaxPool2D(池化核大小,池化步长,填充长度)</span></span><br><span class="line"></span><br><span class="line">        self.block1 = nn.Sequential(</span><br><span class="line">            ConvBN(in_channels, <span class="number">64</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">3</span>),  <span class="comment"># 64*112*112</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2D(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>),             <span class="comment"># 64*56*56</span></span><br><span class="line">        )</span><br><span class="line">        self.block2 = nn.Sequential(</span><br><span class="line">            ConvBN(<span class="number">64</span>, <span class="number">64</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>),           <span class="comment"># 64*56*56</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            ConvBN(<span class="number">64</span>, <span class="number">192</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),          <span class="comment"># 192*56*56</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2D(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>),             <span class="comment"># 192*28*28</span></span><br><span class="line">        )</span><br><span class="line">        self.block3 = nn.Sequential(</span><br><span class="line">            Inception(<span class="number">192</span>, <span class="number">64</span>, (<span class="number">96</span>, <span class="number">128</span>), (<span class="number">16</span>, <span class="number">32</span>), <span class="number">32</span>),      <span class="comment"># 3a：256*28*28</span></span><br><span class="line">            Inception(<span class="number">256</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">192</span>), (<span class="number">32</span>, <span class="number">96</span>), <span class="number">64</span>),    <span class="comment"># 3b：480*28*28</span></span><br><span class="line">            nn.MaxPool2D(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>),             <span class="comment"># 480*14*14</span></span><br><span class="line">        )</span><br><span class="line">        self.block4 = nn.Sequential(</span><br><span class="line">            Inception(<span class="number">480</span>, <span class="number">192</span>, (<span class="number">96</span>, <span class="number">208</span>), (<span class="number">16</span>, <span class="number">48</span>), <span class="number">64</span>),     <span class="comment"># 4a：512*14*14</span></span><br><span class="line">            Inception(<span class="number">512</span>, <span class="number">160</span>, (<span class="number">112</span>, <span class="number">224</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),    <span class="comment"># 4b：512*14*14</span></span><br><span class="line">            Inception(<span class="number">512</span>, <span class="number">128</span>, (<span class="number">128</span>, <span class="number">256</span>), (<span class="number">24</span>, <span class="number">64</span>), <span class="number">64</span>),    <span class="comment"># 4c：512*14*14</span></span><br><span class="line">            Inception(<span class="number">512</span>, <span class="number">112</span>, (<span class="number">144</span>, <span class="number">288</span>), (<span class="number">32</span>, <span class="number">64</span>), <span class="number">64</span>),    <span class="comment"># 4d：528*14*14</span></span><br><span class="line">            Inception(<span class="number">528</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),  <span class="comment"># 4e：832*14*14</span></span><br><span class="line">            nn.MaxPool2D(<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>),             <span class="comment"># 832*7*7</span></span><br><span class="line">        )</span><br><span class="line">        self.block5 = nn.Sequential(</span><br><span class="line">            Inception(<span class="number">832</span>, <span class="number">256</span>, (<span class="number">160</span>, <span class="number">320</span>), (<span class="number">32</span>, <span class="number">128</span>), <span class="number">128</span>),  <span class="comment"># 5a：832*7*7</span></span><br><span class="line">            Inception(<span class="number">832</span>, <span class="number">384</span>, (<span class="number">192</span>, <span class="number">384</span>), (<span class="number">48</span>, <span class="number">128</span>), <span class="number">128</span>),  <span class="comment"># 5b：1024*7*7</span></span><br><span class="line">            nn.AdaptiveAvgPool2D(<span class="number">1</span>),           <span class="comment"># 1024*1*1</span></span><br><span class="line">        )</span><br><span class="line">        self.block6 = nn.Sequential(</span><br><span class="line">            nn.Flatten(<span class="number">1</span>, -<span class="number">1</span>),                 <span class="comment"># 1024</span></span><br><span class="line">            nn.Dropout(p=<span class="number">0.4</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, n_classes),        <span class="comment"># n_classes</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.block1(x)</span><br><span class="line">        x = self.block2(x)</span><br><span class="line">        x = self.block3(x)</span><br><span class="line">        x = self.block4(x)</span><br><span class="line">        x = self.block5(x)</span><br><span class="line">        y = self.block6(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><ul><li><strong>实例化模型</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = GoogLeNet(in_channels=<span class="number">3</span>, n_classes=CLASS_DIM)</span><br></pre></td></tr></table></figure><h2 id="3-3-模型训练-2">3.3. 模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">model.train()                <span class="comment"># 开启训练模式</span></span><br><span class="line">scheduler = NaturalExpDecay(</span><br><span class="line">    learning_rate=INIT_LR,</span><br><span class="line">    gamma=LR_DECAY</span><br><span class="line">)                            <span class="comment"># 定义学习率衰减器</span></span><br><span class="line">optimizer = Adam(</span><br><span class="line">    learning_rate=scheduler,</span><br><span class="line">    parameters=model.parameters()</span><br><span class="line">)                            <span class="comment"># 定义Adam优化器</span></span><br><span class="line">loss_arr, acc_arr = [], []   <span class="comment"># 用于可视化</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">        x_data, y_data = data</span><br><span class="line">        y_data = y_data[:, np.newaxis]          <span class="comment"># 增加一维维度</span></span><br><span class="line">        y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">        acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">        loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">        <span class="keyword">if</span> batch_id % LOG_GAP == <span class="number">0</span>:   <span class="comment"># 定期输出训练结果</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch：%d，Batch：%3d，Loss：%.5f，Acc：%.5f&quot;</span>\</span><br><span class="line">                % (ep, batch_id, loss, acc))</span><br><span class="line">        acc_arr.append(acc.item())</span><br><span class="line">        loss_arr.append(loss.item())</span><br><span class="line">        optimizer.clear_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    scheduler.step()       <span class="comment"># 每轮衰减一次学习率</span></span><br><span class="line"></span><br><span class="line">paddle.save(model.state_dict(), MODEL_PATH)  <span class="comment"># 保存训练好的模型</span></span><br></pre></td></tr></table></figure><p>模型训练的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch：0，Batch：  0，Loss：3.50096，Acc：0.09375</span><br><span class="line">Epoch：0，Batch：200，Loss：0.41797，Acc：0.90625</span><br><span class="line">Epoch：1，Batch：  0，Loss：0.33822，Acc：0.89062</span><br><span class="line">Epoch：1，Batch：200，Loss：0.04866，Acc：0.98438</span><br><span class="line">Epoch：2，Batch：  0，Loss：0.04856，Acc：0.98438</span><br><span class="line">Epoch：2，Batch：200，Loss：0.15580，Acc：0.96875</span><br><span class="line">Epoch：3，Batch：  0，Loss：0.04368，Acc：0.98438</span><br><span class="line">Epoch：3，Batch：200，Loss：0.03558，Acc：0.98438</span><br><span class="line">Epoch：4，Batch：  0，Loss：0.00756，Acc：1.00000</span><br><span class="line">Epoch：4，Batch：200，Loss：0.00995，Acc：1.00000</span><br></pre></td></tr></table></figure><ul><li><strong>可视化训练过程</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=[<span class="number">10</span>, <span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练误差图像：</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">211</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&quot;Loss&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax1.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(loss_arr)), loss_arr, color=<span class="string">&quot;orangered&quot;</span>)</span><br><span class="line">ax1.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练准确率图像：</span></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">212</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&quot;Training Steps&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&quot;Accuracy&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax2.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(acc_arr)), acc_arr, color=<span class="string">&quot;dodgerblue&quot;</span>)</span><br><span class="line">ax2.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ae662697f34b4278b114473ef789354e.png#pic_center" alt=""></p><h2 id="3-4-模型评估-2">3.4. 模型评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">test_costs, test_accs = [], []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):</span><br><span class="line">    x_data, y_data = data</span><br><span class="line">    y_data = y_data[:, np.newaxis]          <span class="comment"># 增加一维维度</span></span><br><span class="line">    y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">    acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">    loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">    test_accs.append(acc.item())</span><br><span class="line">    test_costs.append(loss.item())</span><br><span class="line">test_loss = np.mean(test_costs)    <span class="comment"># 每轮测试的平均误差</span></span><br><span class="line">test_acc = np.mean(test_accs)      <span class="comment"># 每轮测试的平均准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Eval \t Loss：%.5f，Acc：%.5f&quot;</span> % (test_loss, test_acc))</span><br></pre></td></tr></table></figure><p>模型评估的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Eval  Loss：0.04160，Acc：0.99019</span><br></pre></td></tr></table></figure><h2 id="3-5-模型预测-2">3.5. 模型预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">model.set_state_dict(</span><br><span class="line">    paddle.load(MODEL_PATH)</span><br><span class="line">)   <span class="comment"># 载入预训练模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, (img_path, truth_lab) <span class="keyword">in</span> <span class="built_in">enumerate</span>(INFER_LIST):</span><br><span class="line">    image = data_mapper(img_path, show=<span class="literal">True</span>)        <span class="comment"># 获取预测图片</span></span><br><span class="line">    result = model(image[np.newaxis, :, :, :])</span><br><span class="line">    infer_lab = lab_dict[<span class="built_in">str</span>(np.argmax(result))]    <span class="comment"># 获取推理结果</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;图%d的真实标签：%s，预测结果：%s&quot;</span> % (idx+<span class="number">1</span>, truth_lab, infer_lab))</span><br></pre></td></tr></table></figure><p>模型预测的结果如下：</p><p><img src="https://img-blog.csdnimg.cn/76dbe4b1a7f8492697243a00017e0210.png" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图1的真实标签：Pomacentrus moluccensis，预测结果：Pomacentrus moluccensis</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/66ef1465673344bcb0104e1fbf68e088.png" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图2的真实标签：Amphiprion clarkii，预测结果：Amphiprion clarkii</span><br></pre></td></tr></table></figure><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/829907?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【VGG】口罩人脸分类</title>
      <link href="/2021/03/10/%E3%80%90VGG%E3%80%91%E5%8F%A3%E7%BD%A9%E4%BA%BA%E8%84%B8%E5%88%86%E7%B1%BB/"/>
      <url>/2021/03/10/%E3%80%90VGG%E3%80%91%E5%8F%A3%E7%BD%A9%E4%BA%BA%E8%84%B8%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 项目准备</h1><h2 id="1-1-问题导入-10">1.1. 问题导入</h2><p>新冠肺炎病毒在全球肆虐，武汉大学率先公开了口罩遮挡人脸数据集。我们从中选取了6000余张戴口罩的人脸图片和6000余张正常的人脸图片作为实验数据集，以训练改进版的VGG16模型，使其能够实现对人脸是否佩戴口罩的判定。</p><h2 id="1-2-数据集简介-8">1.2. 数据集简介</h2><p>本次实验采用的是武汉大学口罩遮挡人脸数据集（RMFD）的一部分，它包含6000余张戴口罩的人脸图片和6000余张正常的人脸图片。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/922d2a7a7e08387e6f76d2c693aeccee.png#pic_center" alt=""></p><blockquote><p>这是数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/52391">人脸口罩分类数据集 - AI Studio</a></p></blockquote><h1>2. VGG模型</h1><p><code>VGG</code>是由 Simonyan和Zisserman（2014）在<a href="https://arxiv.org/abs/1409.1556">论文</a>中提出卷积神经网络模型，其名称来源于作者所在的牛津大学视觉几何组（Visual Geometry Group）的缩写，它是2014年ILSVRC竞赛的第二名（第一名是<code>GoogLeNet</code>），但是<code>VGG</code>在多个迁移学习任务中的表现要优于<code>GoogLeNet</code>。</p><p>作者在论文中证明了小尺寸（3×3）卷积核的深层网络要优于大尺寸卷积核的浅层网络，因此<code>VGG</code>模型采用3×3的卷积核代替了其他的大尺寸卷积核。<code>VGG</code>中根据卷积核大小和卷积层数目的不同，可分为<code>A</code>、<code>A-LRN</code>、<code>B</code>、<code>C</code>、<code>D</code>、<code>E</code>共6个配置（ConvNet Configuration），其中以<code>D</code>和<code>E</code>两种配置较为常用，分别称为<code>VGG16</code>和<code>VGG19</code>。本实验使用的是<code>VGG16</code>模型（如下图<code>D</code>所示）。<br><img src="https://img-blog.csdnimg.cn/img_convert/62b9772f507d42b9d9170eecd7f32735.png#pic_center" alt=""></p><hr><h1>3. 实验步骤</h1><p><img src="https://img-blog.csdnimg.cn/20210208110405937.png#pic_center" alt=""></p><h2 id="3-0-前期准备-6">3.0. 前期准备</h2><ul><li><strong>导入模块</strong></li></ul><blockquote><p>注意：本案例仅适用于<code>PaddlePaddle 2.0+</code>版本</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageEnhance</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> metric <span class="keyword">as</span> M</span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer.lr <span class="keyword">import</span> NaturalExpDecay</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">64</span>      <span class="comment"># 每批次的样本数</span></span><br><span class="line">EPOCHS = <span class="number">8</span>           <span class="comment"># 训练轮数</span></span><br><span class="line">LOG_GAP = <span class="number">100</span>        <span class="comment"># 输出训练信息的间隔</span></span><br><span class="line"></span><br><span class="line">CLASS_DIM = <span class="number">2</span>        <span class="comment"># 图像种类</span></span><br><span class="line">LAB_DICT = &#123;         <span class="comment"># 记录标签和数字的关系</span></span><br><span class="line">    <span class="string">&quot;0&quot;</span>: <span class="string">&quot;没戴口罩&quot;</span>,</span><br><span class="line">    <span class="string">&quot;1&quot;</span>: <span class="string">&quot;戴了口罩&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">INIT_LR = <span class="number">3e-4</span>       <span class="comment"># 初始学习率</span></span><br><span class="line">LR_DECAY = <span class="number">0.6</span>       <span class="comment"># 学习率衰减率</span></span><br><span class="line"></span><br><span class="line">SRC_PATH = <span class="string">&quot;./data/data52391/Masked_Face.zip&quot;</span>    <span class="comment"># 压缩包路径</span></span><br><span class="line">DST_PATH = <span class="string">&quot;./data&quot;</span>                              <span class="comment"># 解压路径</span></span><br><span class="line">DATA_PATH = &#123;                                    <span class="comment"># 实验数据集路径</span></span><br><span class="line">    <span class="string">&quot;0&quot;</span>: DST_PATH + <span class="string">&quot;/AFDB_face_dataset&quot;</span>,        <span class="comment"># 正常人脸</span></span><br><span class="line">    <span class="string">&quot;1&quot;</span>: DST_PATH + <span class="string">&quot;/AFDB_masked_face_dataset&quot;</span>  <span class="comment"># 口罩人脸</span></span><br><span class="line">&#125;</span><br><span class="line">INFER_PATH = [<span class="string">&quot;./work/n1.jpg&quot;</span>, <span class="string">&quot;./work/n2.jpg&quot;</span>, </span><br><span class="line">              <span class="string">&quot;./work/m1.jpg&quot;</span>, <span class="string">&quot;./work/m2.jpg&quot;</span>]  <span class="comment"># 预测数据集路径</span></span><br><span class="line">MODEL_PATH = <span class="string">&quot;VGG.pdparams&quot;</span>                      <span class="comment"># 模型参数保存路径</span></span><br></pre></td></tr></table></figure><h2 id="3-1-数据准备-5">3.1. 数据准备</h2><ul><li><strong>解压数据集</strong><br>由于数据集中的数据是以压缩包的形式存放的，因此我们需要先解压数据压缩包。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(DATA_PATH[<span class="string">&quot;0&quot;</span>]) <span class="keyword">or</span> <span class="keyword">not</span> os.path.isdir(DATA_PATH[<span class="string">&quot;1&quot;</span>]):</span><br><span class="line">    z = zipfile.ZipFile(SRC_PATH, <span class="string">&quot;r&quot;</span>)   <span class="comment"># 打开压缩文件，创建zip对象</span></span><br><span class="line">    z.extractall(path=DST_PATH)          <span class="comment"># 解压zip文件至目标路径</span></span><br><span class="line">    z.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;数据集解压完成！&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>划分数据集</strong><br>我们需要按1:9比例划分测试集和训练集，分别生成两个包含数据路径和标签映射关系的列表。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_data_list</span>(<span class="params">lab_no, path</span>):   <span class="comment"># 划分path路径下的数据集</span></span><br><span class="line">    count = <span class="number">0</span>      <span class="comment"># 记录图片的数量，便于划分数据集</span></span><br><span class="line">    temp_train_list, temp_test_list = [], []   <span class="comment"># 临时存放数据集位置及类别</span></span><br><span class="line">    file_folders = os.listdir(path)            <span class="comment"># 获取path路径下所有的文件夹</span></span><br><span class="line">    <span class="keyword">for</span> folder <span class="keyword">in</span> file_folders:</span><br><span class="line">        images = os.listdir(os.path.join(path, folder))</span><br><span class="line">        <span class="keyword">for</span> img <span class="keyword">in</span> images:</span><br><span class="line">            img_path = os.path.join(path, folder, img)</span><br><span class="line">            <span class="keyword">if</span> count % <span class="number">10</span> == <span class="number">0</span>:           <span class="comment"># 按照1:9的比例划分数据集</span></span><br><span class="line">                temp_test_list.append([img_path, lab_no])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                temp_train_list.append([img_path, lab_no])</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> temp_train_list, temp_test_list</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_lt1, test_lt1 = get_data_list(<span class="number">0</span>, DATA_PATH[<span class="string">&quot;0&quot;</span>])  <span class="comment"># 划分“正常人脸”</span></span><br><span class="line">train_lt2, test_lt2 = get_data_list(<span class="number">1</span>, DATA_PATH[<span class="string">&quot;1&quot;</span>])  <span class="comment"># 划分“口罩人脸”</span></span><br><span class="line">train_list = train_lt1 + train_lt2</span><br><span class="line">test_list = test_lt1 + test_lt2</span><br></pre></td></tr></table></figure><ul><li><strong>数据增强</strong><br>由于实验模型较为复杂，直接训练容易发生过拟合，故在处理实验数据集时采用数据增强的方法扩充数据集的多样性。数据増广（Data Augmentation），即数据增强，数据增强的目的主要是减少网络的过拟合现象，通过对训练图片进行变换可以得到泛化能力更强的网络，更好地适应应用场景。本实验中用到的数据增强方法有：随机改变亮度，随机改变对比度，随机改变饱和度，随机改变清晰度，随机翻转图像，随机加高斯噪声等。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">random_brightness</span>(<span class="params">img, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变亮度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Brightness(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_contrast</span>(<span class="params">img, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变对比度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Contrast(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_color</span>(<span class="params">img, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变饱和度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Color(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_sharpness</span>(<span class="params">img, low=<span class="number">0.5</span>, high=<span class="number">1.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机改变清晰度(0.5~1.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    x = random.uniform(low, high)</span><br><span class="line">    img = ImageEnhance.Sharpness(img).enhance(x)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_flip</span>(<span class="params">img, prob=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机翻转图像(p=0.5) &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> random.random() &lt; prob:   <span class="comment"># 左右翻转</span></span><br><span class="line">        img = img.transpose(Image.FLIP_LEFT_RIGHT)</span><br><span class="line">    <span class="comment"># if random.random() &lt; prob:   # 上下翻转</span></span><br><span class="line">    <span class="comment">#     img = img.transpose(Image.FLIP_TOP_BOTTOM)</span></span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_rotate</span>(<span class="params">img, low=-<span class="number">30</span>, high=<span class="number">30</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机旋转图像(-30~30) &#x27;&#x27;&#x27;</span></span><br><span class="line">    angle = random.choice(<span class="built_in">range</span>(low, high))</span><br><span class="line">    img = img.rotate(angle)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_noise</span>(<span class="params">img, low=<span class="number">0</span>, high=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 随机加高斯噪声(0~10) &#x27;&#x27;&#x27;</span></span><br><span class="line">    img = np.asarray(img)</span><br><span class="line">    sigma = np.random.uniform(low, high)</span><br><span class="line">    noise = np.random.randn(img.shape[<span class="number">0</span>], img.shape[<span class="number">1</span>], <span class="number">3</span>) * sigma</span><br><span class="line">    img = img + np.<span class="built_in">round</span>(noise).astype(<span class="string">&#x27;uint8&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将矩阵中的所有元素值限制在0~255之间：</span></span><br><span class="line">    img[img &gt; <span class="number">255</span>], img[img &lt; <span class="number">0</span>] = <span class="number">255</span>, <span class="number">0</span></span><br><span class="line">    img = Image.fromarray(img)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_augment</span>(<span class="params">img, prob=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 叠加多种数据增强方法 &#x27;&#x27;&#x27;</span></span><br><span class="line">    opts = [random_brightness, random_contrast, random_color, random_flip,</span><br><span class="line">            random_rotate, random_noise, random_sharpness,]  <span class="comment"># 数据增强方法</span></span><br><span class="line">    random.shuffle(opts)</span><br><span class="line">    <span class="keyword">for</span> opt <span class="keyword">in</span> opts:</span><br><span class="line">        img = opt(img) <span class="keyword">if</span> random.random() &lt; prob <span class="keyword">else</span> img     <span class="comment"># 处理图像</span></span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><ul><li><strong>数据预处理</strong><br>我们需要对数据集图像进行缩放和归一化处理。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 自定义的数据集类 &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, label_list, transform, augment=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `label_list`: 标签与文件路径的映射列表</span></span><br><span class="line"><span class="string">        * `transform`: 数据处理函数</span></span><br><span class="line"><span class="string">        * `augment`: 数据增强函数（默认为空）</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(MyDataset, self).__init__()</span><br><span class="line">        random.shuffle(label_list)      <span class="comment"># 打乱映射列表</span></span><br><span class="line">        self.label_list = label_list</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.augment = augment</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 根据位序获取对应数据 &#x27;&#x27;&#x27;</span></span><br><span class="line">        img_path, label = self.label_list[index]</span><br><span class="line">        img = self.transform(img_path, self.augment)</span><br><span class="line">        <span class="keyword">return</span> img, <span class="built_in">int</span>(label)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 获取数据集样本总数 &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.label_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_mapper</span>(<span class="params">img_path, augment=<span class="literal">None</span>, show=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 图像处理函数 &#x27;&#x27;&#x27;</span></span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&quot;RGB&quot;</span>)   <span class="comment"># 以RGB模式打开图片</span></span><br><span class="line">    <span class="comment"># 将其缩放为224*224的高质量图像：</span></span><br><span class="line">    img = img.resize((<span class="number">224</span>, <span class="number">224</span>), Image.ANTIALIAS)</span><br><span class="line">    <span class="keyword">if</span> show:                  <span class="comment"># 展示图像</span></span><br><span class="line">        display(img)</span><br><span class="line">    <span class="keyword">if</span> augment <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:   <span class="comment"># 数据增强</span></span><br><span class="line">        img = augment(img)</span><br><span class="line">    <span class="comment"># 把图像变成一个numpy数组以匹配数据馈送格式：</span></span><br><span class="line">    img = np.array(img).astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">    <span class="comment"># 将图像矩阵由“rgb,rgb,rbg...”转置为“rr...,gg...,bb...”：</span></span><br><span class="line">    img = img.transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 将图像数据归一化，并转换成Tensor格式：</span></span><br><span class="line">    img = paddle.to_tensor(img / <span class="number">255.0</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = MyDataset(train_list, data_mapper, image_augment) <span class="comment"># 训练集</span></span><br><span class="line">test_dataset = MyDataset(test_list, data_mapper, augment=<span class="literal">None</span>)    <span class="comment"># 测试集</span></span><br></pre></td></tr></table></figure><ul><li><strong>定义数据提供器</strong><br>我们需要分别构建用于训练和测试的数据提供器，其中训练数据提供器是乱序、按批次提供数据的。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(train_dataset,            <span class="comment"># 训练数据集</span></span><br><span class="line">                          batch_size=BATCH_SIZE,    <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                          num_workers=<span class="number">0</span>,            <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                          shuffle=<span class="literal">True</span>,             <span class="comment"># 打乱训练数据集</span></span><br><span class="line">                          drop_last=<span class="literal">False</span>)          <span class="comment"># 不丢弃不完整的样本</span></span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(test_dataset,              <span class="comment"># 测试数据集</span></span><br><span class="line">                         batch_size=BATCH_SIZE,     <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                         num_workers=<span class="number">0</span>,             <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                         shuffle=<span class="literal">False</span>,             <span class="comment"># 不打乱测试数据集</span></span><br><span class="line">                         drop_last=<span class="literal">False</span>)           <span class="comment"># 不丢弃不完整的样本</span></span><br></pre></td></tr></table></figure><h2 id="3-2-网络配置-5">3.2. 网络配置</h2><ul><li><strong>模型改进</strong><br>原始的VGG16包含13个卷积层、5个池化层、3个全连接层，它常常被用于分类问题。由于本实验的数据集并不是特别大，而实验模型又比较复杂，因此需要改进VGG16模型。为了减少模型的复杂程度，我们选择用一层全局池化层来取代VGG16模型的前两层全连接层（模型结构如下图所示），这样可以大大减少我们需要训练的参数。这对于简化实验模型、防止出现过拟合、提升模型训练速度等，均有很大的帮助。<br><img src="https://img-blog.csdnimg.cn/b00b2dc674bc4b628073f883bec69e58.png#pic_center" alt=""></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBN2d</span>(nn.Layer):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Conv2D with BatchNorm2D and ReLU &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels: <span class="built_in">int</span>, out_channels: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">                 kernel_size: <span class="built_in">int</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_channels`: 输入通道数</span></span><br><span class="line"><span class="string">        * `out_channels`: 输出通道数</span></span><br><span class="line"><span class="string">        * `kernel_size`: 卷积核大小</span></span><br><span class="line"><span class="string">        * `stride`: 卷积运算的步长</span></span><br><span class="line"><span class="string">        * `padding`: 卷积填充的大小</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(ConvBN2d, self).__init__()</span><br><span class="line">        self.net = nn.Sequential(</span><br><span class="line">            nn.Conv2D(in_channels, out_channels, kernel_size, stride, padding),</span><br><span class="line">            nn.BatchNorm2D(out_channels),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.net(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvPool</span>(nn.Layer):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; Conv-Pool Block &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, conv_args: <span class="built_in">tuple</span>, pool_args: <span class="built_in">tuple</span>,</span></span><br><span class="line"><span class="params">                 conv_num=<span class="number">1</span>, pool_type=<span class="string">&quot;max&quot;</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `conv_args`: 卷积层参数([输入通道数,输出通道数,卷积核大小,卷积步长,填充长度])</span></span><br><span class="line"><span class="string">        * `pool_args`: 池化层参数([池化核大小,池化步长,填充长度] or [])</span></span><br><span class="line"><span class="string">        * `conv_num`: 卷积层的个数</span></span><br><span class="line"><span class="string">        * `pool_type`: 池化类型(max or avg or global)</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(ConvPool, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (1) 定义卷积层：</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(conv_num):  <span class="comment"># 定义conv_num个卷积层</span></span><br><span class="line">            conv = ConvBN2d(*conv_args)</span><br><span class="line">            conv_args[<span class="number">0</span>] = conv_args[<span class="number">1</span>]</span><br><span class="line">            self.add_sublayer(<span class="string">&quot;conv_%d&quot;</span> % i, conv)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (2) 定义池化层：</span></span><br><span class="line">        pool_type = pool_type.lower()</span><br><span class="line">        <span class="keyword">if</span> pool_type == <span class="string">&quot;max&quot;</span>:      <span class="comment"># 最大池化</span></span><br><span class="line">            pool = nn.MaxPool2D(*pool_args)</span><br><span class="line">        <span class="keyword">elif</span> pool_type == <span class="string">&quot;avg&quot;</span>:    <span class="comment"># 平均池化</span></span><br><span class="line">            pool = nn.AvgPool2D(*pool_args)</span><br><span class="line">        <span class="keyword">else</span>:                       <span class="comment"># 全局平均池化</span></span><br><span class="line">            pool = nn.AdaptiveAvgPool2D(<span class="number">1</span>)</span><br><span class="line">        self.add_sublayer(<span class="string">&quot;pool&quot;</span>, pool)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">for</span> name, sublayer <span class="keyword">in</span> self.named_children():</span><br><span class="line">            x = sublayer(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VGG</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, n_classes=<span class="number">2</span>, mtype=<span class="number">16</span>, global_pool=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_channels`: 输入的通道数</span></span><br><span class="line"><span class="string">        * `n_classes`: 输出分类数量</span></span><br><span class="line"><span class="string">        * `mtype`: VGG类型 (11 or 13 or 16 or 19)</span></span><br><span class="line"><span class="string">        * `global_pool`: 是否用全局平均池化改进VGG</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(VGG, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> mtype == <span class="number">11</span>:          <span class="comment"># Type A =&gt; VGG-11</span></span><br><span class="line">            nums = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="number">13</span>:        <span class="comment"># Type B =&gt; VGG-13</span></span><br><span class="line">            nums = [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="number">16</span>:        <span class="comment"># Type D =&gt; VGG-16</span></span><br><span class="line">            nums = [<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>]</span><br><span class="line">        <span class="keyword">elif</span> mtype == <span class="number">19</span>:        <span class="comment"># Type E =&gt; VGG-19</span></span><br><span class="line">            nums = [<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">&quot;The [mtype] must in [11, 13, 16, 19].&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.conv1 = ConvPool([in_channels, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>], nums[<span class="number">0</span>], <span class="string">&quot;max&quot;</span>)</span><br><span class="line">        self.conv2 = ConvPool([<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>], nums[<span class="number">1</span>], <span class="string">&quot;max&quot;</span>)</span><br><span class="line">        self.conv3 = ConvPool([<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>], nums[<span class="number">2</span>], <span class="string">&quot;max&quot;</span>)</span><br><span class="line">        self.conv4 = ConvPool([<span class="number">256</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>], nums[<span class="number">3</span>], <span class="string">&quot;max&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> global_pool:</span><br><span class="line">            self.conv5 = ConvPool([<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>], [], nums[<span class="number">4</span>], <span class="string">&quot;global&quot;</span>)</span><br><span class="line">            self.linear = nn.Sequential(nn.Flatten(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                                        nn.Linear(<span class="number">512</span>, n_classes))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv5 = ConvPool([<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>], [<span class="number">2</span>, <span class="number">2</span>], nums[<span class="number">4</span>], <span class="string">&quot;max&quot;</span>)</span><br><span class="line">            self.linear = nn.Sequential(nn.Flatten(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">                                        nn.Linear(<span class="number">512</span>*<span class="number">7</span>*<span class="number">7</span>, <span class="number">4096</span>),</span><br><span class="line">                                        nn.ReLU(),</span><br><span class="line">                                        nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">                                        nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">                                        nn.ReLU(),</span><br><span class="line">                                        nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">                                        nn.Linear(<span class="number">4096</span>, n_classes))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)       <span class="comment"># conv1 =&gt; 64*112*112</span></span><br><span class="line">        x = self.conv2(x)       <span class="comment"># conv2 =&gt; 128*56*56</span></span><br><span class="line">        x = self.conv3(x)       <span class="comment"># conv3 =&gt; 256*28*28</span></span><br><span class="line">        x = self.conv4(x)       <span class="comment"># conv4 =&gt; 512*14*14</span></span><br><span class="line">        x = self.conv5(x)       <span class="comment"># conv5 =&gt; 512*7*7</span></span><br><span class="line">        y = self.linear(x)      <span class="comment"># linear =&gt; n_classes</span></span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><ul><li><strong>实例化模型</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = VGG(in_channels=<span class="number">3</span>, n_classes=CLASS_DIM, </span><br><span class="line">            mtype=<span class="number">16</span>, global_pool=<span class="literal">True</span>)     <span class="comment"># VGG-16</span></span><br></pre></td></tr></table></figure><h2 id="3-3-模型训练-5">3.3. 模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">model.train()                <span class="comment"># 开启训练模式</span></span><br><span class="line">scheduler = NaturalExpDecay(</span><br><span class="line">    learning_rate=INIT_LR,</span><br><span class="line">    gamma=LR_DECAY</span><br><span class="line">)                            <span class="comment"># 定义学习率衰减器</span></span><br><span class="line">optimizer = Adam(</span><br><span class="line">    learning_rate=scheduler,</span><br><span class="line">    parameters=model.parameters()</span><br><span class="line">)                            <span class="comment"># 定义Adam优化器</span></span><br><span class="line">loss_arr, acc_arr = [], []   <span class="comment"># 用于可视化</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">        x_data, y_data = data</span><br><span class="line">        y_data = y_data[:, np.newaxis]          <span class="comment"># 增加一维维度</span></span><br><span class="line">        y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">        acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">        loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">        <span class="keyword">if</span> batch_id != <span class="number">0</span> <span class="keyword">and</span> batch_id % LOG_GAP == <span class="number">0</span>:   <span class="comment"># 定期输出训练结果</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch：%d，Batch：%3d，Loss：%.5f，Acc：%.5f&quot;</span>\</span><br><span class="line">                % (ep, batch_id, loss, acc))</span><br><span class="line">        acc_arr.append(acc.item())</span><br><span class="line">        loss_arr.append(loss.item())</span><br><span class="line">        optimizer.clear_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    scheduler.step()       <span class="comment"># 每轮衰减一次学习率</span></span><br><span class="line"></span><br><span class="line">paddle.save(model.state_dict(), MODEL_PATH)  <span class="comment"># 保存训练好的模型</span></span><br></pre></td></tr></table></figure><p>模型训练结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Epoch：0，Batch：  0，Loss：0.65380，Acc：0.59375</span><br><span class="line">Epoch：0，Batch：100，Loss：0.35155，Acc：0.76562</span><br><span class="line">Epoch：1，Batch：  0，Loss：0.10918，Acc：0.96875</span><br><span class="line">Epoch：1，Batch：100，Loss：0.17284，Acc：0.90625</span><br><span class="line">Epoch：2，Batch：  0，Loss：0.09818，Acc：0.95312</span><br><span class="line">Epoch：2，Batch：100，Loss：0.12185，Acc：0.95312</span><br><span class="line">Epoch：3，Batch：  0，Loss：0.24998，Acc：0.95312</span><br><span class="line">Epoch：3，Batch：100，Loss：0.10257，Acc：0.93750</span><br><span class="line">Epoch：4，Batch：  0，Loss：0.16910，Acc：0.98438</span><br><span class="line">Epoch：4，Batch：100，Loss：0.09855，Acc：0.98438</span><br><span class="line">Epoch：5，Batch：  0，Loss：0.06119，Acc：0.98438</span><br><span class="line">Epoch：5，Batch：100，Loss：0.09231，Acc：0.95312</span><br><span class="line">Epoch：6，Batch：  0，Loss：0.08556，Acc：0.96875</span><br><span class="line">Epoch：6，Batch：100，Loss：0.02138，Acc：1.00000</span><br><span class="line">Epoch：7，Batch：  0，Loss：0.06875，Acc：0.98438</span><br><span class="line">Epoch：7，Batch：100，Loss：0.05027，Acc：0.98438</span><br></pre></td></tr></table></figure><ul><li><strong>可视化训练过程</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=[<span class="number">10</span>, <span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练误差图像：</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">211</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&quot;Loss&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax1.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(loss_arr)), loss_arr, color=<span class="string">&quot;orangered&quot;</span>)</span><br><span class="line">ax1.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练准确率图像：</span></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">212</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&quot;Training Steps&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&quot;Accuracy&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax2.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(acc_arr)), acc_arr, color=<span class="string">&quot;dodgerblue&quot;</span>)</span><br><span class="line">ax2.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ea2e08546ae2473bb168b777a41db252.png#pic_center" alt=""></p><h2 id="3-4-模型评估-5">3.4. 模型评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">test_costs, test_accs = [], []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):</span><br><span class="line">    x_data, y_data = data</span><br><span class="line">    y_data = y_data[:, np.newaxis]          <span class="comment"># 增加一维维度</span></span><br><span class="line">    y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">    acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">    loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">    test_accs.append(acc.item())</span><br><span class="line">    test_costs.append(loss.item())</span><br><span class="line">test_loss = np.mean(test_costs)    <span class="comment"># 每轮测试的平均误差</span></span><br><span class="line">test_acc = np.mean(test_accs)      <span class="comment"># 每轮测试的平均准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Eval \t Loss：%.5f，Acc：%.5f&quot;</span> % (test_loss, test_acc))</span><br></pre></td></tr></table></figure><p>模型评估结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Eval  Loss：0.03680，Acc：0.98849</span><br></pre></td></tr></table></figure><h2 id="3-5-模型预测-5">3.5. 模型预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">model.set_state_dict(</span><br><span class="line">    paddle.load(MODEL_PATH)</span><br><span class="line">)   <span class="comment"># 载入预训练模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx, img_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(INFER_PATH):</span><br><span class="line">    image = data_mapper(img_path, show=<span class="literal">True</span>)  <span class="comment"># 获取预测图片</span></span><br><span class="line">    image = image[np.newaxis, :, :, :]</span><br><span class="line">    result = model(image).numpy()             <span class="comment"># 开始模型预测</span></span><br><span class="line">    lab = <span class="built_in">str</span>(np.argmax(result))              <span class="comment"># 获取result数组最大值的索引</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;图%d的预测结果：%s&quot;</span> % (idx+<span class="number">1</span>, LAB_DICT[lab]))</span><br></pre></td></tr></table></figure><p>模型预测结果如下：</p><p><img src="https://img-blog.csdnimg.cn/20210319233343385.jpg" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图1的预测结果为：没戴口罩</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210319233343417.jpg" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图2的预测结果为：没戴口罩</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210319233343398.jpg" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图3的预测结果为：戴了口罩</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210211232816712.png" alt=""></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">图4的预测结果为：戴了口罩</span><br></pre></td></tr></table></figure><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/844191?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【AlexNet】数字手势识别</title>
      <link href="/2021/02/12/%E3%80%90AlexNet%E3%80%91%E6%95%B0%E5%AD%97%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB/"/>
      <url>/2021/02/12/%E3%80%90AlexNet%E3%80%91%E6%95%B0%E5%AD%97%E6%89%8B%E5%8A%BF%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 项目准备</h1><h2 id="1-1-问题导入">1.1. 问题导入</h2><p>图像分类是根据图像的语义信息将不同类别图像区分开来，是计算机视觉中重要的基本问题。本实验将使用经典神经网络模型AlexNet预测手势图片所表示的数字。</p><h2 id="1-2-数据集简介">1.2. 数据集简介</h2><p>本次实验使用的数据集是由土耳其一所中学制作，数据集由<code>Main</code>文件夹中的训练/测试数据集和<code>Infer</code>文件夹中的预测数据集组成，包含<code>0-9</code>共10种数字的手势图片，实验图片都是大小为100 * 100像素、RGB格式的图像。</p><blockquote><p>这是数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/51418">手势识别数据集 - AI Studio</a></p></blockquote><hr><h1>2. AlexNet模型</h1><p>得益于硬件的发展（GPU的使用等）和各种算法的改进，在2012的ImageNet图像分类竞赛中，<code>AlexeNet</code>模型以远超第二名的成绩夺冠。<code>AlexNet</code>模型是Hinton及其学生Alex Krizhevsky等人（2012）在<a href="https://dl.acm.org/doi/pdf/10.1145/3065386">论文</a>中提出的网络模型，也是在那年之后，更多的更深的神经网络被提出，卷积神经网络乃至深度学习重新引起了广泛的关注。<code>AlexNet</code>模型的网络结构如下图所示。</p><p><img src="https://img-blog.csdnimg.cn/5891ba3ec789474a817b876eebd1b9d9.webp#pic_center" alt=""></p><hr><h1>3. 实验步骤</h1><p><img src="https://img-blog.csdnimg.cn/20210208110405937.png#pic_center" alt=""></p><h2 id="3-0-前期准备">3.0. 前期准备</h2><ul><li><strong>导入模块</strong></li></ul><blockquote><p>注意：本案例仅适用于<code>PaddlePaddle 2.0+</code>版本</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> metric <span class="keyword">as</span> M</span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer.lr <span class="keyword">import</span> NaturalExpDecay</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">32</span>      <span class="comment"># 每批次的样本数</span></span><br><span class="line">CLASS_DIM = <span class="number">10</span>       <span class="comment"># 手势种类数</span></span><br><span class="line">EPOCHS = <span class="number">10</span>          <span class="comment"># 训练轮数</span></span><br><span class="line">LOG_GAP = <span class="number">30</span>         <span class="comment"># 输出训练信息的间隔</span></span><br><span class="line"></span><br><span class="line">INIT_LR = <span class="number">3e-4</span>       <span class="comment"># 初始学习率</span></span><br><span class="line">LR_DECAY = <span class="number">0.5</span>       <span class="comment"># 学习率衰减率</span></span><br><span class="line"></span><br><span class="line">SRC_PATH = <span class="string">&quot;./data/Gestures.zip&quot;</span>      <span class="comment"># 压缩包路径</span></span><br><span class="line">DST_PATH = <span class="string">&quot;./data&quot;</span>                   <span class="comment"># 解压路径</span></span><br><span class="line">DATA_PATH = DST_PATH + <span class="string">&quot;/Main&quot;</span>        <span class="comment"># 实验数据集路径</span></span><br><span class="line">INFER_PATH = DST_PATH + <span class="string">&quot;/Infer&quot;</span>      <span class="comment"># 预测数据集路径</span></span><br><span class="line">MODEL_PATH = <span class="string">&quot;AlexNet.pdparams&quot;</span>       <span class="comment"># 模型参数保存路径</span></span><br></pre></td></tr></table></figure><h2 id="3-1-数据准备">3.1. 数据准备</h2><ul><li><strong>解压数据集</strong><br>由于数据集中的数据是以压缩包的形式存放的，因此我们需要先解压数据压缩包。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(DATA_PATH) <span class="keyword">or</span> <span class="keyword">not</span> os.path.isdir(INFER_PATH):</span><br><span class="line">    z = zipfile.ZipFile(SRC_PATH, <span class="string">&quot;r&quot;</span>)   <span class="comment"># 打开压缩文件，创建zip对象</span></span><br><span class="line">    z.extractall(path=DST_PATH)          <span class="comment"># 解压zip文件至目标路径</span></span><br><span class="line">    z.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;数据集解压完成！&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>划分数据集</strong><br>我们需要按1:9比例划分测试集和训练集，分别生成两个包含数据路径和标签映射关系的列表。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_list, test_list = [], []           <span class="comment"># 存放数据的路径及标签的映射关系</span></span><br><span class="line">file_folders = os.listdir(DATA_PATH)     <span class="comment"># 统计数据集下的文件夹</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> folder <span class="keyword">in</span> file_folders:</span><br><span class="line">    imgs = os.listdir(os.path.join(DATA_PATH, folder))</span><br><span class="line">    <span class="keyword">for</span> idx, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(imgs):</span><br><span class="line">        path = os.path.join(DATA_PATH, folder, img)</span><br><span class="line">        <span class="keyword">if</span> idx % <span class="number">10</span> == <span class="number">0</span>:      <span class="comment"># 按照1:9的比例划分数据集</span></span><br><span class="line">            test_list.append([path, folder])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            train_list.append([path, folder])</span><br></pre></td></tr></table></figure><ul><li><strong>数据预处理</strong><br>我们需要对数据集图像进行缩放和归一化处理。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 自定义的数据集类 &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, label_list, transform</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `label_list`: 标签与文件路径的映射列表</span></span><br><span class="line"><span class="string">        * `transform`：数据处理函数</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(MyDataset, self).__init__()</span><br><span class="line">        random.shuffle(label_list)      <span class="comment"># 打乱映射列表</span></span><br><span class="line">        self.label_list = label_list</span><br><span class="line">        self.transform = transform        </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 根据位序获取对应数据 &#x27;&#x27;&#x27;</span></span><br><span class="line">        img_path, label = self.label_list[index]</span><br><span class="line">        img = self.transform(img_path)</span><br><span class="line">        <span class="keyword">return</span> img, <span class="built_in">int</span>(label)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 获取数据集样本总数 &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.label_list)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_mapper</span>(<span class="params">img_path, show=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 图像处理函数 &#x27;&#x27;&#x27;</span></span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">    <span class="keyword">if</span> show:     <span class="comment"># 展示图像</span></span><br><span class="line">        display(img)</span><br><span class="line">    <span class="comment"># 将其缩放为224*224的高质量图像：</span></span><br><span class="line">    img = img.resize((<span class="number">224</span>, <span class="number">224</span>), Image.ANTIALIAS)</span><br><span class="line">    <span class="comment"># 把图像变成一个numpy数组以匹配数据馈送格式：</span></span><br><span class="line">    img = np.array(img).astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">    <span class="comment"># 将图像矩阵由“rgb,rgb,rbg...”转置为“rr...,gg...,bb...”：</span></span><br><span class="line">    img = img.transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 将图像数据归一化，并转换成Tensor格式：</span></span><br><span class="line">    img = paddle.to_tensor(img / <span class="number">255</span>)</span><br><span class="line">    <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = MyDataset(train_list, data_mapper)  <span class="comment"># 训练集</span></span><br><span class="line">test_dataset = MyDataset(test_list, data_mapper)    <span class="comment"># 测试集</span></span><br></pre></td></tr></table></figure><ul><li><strong>定义数据提供器</strong><br>我们需要分别构建用于训练和测试的数据提供器，其中训练数据提供器是乱序、按批次提供数据的。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(train_dataset,            <span class="comment"># 训练数据集</span></span><br><span class="line">                          batch_size=BATCH_SIZE,    <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                          num_workers=<span class="number">0</span>,            <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                          shuffle=<span class="literal">True</span>,             <span class="comment"># 打乱训练数据集</span></span><br><span class="line">                          drop_last=<span class="literal">False</span>)          <span class="comment"># 不丢弃不完整的样本</span></span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(test_dataset,              <span class="comment"># 测试数据集</span></span><br><span class="line">                         batch_size=BATCH_SIZE,     <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                         num_workers=<span class="number">0</span>,             <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                         shuffle=<span class="literal">False</span>,             <span class="comment"># 不打乱测试数据集</span></span><br><span class="line">                         drop_last=<span class="literal">False</span>)           <span class="comment"># 不丢弃不完整的样本</span></span><br></pre></td></tr></table></figure><h2 id="3-2-网络配置">3.2. 网络配置</h2><p><code>AlexNet</code>模型网络结构如下图所示：<br><img src="https://img-blog.csdnimg.cn/38e8240adf0c474eaaaf5a3c692f2604.png#pic_center" alt=""></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">3</span>, n_classes=<span class="number">10</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_channels`: 输入的通道数</span></span><br><span class="line"><span class="string">        * `n_classes`: 输出分类数量</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        <span class="comment"># Conv2D(输入通道数,输出通道数,卷积核大小,卷积步长,填充长度)</span></span><br><span class="line">        <span class="comment"># MaxPool2D(池化核大小,池化步长)</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2D(in_channels, <span class="number">96</span>, <span class="number">11</span>, stride=<span class="number">4</span>, padding=<span class="number">2</span>)</span><br><span class="line">        self.pool1 = nn.MaxPool2D(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2D(<span class="number">96</span>, <span class="number">256</span>, <span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>)</span><br><span class="line">        self.pool2 = nn.MaxPool2D(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv3 = nn.Conv2D(<span class="number">256</span>, <span class="number">384</span>, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv4 = nn.Conv2D(<span class="number">384</span>, <span class="number">384</span>, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv5 = nn.Conv2D(<span class="number">384</span>, <span class="number">256</span>, <span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.pool3 = nn.MaxPool2D(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">256</span>*<span class="number">6</span>*<span class="number">6</span>, <span class="number">4096</span>)</span><br><span class="line">        self.drop1 = nn.Dropout(<span class="number">0.25</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>)</span><br><span class="line">        self.drop2 = nn.Dropout(<span class="number">0.25</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">4096</span>, n_classes)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  <span class="comment"># 前向传播参数，连接各层组成神经网络</span></span><br><span class="line">        x = F.relu( self.conv1(x) )</span><br><span class="line">        x = self.pool1(x)</span><br><span class="line">        x = F.relu( self.conv2(x) )</span><br><span class="line">        x = self.pool2(x)</span><br><span class="line">        x = F.relu( self.conv3(x) )</span><br><span class="line">        x = F.relu( self.conv4(x) )</span><br><span class="line">        x = F.relu( self.conv5(x) )</span><br><span class="line">        x = self.pool3(x)</span><br><span class="line">        x = paddle.flatten(x, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        x = F.relu( self.fc1(x) )</span><br><span class="line">        x = self.drop1(x)</span><br><span class="line">        x = F.relu( self.fc2(x) )</span><br><span class="line">        x = self.drop2(x)</span><br><span class="line">        y = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><ul><li><strong>实例化模型</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = AlexNet(in_channels=<span class="number">3</span>, n_classes=CLASS_DIM)</span><br></pre></td></tr></table></figure><h2 id="3-3-模型训练">3.3. 模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">model.train()                <span class="comment"># 开启训练模式</span></span><br><span class="line">scheduler = NaturalExpDecay(</span><br><span class="line">    learning_rate=INIT_LR,</span><br><span class="line">    gamma=LR_DECAY</span><br><span class="line">)                            <span class="comment"># 定义学习率衰减器</span></span><br><span class="line">optimizer = Adam(</span><br><span class="line">    learning_rate=scheduler,</span><br><span class="line">    parameters=model.parameters()</span><br><span class="line">)                            <span class="comment"># 定义Adam优化器</span></span><br><span class="line">loss_arr, acc_arr = [], []   <span class="comment"># 用于可视化</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">        x_data, y_data = data</span><br><span class="line">        y_data = y_data[:, np.newaxis]          <span class="comment"># 增加一维维度</span></span><br><span class="line">        y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">        acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">        loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">        <span class="keyword">if</span> batch_id != <span class="number">0</span> <span class="keyword">and</span> batch_id % LOG_GAP == <span class="number">0</span>:   <span class="comment"># 定期输出训练结果</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch：%d，Batch：%3d，Loss：%.5f，Acc：%.5f&quot;</span>\</span><br><span class="line">                % (ep, batch_id, loss, acc))</span><br><span class="line">        acc_arr.append(acc.item())</span><br><span class="line">        loss_arr.append(loss.item())</span><br><span class="line">        optimizer.clear_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    scheduler.step()       <span class="comment"># 每轮衰减一次学习率</span></span><br><span class="line"></span><br><span class="line">paddle.save(model.state_dict(), MODEL_PATH)  <span class="comment"># 保存训练好的模型</span></span><br></pre></td></tr></table></figure><p>模型训练结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch：0，Batch：  0，Loss：2.70293，Acc：0.06250</span><br><span class="line">Epoch：0，Batch： 30，Loss：2.30669，Acc：0.18750</span><br><span class="line">Epoch：1，Batch：  0，Loss：2.17180，Acc：0.15625</span><br><span class="line">Epoch：1，Batch： 30，Loss：1.20216，Acc：0.53125</span><br><span class="line">Epoch：2，Batch：  0，Loss：0.83113，Acc：0.75000</span><br><span class="line">Epoch：2，Batch： 30，Loss：0.42846，Acc：0.78125</span><br><span class="line">Epoch：3，Batch：  0，Loss：0.17984，Acc：0.96875</span><br><span class="line">Epoch：3，Batch： 30，Loss：0.24534，Acc：0.90625</span><br><span class="line">Epoch：4，Batch：  0，Loss：0.23818，Acc：0.93750</span><br><span class="line">Epoch：4，Batch： 30，Loss：0.28972，Acc：0.84375</span><br><span class="line">Epoch：5，Batch：  0，Loss：0.07945，Acc：0.96875</span><br><span class="line">Epoch：5，Batch： 30，Loss：0.07204，Acc：0.96875</span><br><span class="line">Epoch：6，Batch：  0，Loss：0.08238，Acc：0.96875</span><br><span class="line">Epoch：6，Batch： 30，Loss：0.09043，Acc：0.96875</span><br><span class="line">Epoch：7，Batch：  0，Loss：0.06805，Acc：0.96875</span><br><span class="line">Epoch：7，Batch： 30，Loss：0.02860，Acc：1.00000</span><br><span class="line">Epoch：8，Batch：  0，Loss：0.09906，Acc：0.96875</span><br><span class="line">Epoch：8，Batch： 30，Loss：0.26927，Acc：0.96875</span><br><span class="line">Epoch：9，Batch：  0，Loss：0.02094，Acc：1.00000</span><br><span class="line">Epoch：9，Batch： 30，Loss：0.04960，Acc：0.96875</span><br></pre></td></tr></table></figure><ul><li><strong>可视化训练过程</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=[<span class="number">10</span>, <span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练误差图像：</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">211</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&quot;Loss&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax1.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(loss_arr)), loss_arr, color=<span class="string">&quot;orangered&quot;</span>)</span><br><span class="line">ax1.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练准确率图像：</span></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">212</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&quot;Training Steps&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&quot;Accuracy&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax2.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(acc_arr)), acc_arr, color=<span class="string">&quot;dodgerblue&quot;</span>)</span><br><span class="line">ax2.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/62e1ca8a45b645ff873d40b74b1c5ff7.png#pic_center" alt=""></p><h2 id="3-4-模型评估">3.4. 模型评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">test_costs, test_accs = [], []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):</span><br><span class="line">    x_data, y_data = data</span><br><span class="line">    y_data = y_data[:, np.newaxis]          <span class="comment"># 增加一维维度</span></span><br><span class="line">    y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">    acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">    loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">    test_accs.append(acc.item())</span><br><span class="line">    test_costs.append(loss.item())</span><br><span class="line">test_loss = np.mean(test_costs)    <span class="comment"># 每轮测试的平均误差</span></span><br><span class="line">test_acc = np.mean(test_accs)      <span class="comment"># 每轮测试的平均准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Eval \t Loss：%.5f，Acc：%.5f&quot;</span> % (test_loss, test_acc))</span><br></pre></td></tr></table></figure><p>模型评估结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Eval  Loss：0.10308，Acc：0.96429</span><br></pre></td></tr></table></figure><h2 id="3-5-模型预测">3.5. 模型预测</h2><ul><li><strong>预处理预测数据</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">truth_lab = random.randint(<span class="number">0</span>, <span class="number">9</span>)                        <span class="comment"># 预测图片的真实标签</span></span><br><span class="line">infer_path = INFER_PATH + <span class="string">&#x27;/infer_%d.JPG&#x27;</span> % truth_lab   <span class="comment"># 预测图片的路径</span></span><br><span class="line">infer_img = data_mapper(infer_path, show=<span class="literal">True</span>)          <span class="comment"># 获取预测图片</span></span><br><span class="line">infer_img = infer_img[np.newaxis, :, :, :]              <span class="comment"># 为图像数组增加一维</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210211135246733.png" alt=""></p><ul><li><strong>载入模型并开始预测</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">model.set_state_dict(</span><br><span class="line">    paddle.load(MODEL_PATH)</span><br><span class="line">)   <span class="comment"># 载入预训练模型参数</span></span><br><span class="line"></span><br><span class="line">result = model(infer_img)</span><br><span class="line">infer_lab = np.argmax(result)   <span class="comment"># 返回数组result中的最大值的索引值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;真实标签：%d，预测结果：%d&quot;</span> % (truth_lab, infer_lab))</span><br></pre></td></tr></table></figure><p>模型预测结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">该图片的真实标签为7，模型预测结果为7</span><br></pre></td></tr></table></figure><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/753862?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【LeNet5】简单车牌识别</title>
      <link href="/2020/09/10/%E3%80%90LeNet5%E3%80%91%E7%AE%80%E5%8D%95%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB/"/>
      <url>/2020/09/10/%E3%80%90LeNet5%E3%80%91%E7%AE%80%E5%8D%95%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 项目准备</h1><h2 id="1-1-问题导入-9">1.1. 问题导入</h2><p>本次实践是一个多分类任务，需要将照片中的每个字符分别进行识别，我们将借助CV2模块完成对车牌图像逐字符划分，然后训练卷积神经网络模型LeNet5完成对车牌的识别。</p><p><img src="https://img-blog.csdnimg.cn/79fe26773c2c4ebb91c04ec4ccfe9ea9.png#pic_center" alt=""></p><h2 id="1-2-数据集简介-7">1.2. 数据集简介</h2><p>实验数据集中有65个文件夹，包含数字 (0-9)、大写字母 (A-Z) 以及各省简称，每个文件夹存放一类图片，所有的图片均为20 * 20像素的灰度图像。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/14960b16959204c3e2b473410a46dda1.png#pic_center" alt=""></p><blockquote><p>这是数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/23617">车牌识别数据集 - AI Studio</a></p></blockquote><hr><h1>2. LeNet5模型</h1><h2 id="2-1-卷积神经网络">2.1. 卷积神经网络</h2><p>本实验使用的模型属于卷积神经网络模型（Convolutional Neural Network，CNN）。一个卷积神经网络通常包括输入层、输出层和多个隐藏层，而隐藏层通常包括卷积层、池化层和全连接层等。<br><img src="https://img-blog.csdnimg.cn/76c6853855f64216853ccc5cadfdcea7.png#pic_center" alt=""></p><p>在卷积运算和池化运算中，如果输入维度为$N$，卷积核或池化核的大小为$K$，运算步长为$S$，填充长度为$P$，那么输出维度为$⌊\frac{(N-K+2P)}{S}⌋ + 1$。并且在卷积运算中，卷积核的数量与输出通道数相等。</p><h2 id="2-2-模型介绍-2">2.2. 模型介绍</h2><p><code>LeNet-5</code>是Yann LeCun（1998）在<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">论文</a>中提出来的，是一种用于手写体字符识别的、结构简单、非常高效的卷积神经网络。<code>LeNet-5</code>大体上由提取特征的三个卷积层和两个分类的全连接层组成，在卷积层之间均插入了最大池化层来缩小特征图，以便于后面的网络层提取更大尺度的特征，并且卷积层和全连接层均采用Sigmoid激活函数（现常用ReLU作为激活函数），其网络结构如下图所示。</p><p><img src="https://img-blog.csdnimg.cn/a008f953269941a78d35a6a8db692fb3.png#pic_center" alt=""></p><hr><h1>3. 实验步骤</h1><p><img src="https://img-blog.csdnimg.cn/20210208110405937.png#pic_center" alt=""></p><h2 id="3-0-前期准备-5">3.0. 前期准备</h2><ul><li><strong>导入模块</strong></li></ul><blockquote><p>注意：本案例仅适用于<code>PaddlePaddle 2.0+</code>版本</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2              <span class="comment"># 在本项目中，它主要用来分割图像</span></span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> metric <span class="keyword">as</span> M</span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> paddle.vision <span class="keyword">import</span> transforms <span class="keyword">as</span> T</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">128</span>               <span class="comment"># 每批次的样本数</span></span><br><span class="line">INIT_LR = <span class="number">1e-4</span>                 <span class="comment"># 初始学习率</span></span><br><span class="line">EPOCHS = <span class="number">25</span>                    <span class="comment"># 训练轮数</span></span><br><span class="line">LOG_GAP = <span class="number">100</span>                  <span class="comment"># 输出训练信息的间隔</span></span><br><span class="line"></span><br><span class="line">SRC_PATH = <span class="string">&quot;./data/characterData.zip&quot;</span>     <span class="comment"># 压缩包路径</span></span><br><span class="line">DATA_PATH = <span class="string">&quot;./data/dataset&quot;</span>              <span class="comment"># 数据集路径</span></span><br><span class="line">INFER_PATH = <span class="string">&quot;./data/infer_license.png&quot;</span>   <span class="comment"># 预测图片路径</span></span><br><span class="line">TEMP_PATH = <span class="string">&quot;./data/infer&quot;</span>                <span class="comment"># 临时图片路径</span></span><br><span class="line">MODEL_PATH = <span class="string">&quot;LeNet5.pdparams&quot;</span>            <span class="comment"># 模型参数保存路径</span></span><br></pre></td></tr></table></figure><h2 id="3-1-数据准备-4">3.1. 数据准备</h2><ul><li><strong>解压数据集</strong><br>由于数据集中的数据是以压缩包的形式存放的，因此我们需要先解压数据压缩包。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(DATA_PATH):</span><br><span class="line">    z = zipfile.ZipFile(SRC_PATH, <span class="string">&#x27;r&#x27;</span>)      <span class="comment"># 打开Zip文件，创建Zip对象</span></span><br><span class="line">    z.extractall(path=DATA_PATH)            <span class="comment"># 解压Zip文件至DATA_PATH</span></span><br><span class="line">    shutil.rmtree(DATA_PATH + <span class="string">&quot;/__MACOSX&quot;</span>)  <span class="comment"># 删除无关文件</span></span><br><span class="line">    z.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;数据集解压完成！&quot;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>划分数据集</strong><br>我们需要按1:9比例划分测试集和训练集，分别生成两个包含数据路径和标签映射关系的列表。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">train_list, test_list = [], []           <span class="comment"># 存放数据的路径及标签的映射关系</span></span><br><span class="line">char_num, label_dict = <span class="number">0</span>, &#123;&#125;             <span class="comment"># 方便字符在整型和字符型之间转换</span></span><br><span class="line">file_folders = os.listdir(DATA_PATH)     <span class="comment"># 统计数据集下的文件夹</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> folder <span class="keyword">in</span> file_folders:</span><br><span class="line">    label_dict[<span class="built_in">str</span>(char_num)] = folder   <span class="comment"># 记录标签和代号的对应关系</span></span><br><span class="line">    imgs = os.listdir(os.path.join(DATA_PATH, folder))</span><br><span class="line">    <span class="keyword">for</span> idx, img <span class="keyword">in</span> <span class="built_in">enumerate</span>(imgs):</span><br><span class="line">        img_path = os.path.join(DATA_PATH, folder, img)</span><br><span class="line">        value = [img_path, char_num]</span><br><span class="line">        <span class="keyword">if</span> idx % <span class="number">10</span> == <span class="number">0</span>:      <span class="comment"># 按照1:9的比例划分数据集</span></span><br><span class="line">            test_list.append(value)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            train_list.append(value)</span><br><span class="line">    char_num += <span class="number">1</span></span><br></pre></td></tr></table></figure><ul><li><strong>数据预处理</strong><br>我们需要先定义一个数据集类，接着对数据集图像进行缩放和归一化处理。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; 自定义的数据集类 &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, label_list, transform=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `label_list`: 标签与文件路径的映射列表</span></span><br><span class="line"><span class="string">        * `transform`：数据处理函数</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(MyDataset, self).__init__()</span><br><span class="line">        random.shuffle(label_list)      <span class="comment"># 打乱映射列表</span></span><br><span class="line">        self.label_list = label_list</span><br><span class="line">        self.transform = transform</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 根据位序获取对应数据 &#x27;&#x27;&#x27;</span></span><br><span class="line">        img_path, label = self.label_list[index]</span><br><span class="line">        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)</span><br><span class="line">        image = image.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            image = self.transform(image)</span><br><span class="line">        image = paddle.to_tensor(image)</span><br><span class="line">        <span class="keyword">return</span> image, <span class="built_in">int</span>(label)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27; 获取数据集样本总数 &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.label_list)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">transform = T.Compose([</span><br><span class="line">    T.Resize(size=(<span class="number">32</span>, <span class="number">32</span>)),                                   <span class="comment"># 缩放大小</span></span><br><span class="line">    T.Normalize(mean=[<span class="number">127.5</span>], std=[<span class="number">127.5</span>], data_format=<span class="string">&#x27;CHW&#x27;</span>)  <span class="comment"># 归一化</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_dataset = MyDataset(train_list, transform)  <span class="comment"># 训练集</span></span><br><span class="line">test_dataset = MyDataset(test_list, transform)    <span class="comment"># 测试集</span></span><br></pre></td></tr></table></figure><ul><li><strong>定义数据提供器</strong><br>我们需要分别构建用于训练和测试的数据提供器，其中训练数据提供器是乱序、按批次提供数据的。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(train_dataset,            <span class="comment"># 训练数据集</span></span><br><span class="line">                          batch_size=BATCH_SIZE,    <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                          num_workers=<span class="number">1</span>,            <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                          shuffle=<span class="literal">True</span>,             <span class="comment"># 打乱训练数据集</span></span><br><span class="line">                          drop_last=<span class="literal">False</span>)          <span class="comment"># 不丢弃不完整的样本</span></span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(test_dataset,              <span class="comment"># 测试数据集</span></span><br><span class="line">                         batch_size=BATCH_SIZE,     <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                         num_workers=<span class="number">1</span>,             <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                         shuffle=<span class="literal">False</span>,             <span class="comment"># 不打乱测试数据集</span></span><br><span class="line">                         drop_last=<span class="literal">False</span>)           <span class="comment"># 不丢弃不完整的样本</span></span><br></pre></td></tr></table></figure><h2 id="3-2-网络配置-4">3.2. 网络配置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet5</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels=<span class="number">1</span>, n_classes=<span class="number">10</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        * `in_channels`: 输入的通道数</span></span><br><span class="line"><span class="string">        * `n_classes`: 输出分类数量</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(LeNet5, self).__init__()</span><br><span class="line">        <span class="comment"># Conv2D(输入通道数,输出通道数,卷积核大小,卷积步长)</span></span><br><span class="line">        <span class="comment"># MaxPool2D(池化核大小,池化步长)</span></span><br><span class="line">        self.conv1 = nn.Conv2D(in_channels, <span class="number">6</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.pool1 = nn.MaxPool2D(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2D(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.pool2 = nn.MaxPool2D(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv3 = nn.Conv2D(<span class="number">16</span>, <span class="number">120</span>, <span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">84</span>, n_classes)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.conv1(x))  <span class="comment"># C1输出维度为28*28*6</span></span><br><span class="line">        x = self.pool1(x)          <span class="comment"># S2输出维度为14*14*6</span></span><br><span class="line">        x = F.relu(self.conv2(x))  <span class="comment"># C3输出维度为10*10*6</span></span><br><span class="line">        x = self.pool2(x)          <span class="comment"># S4输出维度为5*5*16</span></span><br><span class="line">        x = F.relu(self.conv3(x))  <span class="comment"># C5输出维度为120</span></span><br><span class="line">        x = paddle.flatten(x, <span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))    <span class="comment"># F6输出维度为84</span></span><br><span class="line">        x = F.dropout(x, p=<span class="number">0.25</span>)</span><br><span class="line">        y = self.fc2(x)            <span class="comment"># F7输出维度为10</span></span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure><ul><li><strong>模型实例化</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = LeNet5(in_channels=<span class="number">1</span>, n_classes=char_num)</span><br></pre></td></tr></table></figure><h2 id="3-3-模型训练-4">3.3. 模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">model.train()                <span class="comment"># 开启训练模式</span></span><br><span class="line">opt = Adam(learning_rate=INIT_LR,</span><br><span class="line">           parameters=model.parameters())  <span class="comment"># 定义Adam优化器</span></span><br><span class="line">loss_arr, acc_arr = [], []   <span class="comment"># 用于可视化</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">        x_data, y_data = data</span><br><span class="line">        y_data = y_data[:, np.newaxis]          <span class="comment"># 增加一维维度</span></span><br><span class="line">        y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">        acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">        loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">        <span class="keyword">if</span> batch_id != <span class="number">0</span> <span class="keyword">and</span> batch_id % LOG_GAP == <span class="number">0</span>:   <span class="comment"># 定期输出训练结果</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch：%d，Batch：%3d，Loss：%.5f，Acc：%.5f&quot;</span>\</span><br><span class="line">                % (ep, batch_id, loss, acc))</span><br><span class="line">        acc_arr.append(acc.item())</span><br><span class="line">        loss_arr.append(loss.item())</span><br><span class="line">        opt.clear_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br><span class="line"></span><br><span class="line">paddle.save(model.state_dict(), MODEL_PATH)  <span class="comment"># 保存训练好的模型</span></span><br></pre></td></tr></table></figure><p>模型训练结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch：0，Batch：100，Loss：0.93938，Acc：0.77344</span><br><span class="line">Epoch：1，Batch：100，Loss：0.45156，Acc：0.88281</span><br><span class="line">Epoch：2，Batch：100，Loss：0.37834，Acc：0.90625</span><br><span class="line">Epoch：3，Batch：100，Loss：0.33006，Acc：0.92188</span><br><span class="line">Epoch：4，Batch：100，Loss：0.28153，Acc：0.92969</span><br><span class="line">Epoch：5，Batch：100，Loss：0.14206，Acc：0.96875</span><br><span class="line">Epoch：6，Batch：100，Loss：0.17640，Acc：0.94531</span><br><span class="line">Epoch：7，Batch：100，Loss：0.14656，Acc：0.97656</span><br><span class="line">Epoch：8，Batch：100，Loss：0.17134，Acc：0.96875</span><br><span class="line">Epoch：9，Batch：100，Loss：0.13322，Acc：0.95312</span><br><span class="line">Epoch：10，Batch：100，Loss：0.10637，Acc：0.96875</span><br><span class="line">Epoch：11，Batch：100，Loss：0.06380，Acc：0.97656</span><br><span class="line">Epoch：12，Batch：100，Loss：0.06698，Acc：0.97656</span><br><span class="line">Epoch：13，Batch：100，Loss：0.01808，Acc：1.00000</span><br><span class="line">Epoch：14，Batch：100，Loss：0.03210，Acc：0.99219</span><br><span class="line">Epoch：15，Batch：100，Loss：0.01909，Acc：1.00000</span><br><span class="line">Epoch：16，Batch：100，Loss：0.06952，Acc：0.97656</span><br><span class="line">Epoch：17，Batch：100，Loss：0.01585，Acc：1.00000</span><br><span class="line">Epoch：18，Batch：100，Loss：0.03883，Acc：0.98438</span><br><span class="line">Epoch：19，Batch：100，Loss：0.01998，Acc：1.00000</span><br></pre></td></tr></table></figure><ul><li><strong>可视化训练过程</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=[<span class="number">10</span>, <span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练误差图像：</span></span><br><span class="line">ax1 = fig.add_subplot(<span class="number">211</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&quot;Loss&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax1.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(loss_arr)), loss_arr, color=<span class="string">&quot;orangered&quot;</span>)</span><br><span class="line">ax1.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练准确率图像：</span></span><br><span class="line">ax2 = fig.add_subplot(<span class="number">212</span>, facecolor=<span class="string">&quot;#E8E8F8&quot;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&quot;Training Steps&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&quot;Accuracy&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.tick_params(labelsize=<span class="number">14</span>)</span><br><span class="line">ax2.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(acc_arr)), acc_arr, color=<span class="string">&quot;dodgerblue&quot;</span>)</span><br><span class="line">ax2.grid(linewidth=<span class="number">1.5</span>, color=<span class="string">&quot;white&quot;</span>)  <span class="comment"># 显示网格</span></span><br><span class="line"></span><br><span class="line">fig.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line">plt.close()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/1007325d1d264b4e9d892581b97e4f6e.png#pic_center" alt=""></p><h2 id="3-4-模型评估-4">3.4. 模型评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">test_costs, test_accs = [], []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):</span><br><span class="line">    x_data, y_data = data</span><br><span class="line">    y_data = y_data[:, np.newaxis]          <span class="comment"># 增加一维维度</span></span><br><span class="line">    y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">    acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">    loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">    test_accs.append(acc.item())</span><br><span class="line">    test_costs.append(loss.item())</span><br><span class="line">test_loss = np.mean(test_costs)    <span class="comment"># 每轮测试的平均误差</span></span><br><span class="line">test_acc = np.mean(test_accs)      <span class="comment"># 每轮测试的平均准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Eval \t Loss：%.5f，Acc：%.5f&quot;</span> % (test_loss, test_acc))</span><br></pre></td></tr></table></figure><p>模型评估结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Eval  Loss：0.16533，Acc：0.96663</span><br></pre></td></tr></table></figure><h2 id="3-5-模型预测-4">3.5. 模型预测</h2><ul><li><strong>预测图片预处理</strong><br>由于车牌图片是由多个字符构成的RGB模式的图片，因此在进行预测之前需要将车牌图片转化为灰度图并按字符划分子图像，以便于模型逐字符进行预测。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">path</span>):      <span class="comment"># 图像整体预处理</span></span><br><span class="line">    img = Image.<span class="built_in">open</span>(path).convert(<span class="string">&quot;L&quot;</span>)    <span class="comment"># 将图像打开并转为灰度图</span></span><br><span class="line">    img = img.resize((<span class="number">32</span>, <span class="number">32</span>), Image.ANTIALIAS)</span><br><span class="line">    img = np.array(img).reshape(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)\</span><br><span class="line">        .astype(<span class="string">&#x27;float32&#x27;</span>)          <span class="comment"># 把图像变成numpy数组</span></span><br><span class="line">    img = img / <span class="number">255.0</span> * <span class="number">2.0</span> - <span class="number">1.0</span>   <span class="comment"># 将数据归一化到[-1, 1]之间</span></span><br><span class="line">    img = paddle.to_tensor(img)</span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">divide_picture</span>(<span class="params">path</span>):      <span class="comment"># 分割出车牌图像中的每一个字符并保存</span></span><br><span class="line">    <span class="comment"># (1) 图片灰度化处理：</span></span><br><span class="line">    license = cv2.imread(path)</span><br><span class="line">    gray_img = cv2.cvtColor(license, cv2.COLOR_RGB2GRAY)  <span class="comment"># 将车牌转化为灰度图</span></span><br><span class="line">    retval, bin_img = cv2.threshold(                      <span class="comment"># 进行图像二值化操作</span></span><br><span class="line">        gray_img, <span class="number">100</span>, <span class="number">255</span>, cv2.THRESH_BINARY  <span class="comment"># 源图片、起始阈值、最大阈值、阈值类型</span></span><br><span class="line">    )   <span class="comment"># 函数返回值：retval是阈值；bin_img是根据阈值处理后的图像</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># (2) 按列统计像素分布：</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(bin_img.shape[<span class="number">1</span>]):</span><br><span class="line">        result.append(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(bin_img.shape[<span class="number">0</span>]):</span><br><span class="line">            result[col] += bin_img[row][col] / <span class="number">255.0</span>    <span class="comment"># 统计归一化后的像素分布</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># (3) 记录车牌中的字符的位置：</span></span><br><span class="line">    place_dict, num, i = &#123;&#125;, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(result):</span><br><span class="line">        <span class="keyword">if</span> result[i] == <span class="number">0</span>:</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            index = i + <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> result[index] != <span class="number">0</span>:</span><br><span class="line">                index += <span class="number">1</span></span><br><span class="line">            place_dict[num] = [i, index-<span class="number">1</span>]</span><br><span class="line">            num += <span class="number">1</span></span><br><span class="line">            i = index</span><br><span class="line"></span><br><span class="line">    <span class="comment"># (4) 将每个字符填充并存储：</span></span><br><span class="line">    characters = []</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(TEMP_PATH):</span><br><span class="line">        os.mkdir(TEMP_PATH)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">2</span>:   <span class="comment"># 跳过蓝牌中的“•”号</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        padding = (<span class="number">170</span> - (place_dict[i][<span class="number">1</span>] - place_dict[i][<span class="number">0</span>])) / <span class="number">2</span></span><br><span class="line">        ndarray = np.pad(     <span class="comment"># 将单个字符图像填充为170*170</span></span><br><span class="line">            bin_img[:, place_dict[i][<span class="number">0</span>]: place_dict[i][<span class="number">1</span>]],</span><br><span class="line">            ((<span class="number">0</span>, <span class="number">0</span>), (<span class="built_in">int</span>(padding), <span class="built_in">int</span>(padding))),</span><br><span class="line">            <span class="string">&quot;constant&quot;</span>,</span><br><span class="line">            constant_values=(<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">        )</span><br><span class="line">        ndarray = cv2.resize(ndarray, (<span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">        cv2.imwrite(TEMP_PATH + <span class="string">&quot;/%d.png&quot;</span> % i, ndarray)   <span class="comment"># 保存划分后的单字符图片</span></span><br><span class="line">        characters.append(ndarray)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">match_labels</span>(<span class="params">label_dict</span>):   <span class="comment"># 返回将标签与汉字的映射关系</span></span><br><span class="line">    temp = &#123;<span class="string">&#x27;yun&#x27;</span>: <span class="string">&#x27;云&#x27;</span>, <span class="string">&#x27;cuan&#x27;</span>: <span class="string">&#x27;川&#x27;</span>, <span class="string">&#x27;hei&#x27;</span>: <span class="string">&#x27;黑&#x27;</span>, <span class="string">&#x27;zhe&#x27;</span>: <span class="string">&#x27;浙&#x27;</span>, <span class="string">&#x27;ning&#x27;</span>: <span class="string">&#x27;宁&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;yu&#x27;</span>: <span class="string">&#x27;豫&#x27;</span>, <span class="string">&#x27;ji&#x27;</span>: <span class="string">&#x27;冀&#x27;</span>, <span class="string">&#x27;hu&#x27;</span>: <span class="string">&#x27;沪&#x27;</span>, <span class="string">&#x27;jl&#x27;</span>: <span class="string">&#x27;吉&#x27;</span>, <span class="string">&#x27;sx&#x27;</span>: <span class="string">&#x27;晋&#x27;</span>, <span class="string">&#x27;lu&#x27;</span>: <span class="string">&#x27;鲁&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;qing&#x27;</span>: <span class="string">&#x27;青&#x27;</span>, <span class="string">&#x27;zang&#x27;</span>: <span class="string">&#x27;藏&#x27;</span>, <span class="string">&#x27;e1&#x27;</span>: <span class="string">&#x27;鄂&#x27;</span>, <span class="string">&#x27;meng&#x27;</span>: <span class="string">&#x27;蒙&#x27;</span>, <span class="string">&#x27;gan1&#x27;</span>: <span class="string">&#x27;甘&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;qiong&#x27;</span>: <span class="string">&#x27;琼&#x27;</span>, <span class="string">&#x27;shan&#x27;</span>: <span class="string">&#x27;陕&#x27;</span>, <span class="string">&#x27;min&#x27;</span>: <span class="string">&#x27;闽&#x27;</span>, <span class="string">&#x27;su&#x27;</span>: <span class="string">&#x27;苏&#x27;</span>, <span class="string">&#x27;xin&#x27;</span>: <span class="string">&#x27;新&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;wan&#x27;</span>: <span class="string">&#x27;皖&#x27;</span>, <span class="string">&#x27;jing&#x27;</span>: <span class="string">&#x27;京&#x27;</span>, <span class="string">&#x27;xiang&#x27;</span>: <span class="string">&#x27;湘&#x27;</span>, <span class="string">&#x27;gui&#x27;</span>: <span class="string">&#x27;贵&#x27;</span>, <span class="string">&#x27;yu1&#x27;</span>: <span class="string">&#x27;渝&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;jin&#x27;</span>: <span class="string">&#x27;津&#x27;</span>, <span class="string">&#x27;gan&#x27;</span>: <span class="string">&#x27;赣&#x27;</span>, <span class="string">&#x27;yue&#x27;</span>: <span class="string">&#x27;粤&#x27;</span>, <span class="string">&#x27;gui1&#x27;</span>: <span class="string">&#x27;桂&#x27;</span>, <span class="string">&#x27;liao&#x27;</span>: <span class="string">&#x27;辽&#x27;</span>&#125;</span><br><span class="line">    name_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key, val <span class="keyword">in</span> label_dict.items():      <span class="comment"># 本次转换的目的是转换字母和汉字</span></span><br><span class="line">        name_dict[key] = temp.get(val, val)</span><br><span class="line">    <span class="keyword">return</span> name_dict</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name_dict = match_labels(label_dict)    <span class="comment"># 获取转换标签的字典</span></span><br><span class="line">divide_picture(INFER_PATH)              <span class="comment"># 按车牌字符划分图片</span></span><br><span class="line">display(Image.<span class="built_in">open</span>(INFER_PATH))         <span class="comment"># 展示预测车牌</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20210211225000923.png#pic_center" alt=""></p><ul><li><strong>载入模型并开始预测</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">model.set_state_dict(</span><br><span class="line">    paddle.load(MODEL_PATH)</span><br><span class="line">)   <span class="comment"># 载入预训练模型参数</span></span><br><span class="line"></span><br><span class="line">infer_label = <span class="string">&quot;&quot;</span>                         <span class="comment"># 存储预测结果</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">2</span>:     <span class="comment"># 跳过蓝牌中的“•”号</span></span><br><span class="line">        infer_label += <span class="string">&quot;•&quot;</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    char_img = load_image(TEMP_PATH + <span class="string">&quot;/%d.png&quot;</span> % i)</span><br><span class="line">    result = model(char_img)            <span class="comment"># 模型预测，返回一个概率数组</span></span><br><span class="line">    lab = np.argmax(result.numpy())     <span class="comment"># 返回数组result中的最大值的索引值</span></span><br><span class="line">    infer_label += name_dict[<span class="built_in">str</span>(lab)]  <span class="comment"># 将字符的预测结果加入到总结果中</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n该车牌的预测结果为:&quot;</span>, infer_label)     <span class="comment"># 展示预测结果</span></span><br></pre></td></tr></table></figure><p>模型预测结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">该车牌的预测结果为: 苏A•UP678</span><br></pre></td></tr></table></figure><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/764714?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【DNN】手写数字识别</title>
      <link href="/2020/08/27/%E3%80%90DNN%E3%80%91%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
      <url>/2020/08/27/%E3%80%90DNN%E3%80%91%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 项目准备</h1><h2 id="1-1-问题导入-2">1.1. 问题导入</h2><p>图像分类是根据图像的语义信息将不同类别图像区分开来，是计算机视觉中重要的基本问题。现有10类若干张手写数字图片，请使用多层感知器训练DNN模型预测手写数字图片：<br><img src="https://img-blog.csdnimg.cn/20210208100153448.png#pic_center" alt=""></p><h2 id="1-2-数据集简介-2">1.2. 数据集简介</h2><p>本实验使用的是PaddlePaddle提供的mnist数据集（paddle.dataset.mnist），它包含60000个训练集和10000测试数据集，分为图片和标签，图片是 28 * 28 的像素矩阵，标签为0~9共10个数字：<br><img src="https://img-blog.csdnimg.cn/202102081005013.png#pic_center" alt=""></p><hr><h1>2. 实验步骤</h1><p><img src="https://img-blog.csdnimg.cn/20210208110405937.png#pic_center" alt=""></p><h2 id="2-0-前期准备">2.0. 前期准备</h2><ul><li><strong>导入模块</strong></li></ul><blockquote><p>注意：本案例仅适用于<code>PaddlePaddle 2.0+</code>版本</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> paddle <span class="keyword">import</span> metric <span class="keyword">as</span> M</span><br><span class="line"><span class="keyword">from</span> paddle.io <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> paddle.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> paddle.optimizer <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> paddle.vision.datasets <span class="keyword">import</span> MNIST</span><br><span class="line"><span class="keyword">from</span> paddle.vision.transforms <span class="keyword">import</span> Compose, Normalize</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">128</span>                <span class="comment"># 每批次的样本数</span></span><br><span class="line">CLASS_DIM = <span class="number">10</span>                  <span class="comment"># 图像种类数</span></span><br><span class="line">EPOCHS = <span class="number">4</span>                      <span class="comment"># 训练轮数</span></span><br><span class="line">LOG_GAP = <span class="number">200</span>                   <span class="comment"># 输出训练信息的间隔</span></span><br><span class="line">INIT_LR = <span class="number">2e-4</span>                  <span class="comment"># 初始学习率</span></span><br><span class="line">DATA_PATH = <span class="string">&quot;./data&quot;</span>            <span class="comment"># 数据集存放路径</span></span><br><span class="line">MODEL_PATH = <span class="string">&quot;DNN.pdparams&quot;</span>     <span class="comment"># 模型参数保存路径</span></span><br></pre></td></tr></table></figure><h2 id="2-1-数据准备">2.1. 数据准备</h2><ul><li><strong>数据预处理</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">transform = Compose([</span><br><span class="line">    Normalize(mean=[<span class="number">127.5</span>], std=[<span class="number">127.5</span>], data_format=<span class="string">&#x27;CHW&#x27;</span>)  <span class="comment"># 归一化</span></span><br><span class="line">])</span><br><span class="line">train_dataset = MNIST(mode=<span class="string">&#x27;train&#x27;</span>, transform=transform)     <span class="comment"># 训练集</span></span><br><span class="line">test_dataset = MNIST(mode=<span class="string">&#x27;test&#x27;</span>, transform=transform)       <span class="comment"># 测试集</span></span><br></pre></td></tr></table></figure><ul><li><strong>定义数据读取器</strong></li></ul><blockquote><ul><li><code>batch_size</code>：每批次读取样本数。例如<code>batch_size=64</code>表示每批次读取64个样本。</li><li><code>shuffle</code>：是否打乱样本。例如<code>shuffle=True</code>表示在取数据时打乱样本顺序，以减少过拟合发生的可能。</li><li><code>drop_last</code>：是否丢弃不完整的批次样本。例如<code>drop_last=True</code>表示丢弃因数据集样本数不能被<code>batch_size</code>整除而产生的最后一个不完整的batch样本。</li><li><code>num_workers</code>：加载数据的子进程个数。<code>num_workers</code>的值设为大于0时，即开启多进程方式异步加载数据，可提升数据读取速度。</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(train_dataset,          <span class="comment"># 训练数据集</span></span><br><span class="line">                          batch_size=BATCH_SIZE,  <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                          num_workers=<span class="number">1</span>,          <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                          shuffle=<span class="literal">True</span>,           <span class="comment"># 打乱训练数据集</span></span><br><span class="line">                          drop_last=<span class="literal">True</span>)         <span class="comment"># 丢弃不完整的样本</span></span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(test_dataset,            <span class="comment"># 测试数据集</span></span><br><span class="line">                         batch_size=BATCH_SIZE,   <span class="comment"># 每批读取的样本数</span></span><br><span class="line">                         num_workers=<span class="number">1</span>,           <span class="comment"># 加载数据的子进程个数</span></span><br><span class="line">                         shuffle=<span class="literal">False</span>,           <span class="comment"># 不打乱测试数据集</span></span><br><span class="line">                         drop_last=<span class="literal">True</span>)          <span class="comment"># 丢弃不完整的样本</span></span><br></pre></td></tr></table></figure><h2 id="2-2-模型配置">2.2. 模型配置</h2><ul><li><strong>定义多层感知器</strong><br>本实验定义的是一个多层感知器，它一共有三层（不含输入层）：即两个大小为512的隐藏层和一个大小为10的输出层。<br><img src="https://img-blog.csdnimg.cn/img_convert/8d8e46829d0b0aebc64e9800c9594cc4.png#pic_center" alt=""></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DNN</span>(nn.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_classes=<span class="number">10</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(DNN, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            nn.Flatten(<span class="number">1</span>, -<span class="number">1</span>),</span><br><span class="line">            nn.Linear(<span class="number">28</span>*<span class="number">28</span>, <span class="number">1024</span>),     <span class="comment"># 第一个全连接隐藏层</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.25</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, n_classes)  <span class="comment"># 第二个全连接隐藏层</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.model(x)</span><br></pre></td></tr></table></figure><ul><li><strong>模型实例化</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = DNN(n_classes=CLASS_DIM)</span><br></pre></td></tr></table></figure><h2 id="2-3-模型训练">2.3. 模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">model.train()                <span class="comment"># 开启训练模式</span></span><br><span class="line">opt = Adam(learning_rate=INIT_LR,</span><br><span class="line">           parameters=model.parameters())  <span class="comment"># 定义Adam优化器</span></span><br><span class="line">loss_arr, acc_arr = [], []   <span class="comment"># 用于可视化</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ep <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    <span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader()):</span><br><span class="line">        x_data, y_data = data</span><br><span class="line">        y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">        acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">        loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">        <span class="keyword">if</span> batch_id % LOG_GAP == <span class="number">0</span>:             <span class="comment"># 定期输出训练结果</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch：%d，Batch：%3d，Loss：%.5f，Acc：%.5f&quot;</span>\</span><br><span class="line">                % (ep, batch_id, loss, acc))</span><br><span class="line">        acc_arr.append(acc.item())</span><br><span class="line">        loss_arr.append(loss.item())</span><br><span class="line">        opt.clear_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        opt.step()</span><br><span class="line"></span><br><span class="line">paddle.save(model.state_dict(), MODEL_PATH)  <span class="comment"># 保存训练好的模型</span></span><br></pre></td></tr></table></figure><p>模型训练的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Epoch：0，Batch：  0，Loss：2.63496，Acc：0.14062</span><br><span class="line">Epoch：0，Batch：200，Loss：0.42945，Acc：0.86719</span><br><span class="line">Epoch：0，Batch：400，Loss：0.19543，Acc：0.96094</span><br><span class="line">Epoch：1，Batch：  0，Loss：0.18954，Acc：0.96094</span><br><span class="line">Epoch：1，Batch：200，Loss：0.18587，Acc：0.95312</span><br><span class="line">Epoch：1，Batch：400，Loss：0.18084，Acc：0.96094</span><br><span class="line">Epoch：2，Batch：  0，Loss：0.12029，Acc：0.97656</span><br><span class="line">Epoch：2，Batch：200，Loss：0.18207，Acc：0.95312</span><br><span class="line">Epoch：2，Batch：400，Loss：0.18604，Acc：0.92188</span><br><span class="line">Epoch：3，Batch：  0，Loss：0.14635，Acc：0.97656</span><br><span class="line">Epoch：3，Batch：200，Loss：0.13389，Acc：0.95312</span><br><span class="line">Epoch：3，Batch：400，Loss：0.06493，Acc：0.99219</span><br></pre></td></tr></table></figure><ul><li><strong>可视化训练过程</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=[<span class="number">10</span>, <span class="number">5</span>])</span><br><span class="line">plt.title(<span class="string">&quot;Model Training&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;steps&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;loss / accuracy&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(loss_arr)), loss_arr, color=<span class="string">&quot;r&quot;</span>, label=<span class="string">&quot;loss&quot;</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="built_in">len</span>(acc_arr)), acc_arr, color=<span class="string">&quot;g&quot;</span>, label=<span class="string">&quot;accuracy&quot;</span>)</span><br><span class="line">plt.legend(fontsize=<span class="number">16</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/68ee32fd6e6a4094bbea8f60be1b59bc.png#pic_center" alt=""></p><h2 id="2-4-模型评估">2.4. 模型评估</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                 <span class="comment"># 开启评估模式</span></span><br><span class="line">test_costs, test_accs = [], []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch_id, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader()):</span><br><span class="line">    x_data, y_data = data</span><br><span class="line">    y_pred = model(x_data)                  <span class="comment"># 预测结果</span></span><br><span class="line">    acc = M.accuracy(y_pred, y_data)        <span class="comment"># 计算准确率</span></span><br><span class="line">    loss = F.cross_entropy(y_pred, y_data)  <span class="comment"># 计算交叉熵</span></span><br><span class="line">    test_accs.append(acc.item())</span><br><span class="line">    test_costs.append(loss.item())</span><br><span class="line">test_loss = np.mean(test_costs)    <span class="comment"># 每轮测试的平均误差</span></span><br><span class="line">test_acc = np.mean(test_accs)      <span class="comment"># 每轮测试的平均准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Eval \t Loss：%.5f，Acc：%.5f&quot;</span> % (test_loss, test_acc))</span><br></pre></td></tr></table></figure><p>模型评估的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Eval  Loss：0.09750，Acc：0.97296</span><br></pre></td></tr></table></figure><h2 id="2-5-模型预测">2.5. 模型预测</h2><ul><li><strong>准备预测数据</strong></li></ul><blockquote><p>这是预测数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/51183">手写数字预测数据集 - AI Studio</a>，它包含从0到9的10张数字图片。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">path</span>):        <span class="comment"># 图片预处理</span></span><br><span class="line">    <span class="comment"># (1) 打开并展示图像：</span></span><br><span class="line">    img = Image.<span class="built_in">open</span>(path)   <span class="comment"># 打开图像</span></span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    plt.show()               <span class="comment"># 显示图像</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># (2) 格式化图像：</span></span><br><span class="line">    img = img.convert(<span class="string">&quot;L&quot;</span>)                 <span class="comment"># 将图像转化为灰度图像，L代表灰度图像</span></span><br><span class="line">    img = img.resize((<span class="number">28</span>, <span class="number">28</span>), Image.ANTIALIAS)  <span class="comment"># 将图像缩放为28*28的高质量图像</span></span><br><span class="line">    img = np.array(img).reshape(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)\</span><br><span class="line">        .astype(np.float32)          <span class="comment"># 把图像变成一个numpy数组以匹配数据馈送格式</span></span><br><span class="line">    img = img / <span class="number">255.0</span> * <span class="number">2.0</span> - <span class="number">1.0</span>    <span class="comment"># 将数据归一化到[-1, 1]之间</span></span><br><span class="line">    img = paddle.to_tensor(img)      <span class="comment"># 将图像转化为Tensor类型</span></span><br><span class="line">    <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">truth_lab = randint(<span class="number">0</span>, <span class="number">9</span>)                     <span class="comment"># 预测图片的真实标签</span></span><br><span class="line">img_path = DATA_PATH + <span class="string">&quot;/infer_%d.png&quot;</span>        <span class="comment"># 预测图片的路径</span></span><br><span class="line">infer_img = load_image(img_path % truth_lab)  <span class="comment"># 获取预测图片</span></span><br></pre></td></tr></table></figure><p>随机选取的预测图片如下：<br><img src="https://img-blog.csdnimg.cn/20210208110620596.png#pic_center" alt=""></p><ul><li><strong>载入模型并开始预测</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()                    <span class="comment"># 开启评估模式</span></span><br><span class="line">model.set_state_dict(</span><br><span class="line">    paddle.load(MODEL_PATH)</span><br><span class="line">)   <span class="comment"># 载入预训练模型参数</span></span><br><span class="line">result = model(infer_img)</span><br><span class="line">infer_lab = np.argmax(result)   <span class="comment"># 返回数组result中的最大值的索引值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;真实标签：%d，预测结果：%d&quot;</span> % (truth_lab, infer_lab))</span><br></pre></td></tr></table></figure><p>模型预测的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">真实标签：2，预测结果：2</span><br></pre></td></tr></table></figure><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/760892?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 图像分类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【KMeans】基于经纬度的城市聚类</title>
      <link href="/2020/08/23/%E3%80%90KMeans%E3%80%91%E5%9F%BA%E4%BA%8E%E7%BB%8F%E7%BA%AC%E5%BA%A6%E7%9A%84%E5%9F%8E%E5%B8%82%E8%81%9A%E7%B1%BB/"/>
      <url>/2020/08/23/%E3%80%90KMeans%E3%80%91%E5%9F%BA%E4%BA%8E%E7%BB%8F%E7%BA%AC%E5%BA%A6%E7%9A%84%E5%9F%8E%E5%B8%82%E8%81%9A%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 项目准备</h1><h2 id="1-1-问题导入-4">1.1. 问题导入</h2><p>KMeans聚类算法是一种非层次聚类算法，在最小误差的基础上将数据划分了特定的类，类间利用距离作为相似度指标，两个向量之间的距离越小，其相似度就越高。已知中国部分二级城市的经纬度，要求利用经纬度坐标进行KMeans聚类分析。</p><h2 id="1-2-数据集简介-3">1.2. 数据集简介</h2><p>本案例的数据集包含4列351行数据，每行数据包含一个城市，其中前两列为城市所在省和市，最后两列为城市的经纬度。</p><blockquote><p>这是数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/49718">中国主要城市经纬度数据集 - AI Studio</a></p></blockquote><hr><h1>2. K-Means算法</h1><h2 id="2-1-算法特点">2.1. 算法特点</h2><p>K-Means聚类算法是一种基于向量距离作为相似性的评价指标，即认为两个对象的距离越近，其相似度就越大。该算法认为类簇是由距离靠近的对象组成的，因此它把得到紧凑且独立的类簇作为聚类的最终目标。<br>综上所述，K-Means算法划分的k个聚类具有以下特点：各聚类内部的元素尽可能的紧凑，而各聚类之间的元素尽可能的分开。</p><h2 id="2-2-算法流程">2.2. 算法流程</h2><p>K-Means算法的基础是最小误差平方和准则，K-Means算法具体流程如下：<br>（1）从n个样本对象任意选择k个对象作为初始聚类中心；<br>（2）根据在步骤 (1) 中设置的k个聚类中心，计算每个对象与这k个中心的距离；<br>（3）经过步骤 (2) 的计算，所有对象与这个k个中心的距离就计算出来了，接着把所有对象与离它最近的中心归在一个类簇中；<br>（4）重新计算每个类簇的中心对象的位置；<br>（5）重复步骤 (3) 和 (4)，直到类簇聚类方案中的对象归类几乎不发生变化为止。</p><h2 id="2-3-算法缺陷">2.3. 算法缺陷</h2><p>（1）种子点的个数要事先确定，但是我们一般很难估计它的个数。<br>（2）K-Means算法需要初始种子点，并且随机种子会影响计算结果。<br>（3）需要不断地计算调整后的类簇中心，当数据量很大时，这个计算所需的时间就会很大。</p><h2 id="2-4-算法改进">2.4. 算法改进</h2><p>K-Means++算法是改进后的K-Means算法，具体算法流程如下：<br>（1）从数据集的点中随机选择一个点作为种子点；<br>（2）计算数据集中的每一个点到种子点的距离D(x)；<br>（3）选择D(x)较大的点作为新的种子点；<br>（4）重复步骤 (2) 和 (3)直到新的种子被选出来。</p><hr><h1>3. 实验步骤</h1><h2 id="3-1-前期准备">3.1. 前期准备</h2><ul><li><strong>导入模块</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, silhouette_samples</span><br></pre></td></tr></table></figure><ul><li><strong>设置超参数</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">N_CLUSTERS = <span class="number">7</span>                                     <span class="comment"># 类簇的数量</span></span><br><span class="line">MARKERS = [<span class="string">&#x27;*&#x27;</span>, <span class="string">&#x27;v&#x27;</span>, <span class="string">&#x27;+&#x27;</span>, <span class="string">&#x27;^&#x27;</span>, <span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;o&#x27;</span>]      <span class="comment"># 标记样式（绘图）</span></span><br><span class="line">COLORS = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>]  <span class="comment"># 标记颜色（绘图）</span></span><br><span class="line">DATA_PATH = <span class="string">&#x27;./data/China_cities.csv&#x27;</span>              <span class="comment"># 数据集路径</span></span><br></pre></td></tr></table></figure><h2 id="3-2-读入数据">3.2. 读入数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(DATA_PATH)</span><br><span class="line"><span class="built_in">print</span>(df.head())    <span class="comment"># 展示前5行数据</span></span><br></pre></td></tr></table></figure><p>前5行数据的输出结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">     省级行政区      城市       北纬        东经</span><br><span class="line">0       北京        北京市   39.904690   116.40717</span><br><span class="line">1       天津        天津市   39.085100   117.19937</span><br><span class="line">2       上海        上海市   31.230370   121.47370</span><br><span class="line">3       重庆        重庆市   29.564710   106.55073</span><br><span class="line">4  香港特别行政区    九龙    22.327115   114.17495</span><br></pre></td></tr></table></figure><h2 id="3-3-数据预处理">3.3. 数据预处理</h2><p>我们需要将各城市的经纬度数据单独提取出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = df.drop(<span class="string">&#x27;省级行政区&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">x = x.drop(<span class="string">&quot;城市&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line">x_np = np.array(x)        <span class="comment"># 将x转化为numpy数组</span></span><br></pre></td></tr></table></figure><h2 id="3-4-模型构建与训练">3.4. 模型构建与训练</h2><p>本项目使用<strong>K-Means聚类算法</strong>来对城市的经纬度特征进行聚类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = KMeans(N_CLUSTERS)      <span class="comment"># 构建聚类器</span></span><br><span class="line">model.fit(x)                    <span class="comment"># 训练聚类器</span></span><br></pre></td></tr></table></figure><ul><li><strong>展示类簇中心</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(model.cluster_centers_)<span class="comment"># 输出类簇中心</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[[ 36.30742841 105.21526409]</span><br><span class="line"> [ 27.85671809 102.12971362]</span><br><span class="line"> [ 41.34384438  84.09634   ]</span><br><span class="line"> [ 44.01411423 124.90852352]</span><br><span class="line"> [ 24.3572954  111.87362376]</span><br><span class="line"> [ 29.06106948 118.51486687]</span><br><span class="line"> [ 36.22217001 115.34626425]]</span><br></pre></td></tr></table></figure><ul><li><strong>计算轮廓系数</strong><br>轮廓系数（Silhouette Coefficient）是一种评价聚类效果的方法，其值介于[-1, 1]之间，值越趋近于1代表同簇点的内聚度和异簇点的分离度都相对较优。<br>假设我们用K-Means算法将数据划分成K个类簇，对于某簇中任意一个向量i而言，其轮廓系数$S_i = \frac{B_i-A_i}{max(A_i, B_i)}$。其中，$A_i$是i到同簇中其它所有点距离的平均值，它是i与同簇内其他点不相似程度的平均值；$B_i$是i到其他簇内所有点平均距离的最小值，它是i与其他簇的点平均不相似程度的最小值。<br>将所有点的轮廓系数求平均，就能得到该聚类结果总的轮廓系数。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">labels = model.labels_      <span class="comment"># 获取聚类标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(silhouette_samples(x, labels))  # 获取所有样本的轮廓系数</span></span><br><span class="line"><span class="built_in">print</span>(silhouette_score(x, labels))      <span class="comment"># 获取聚类结果总的轮廓系数</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.40034267246878397</span><br></pre></td></tr></table></figure><h2 id="3-5-数据可视化">3.5. 数据可视化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">9</span>, <span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">&quot;Major Cities in China&quot;</span>, fontsize=<span class="number">22</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;East Longitude&#x27;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;North Latitude&#x27;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N_CLUSTERS):</span><br><span class="line">    members = labels == i      <span class="comment"># members是一个布尔型数组</span></span><br><span class="line">    plt.scatter(</span><br><span class="line">        x_np[members, <span class="number">1</span>],      <span class="comment"># 城市经度数组</span></span><br><span class="line">        x_np[members, <span class="number">0</span>],      <span class="comment"># 城市纬度数组</span></span><br><span class="line">        marker = MARKERS[i],   <span class="comment"># 标记样式</span></span><br><span class="line">        c = COLORS[i]          <span class="comment"># 标记颜色</span></span><br><span class="line">    )   <span class="comment"># 绘制散点图</span></span><br><span class="line"></span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>基于经纬度的城市聚类结果：<br><img src="https://img-blog.csdnimg.cn/20210206115113756.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1RYS19LZXZpbg==,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/729321?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 聚类问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【决策树】个人信贷风险预测</title>
      <link href="/2020/08/15/%E3%80%90%E5%86%B3%E7%AD%96%E6%A0%91%E3%80%91%E4%B8%AA%E4%BA%BA%E4%BF%A1%E8%B4%B7%E9%A3%8E%E9%99%A9%E9%A2%84%E6%B5%8B/"/>
      <url>/2020/08/15/%E3%80%90%E5%86%B3%E7%AD%96%E6%A0%91%E3%80%91%E4%B8%AA%E4%BA%BA%E4%BF%A1%E8%B4%B7%E9%A3%8E%E9%99%A9%E9%A2%84%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<h1>1. 项目准备</h1><h2 id="1-1-问题导入-11">1.1. 问题导入</h2><p>随着技术的不断革新以及个人消费意识的改变，从互联网上借贷来满足生活需求或者实现个人增值，越来越受到大众的接受。请利用以往的信贷数据利用决策树构建一个风险控制模型，使其在后续的借贷业务中，能够提前识别出信贷风险，供投资者选择是否投资此项贷款。</p><h2 id="1-2-数据集简介-9">1.2. 数据集简介</h2><p>数据集中的数据是美国最大的P2P网贷交易平台Lending Club的历史数据，一共由9578行、14列数据构成：</p><blockquote><p>（1） <strong>credit.policy</strong><br>客户是否满足Lending Club的授信标准（1为是，0为否）<br>（2） <strong>purpose</strong><br>表示贷款的目的（例：信用卡还款，债务处理，教育，购买大件，中小企业经营等等）<br>（3） <strong>int.rate</strong><br>贷款利率（较高的贷款利率意味着较高的风险）<br>（4） <strong>installment</strong><br>每月分期还款额<br>（5） <strong>log.annual.inc</strong><br>借贷者的年收入的自然对数<br>（6） <strong>dti</strong><br>借贷者的债务收入比（贷款收入比例，Delt-to-income）<br>（7） <strong>fico</strong><br>美国个人评分系统的评分。FICO得出的分数在300-850分之间，分数越高说明客户的信用风险越小，但分数本身不能说明一个客户是好是坏，贷款方通常会将分数作为参考，来进行贷款决策。每个贷款方都有自己的贷款策略和标准，并且每种产品都会有自己的风险水平，从而决定了可以接受的信用分数水平。<br>（8） <strong>days.with.cr.line</strong><br>借贷者有信用额度的天数<br>（9） <strong>revol.bal</strong><br>借贷者的账户余额（尚未结清的金额）<br>（10） <strong>revol.util</strong><br>借贷者的信用账户利用率（使用的金额/授信的金额）<br>（11） <strong>inq.last.6mths</strong><br>借贷者在过去6个月被借款者咨询的次数<br>（12） <strong>delinq.2yrs</strong><br>借贷者在过去2年逾期还款超过30天的次数<br>（13） <strong>pub.rec</strong><br>借贷者公共事业记录差评的次数<br>（14） <strong>not.fully.paid</strong><br>表示不完全支付，要预测这个因变量，可供投资者选择是否投资此项贷款（0贷款，1不贷款）</p></blockquote><blockquote><p>这是数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/49208">Lending Club借贷数据 - AI Studio</a></p></blockquote><hr><h1>2. 实验步骤</h1><h2 id="2-0-导入模块-3">2.0. 导入模块</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report, confusion_matrix</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br></pre></td></tr></table></figure><h2 id="2-1-数据预处理">2.1. 数据预处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&#x27;loan_data.csv&#x27;</span>)</span><br><span class="line">x = df.drop(<span class="string">&quot;not.fully.paid&quot;</span>, axis=<span class="number">1</span>)  <span class="comment"># 提取特征值（除“not.fully.paid”外的所有字段的值）</span></span><br><span class="line">y = df[<span class="string">&#x27;not.fully.paid&#x27;</span>]               <span class="comment"># 提取目标值（字段“not.fully.paid”对应的字段值）</span></span><br></pre></td></tr></table></figure><ul><li><strong>数据的描述性统计分析</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df.describe().T)</span><br><span class="line"><span class="comment"># 表头：特征数据个数，平均值，标准差，最小值，1/4中位数，1/2中位数，3/4中位数，最大值</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">                    count          mean           std         min  \</span><br><span class="line">credit.policy      9578.0      0.804970      0.396245    0.000000   </span><br><span class="line">int.rate           9578.0      0.122640      0.026847    0.060000   </span><br><span class="line">installment        9578.0    319.089413    207.071301   15.670000   </span><br><span class="line">log.annual.inc     9578.0     10.932117      0.614813    7.547502   </span><br><span class="line">dti                9578.0     12.606679      6.883970    0.000000   </span><br><span class="line">fico               9578.0    710.846314     37.970537  612.000000   </span><br><span class="line">days.with.cr.line  9578.0   4560.767197   2496.930377  178.958333   </span><br><span class="line">revol.bal          9578.0  16913.963876  33756.189557    0.000000   </span><br><span class="line">revol.util         9578.0     46.799236     29.014417    0.000000   </span><br><span class="line">inq.last.6mths     9578.0      1.577469      2.200245    0.000000   </span><br><span class="line">delinq.2yrs        9578.0      0.163708      0.546215    0.000000   </span><br><span class="line">pub.rec            9578.0      0.062122      0.262126    0.000000   </span><br><span class="line">not.fully.paid     9578.0      0.160054      0.366676    0.000000   </span><br><span class="line"></span><br><span class="line">                           25%          50%           75%           max  </span><br><span class="line">credit.policy         1.000000     1.000000      1.000000  1.000000e+00  </span><br><span class="line">int.rate              0.103900     0.122100      0.140700  2.164000e-01  </span><br><span class="line">installment         163.770000   268.950000    432.762500  9.401400e+02  </span><br><span class="line">log.annual.inc       10.558414    10.928884     11.291293  1.452835e+01  </span><br><span class="line">dti                   7.212500    12.665000     17.950000  2.996000e+01  </span><br><span class="line">fico                682.000000   707.000000    737.000000  8.270000e+02  </span><br><span class="line">days.with.cr.line  2820.000000  4139.958333   5730.000000  1.763996e+04  </span><br><span class="line">revol.bal          3187.000000  8596.000000  18249.500000  1.207359e+06  </span><br><span class="line">revol.util           22.600000    46.300000     70.900000  1.190000e+02  </span><br><span class="line">inq.last.6mths        0.000000     1.000000      2.000000  3.300000e+01  </span><br><span class="line">delinq.2yrs           0.000000     0.000000      0.000000  1.300000e+01  </span><br><span class="line">pub.rec               0.000000     0.000000      0.000000  5.000000e+00  </span><br><span class="line">not.fully.paid        0.000000     0.000000      0.000000  1.000000e+00  </span><br></pre></td></tr></table></figure><ul><li><strong>数据的相关性分析</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 相关系数绝对值越大，表示相关性越大；相关系数为正，表示正相关；相关系数为负，表示负相关</span></span><br><span class="line"><span class="built_in">print</span>(df.corr())</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">                   credit.policy  int.rate  installment  log.annual.inc  \</span><br><span class="line">credit.policy           1.000000 -0.294089     0.058770        0.034906   </span><br><span class="line">int.rate               -0.294089  1.000000     0.276140        0.056383   </span><br><span class="line">installment             0.058770  0.276140     1.000000        0.448102   </span><br><span class="line">log.annual.inc          0.034906  0.056383     0.448102        1.000000   </span><br><span class="line">dti                    -0.090901  0.220006     0.050202       -0.054065   </span><br><span class="line">fico                    0.348319 -0.714821     0.086039        0.114576   </span><br><span class="line">days.with.cr.line       0.099026 -0.124022     0.183297        0.336896   </span><br><span class="line">revol.bal              -0.187518  0.092527     0.233625        0.372140   </span><br><span class="line">revol.util             -0.104095  0.464837     0.081356        0.054881   </span><br><span class="line">inq.last.6mths         -0.535511  0.202780    -0.010419        0.029171   </span><br><span class="line">delinq.2yrs            -0.076318  0.156079    -0.004368        0.029203   </span><br><span class="line">pub.rec                -0.054243  0.098162    -0.032760        0.016506   </span><br><span class="line">not.fully.paid         -0.158119  0.159552     0.049955       -0.033439   </span><br><span class="line"></span><br><span class="line">                        dti      fico  days.with.cr.line  revol.bal  \</span><br><span class="line">credit.policy     -0.090901  0.348319           0.099026  -0.187518   </span><br><span class="line">int.rate           0.220006 -0.714821          -0.124022   0.092527   </span><br><span class="line">installment        0.050202  0.086039           0.183297   0.233625   </span><br><span class="line">log.annual.inc    -0.054065  0.114576           0.336896   0.372140   </span><br><span class="line">dti                1.000000 -0.241191           0.060101   0.188748   </span><br><span class="line">fico              -0.241191  1.000000           0.263880  -0.015553   </span><br><span class="line">days.with.cr.line  0.060101  0.263880           1.000000   0.229344   </span><br><span class="line">revol.bal          0.188748 -0.015553           0.229344   1.000000   </span><br><span class="line">revol.util         0.337109 -0.541289          -0.024239   0.203779   </span><br><span class="line">inq.last.6mths     0.029189 -0.185293          -0.041736   0.022394   </span><br><span class="line">delinq.2yrs       -0.021792 -0.216340           0.081374  -0.033243   </span><br><span class="line">pub.rec            0.006209 -0.147592           0.071826  -0.031010   </span><br><span class="line">not.fully.paid     0.037362 -0.149666          -0.029237   0.053699   </span><br><span class="line"></span><br><span class="line">                   revol.util  inq.last.6mths  delinq.2yrs   pub.rec  \</span><br><span class="line">credit.policy       -0.104095       -0.535511    -0.076318 -0.054243   </span><br><span class="line">int.rate             0.464837        0.202780     0.156079  0.098162   </span><br><span class="line">installment          0.081356       -0.010419    -0.004368 -0.032760   </span><br><span class="line">log.annual.inc       0.054881        0.029171     0.029203  0.016506   </span><br><span class="line">dti                  0.337109        0.029189    -0.021792  0.006209   </span><br><span class="line">fico                -0.541289       -0.185293    -0.216340 -0.147592   </span><br><span class="line">days.with.cr.line   -0.024239       -0.041736     0.081374  0.071826   </span><br><span class="line">revol.bal            0.203779        0.022394    -0.033243 -0.031010   </span><br><span class="line">revol.util           1.000000       -0.013880    -0.042740  0.066717   </span><br><span class="line">inq.last.6mths      -0.013880        1.000000     0.021245  0.072673   </span><br><span class="line">delinq.2yrs         -0.042740        0.021245     1.000000  0.009184   </span><br><span class="line">pub.rec              0.066717        0.072673     0.009184  1.000000   </span><br><span class="line">not.fully.paid       0.082088        0.149452     0.008881  0.048634   </span><br><span class="line"></span><br><span class="line">                   not.fully.paid  </span><br><span class="line">credit.policy           -0.158119  </span><br><span class="line">int.rate                 0.159552  </span><br><span class="line">installment              0.049955  </span><br><span class="line">log.annual.inc          -0.033439  </span><br><span class="line">dti                      0.037362  </span><br><span class="line">fico                    -0.149666  </span><br><span class="line">days.with.cr.line       -0.029237  </span><br><span class="line">revol.bal                0.053699  </span><br><span class="line">revol.util               0.082088  </span><br><span class="line">inq.last.6mths           0.149452  </span><br><span class="line">delinq.2yrs              0.008881  </span><br><span class="line">pub.rec                  0.048634  </span><br><span class="line">not.fully.paid           1.000000  </span><br></pre></td></tr></table></figure><h2 id="2-2-数据预处理-2">2.2. 数据预处理</h2><p>数据的预处理包括：数据的清洗、数据的采样、数据集划分、特征选择、特征降维、特征编码、规范化等过程。<br>下面重点强调一下“特征编码”和“数据集划分”这两个步骤：</p><ul><li><strong>特征编码</strong><br>在构建决策树时，每一个特征都应该是数值类型的，但是我们可以看出，purpose等列的取值都是字符型的（类别，categorical）。所以，必须经过一些转换，把这些类别都映射成为某个数值，才能进行后续步骤。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dic = defaultdict(LabelEncoder)</span><br><span class="line">x_trans = x.apply(<span class="keyword">lambda</span> x: dic[x.name].fit_transform(x))</span><br><span class="line"><span class="built_in">print</span>(x_trans.head())    <span class="comment"># 输出映射后的前5行数据</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">   credit.policy  purpose  int.rate  installment  log.annual.inc   dti  fico  \</span><br><span class="line">0              1        2        76         4665            1462  1887    25   </span><br><span class="line">1              1        1        50         2116            1143  1380    19   </span><br><span class="line">2              1        2       115         3240             348  1115    14   </span><br><span class="line">3              1        2        38         1375            1462   767    20   </span><br><span class="line">4              1        1       132          759            1410  1446    11   </span><br><span class="line"></span><br><span class="line">   days.with.cr.line  revol.bal  revol.util  inq.last.6mths  delinq.2yrs  \</span><br><span class="line">0               1663       6606         530               0            0   </span><br><span class="line">1                632       6849         778               0            0   </span><br><span class="line">2               1363       1628         260               1            0   </span><br><span class="line">3                609       6852         743               1            0   </span><br><span class="line">4               1132       2115         403               0            1   </span><br><span class="line"></span><br><span class="line">   pub.rec  </span><br><span class="line">0        0  </span><br><span class="line">1        0  </span><br><span class="line">2        0  </span><br><span class="line">3        0  </span><br><span class="line">4        0  </span><br></pre></td></tr></table></figure><ul><li><strong>数据集划分</strong><br>训练集和测试集的划分 将整个数据集拆分成：训练集和测试集。不过，如果我们将其直接划分为训练集和数据集，那么就会造成数据分布不均的问题。好在sklearn为我们提供了划分训练集和数据集的方法。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[x_train, x_test,    <span class="comment"># 特征值x的训练集和测试集</span></span><br><span class="line"> y_train, y_test     <span class="comment"># 目标值y的训练集和测试集</span></span><br><span class="line">] = train_test_split(x_trans, y, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="2-3-模型训练与预测-2">2.3. 模型训练与预测</h2><p>sklearn 中使用 sklearn.tree.DecisionTreeClassifier 类来实现决策树算法，其构造方法包含许多参数，比较常用的有以下几个：</p><p>（1）<strong>特征选择标准 criterion</strong></p><blockquote><ul><li>可选值：“gini”（基尼系数，默认）或 “entropy”（信息熵）</li><li>两种算法差异不大对准确率无影响，信息熵效率低一点，因为它有对数运算。一般说使用默认的基尼系数“gini”就可以了，即CART算法。</li></ul></blockquote><p>（2）<strong>随机状态数 random_state</strong></p><blockquote><ul><li>可选值：None（默认），int 或 RandomState</li><li>如果传入值为整数，则它指定了随机数生成器的种子；如果传入值为RandomState实例，则指定了随机数生成器；如果传入值为None，则使用默认的随机数生成器。</li></ul></blockquote><p>（3）<strong>特征划分标准 splitter</strong></p><blockquote><ul><li>可选值：“best”（最佳，默认）或 “random”（随机）</li><li>前者在特征的所有划分点中找出最优的划分点。后者是随机的在部分划分点中找局部最优的划分点。 默认的“best”适合样本量不大的时候，而如果样本数据量非常大，此时决策树构建推“random”。</li></ul></blockquote><p>（4）<strong>决策树最大深度 max_depth</strong></p><blockquote><ul><li>可选值：None（默认）或 int</li><li>一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。常用来防止模型出现过拟合。</li></ul></blockquote><p>（5）<strong>叶节点最少样本数 min_samples_leaf</strong></p><blockquote><ul><li>可选值：int（默认为1）或 float</li><li>如果值是 int型，则取传入值本身作为最小样本数；如果值是 float型，则取 ceil(min_samples_leaf * 样本数量) 的值作为最小样本数（ceil 函数的作用是向上取整）。min_samples_leaf 主要用于对决策树进行修剪，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝。</li></ul></blockquote><p>（6）<strong>最大特征个数 max_features</strong></p><blockquote><ul><li>可选值：None（默认），int，float 或 string（“auto”, “sqrt”, “log2”）</li><li>max_features 一般配合 max_depth 使用，用作树的“精修”，它限制分枝时考虑的特征个数，超过限制个数的特征都会被舍弃。</li></ul></blockquote><p>（7）<strong>节点划分最小不纯度 min_impurity_decrease</strong></p><blockquote><ul><li>可选值：float（默认为0）</li><li>min_impurity_decrease 限制了决策树的增长，如果某节点的不纯度（基尼系数，信息增益，均方差，绝对差）小于这个阈值，则该节点不再生成子节点。</li></ul></blockquote><p>（8）<strong>内部节点再划分所需最小样本数 min_samples_split</strong></p><blockquote><ul><li>可选值：int（默认为2）或 float</li><li>如果值是 int型，则取传入值本身作为最小样本数；如果值是 float型，则取 ceil(min_samples_split * 样本数量) 的值作为最小样本数（ceil 函数的作用是向上取整）。</li></ul></blockquote><p>我们这里暂时先采用默认参数来构造决策树模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dt = DecisionTreeClassifier()    <span class="comment"># 以默认参数构建决策树模型</span></span><br><span class="line">dt.fit(x_train, y_train)         <span class="comment"># 训练模型</span></span><br><span class="line"></span><br><span class="line">dt_infer = dt.predict(x_test)    <span class="comment"># 预测结果</span></span><br><span class="line">dt_truth = <span class="built_in">list</span>(y_test)          <span class="comment"># 真实结果</span></span><br></pre></td></tr></table></figure><h2 id="2-4-模型评价-2">2.4. 模型评价</h2><p><img src="https://img-blog.csdnimg.cn/821d0843671446aca2be1f7228bd15b9.jpeg#pic_center" alt=""><br><img src="https://img-blog.csdnimg.cn/19d5ba67364748c684f302b31c758b23.jpeg#pic_center" alt=""><br><img src="https://img-blog.csdnimg.cn/a0342710efb840dfad92bf373b292976.jpeg#pic_center" alt=""></p><ul><li><strong>预测准确率</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Accuracy \t %.8f&quot;</span> % accuracy_score(dt_truth, dt_infer))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy  0.73903967</span><br></pre></td></tr></table></figure><ul><li><strong>混淆矩阵</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(confusion_matrix(dt_truth, dt_infer))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[1668  324]</span><br><span class="line"> [ 301  102]]</span><br></pre></td></tr></table></figure><ul><li><strong>分类报告</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(classification_report(dt_truth, dt_infer))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">              precision    recall  f1-score   support</span><br><span class="line"></span><br><span class="line">           0       0.85      0.84      0.84      1992</span><br><span class="line">           1       0.24      0.25      0.25       403</span><br><span class="line"></span><br><span class="line">   micro avg       0.74      0.74      0.74      2395</span><br><span class="line">   macro avg       0.54      0.55      0.54      2395</span><br><span class="line">weighted avg       0.74      0.74      0.74      2395</span><br></pre></td></tr></table></figure><h2 id="2-5-模型调优">2.5. 模型调优</h2><p>模型的结果还可以通过优化来提升，在刚才的整个机器学习过程中，用的都是决策树的缺省值，下面通过设置DecisionTreeClassifier() 训练过程中的参数进行调优：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ndt = DecisionTreeClassifier(</span><br><span class="line">    max_depth=<span class="number">5</span>,            <span class="comment"># 决策树最大深度</span></span><br><span class="line">    min_samples_leaf=<span class="number">0.3</span>,   <span class="comment"># 叶节点最少样本数</span></span><br><span class="line">    max_features=<span class="number">1</span>          <span class="comment"># 最大特征个数</span></span><br><span class="line">)   <span class="comment"># 构建决策树模型</span></span><br><span class="line">ndt.fit(x_train, y_train)         <span class="comment"># 模型训练</span></span><br><span class="line">ndt_infer = ndt.predict(x_test)   <span class="comment"># 获取预测值</span></span><br><span class="line">ndt_truth = <span class="built_in">list</span>(y_test)          <span class="comment"># 获取真实值</span></span><br></pre></td></tr></table></figure><ul><li><strong>预测准确率</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Accruacy \t %.8f&quot;</span> % accuracy_score(ndt_truth, ndt_infer))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accruacy  0.83173278</span><br></pre></td></tr></table></figure><ul><li><strong>混淆矩阵</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(confusion_matrix(ndt_truth, ndt_infer))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[1992    0]</span><br><span class="line"> [ 403    0]]</span><br></pre></td></tr></table></figure><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/716905?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 分类问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【SVM】鸢尾花分类</title>
      <link href="/2020/08/11/%E3%80%90SVM%E3%80%91%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB/"/>
      <url>/2020/08/11/%E3%80%90SVM%E3%80%91%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<h1>1. 项目准备</h1><h2 id="1-1-问题导入-5">1.1. 问题导入</h2><p>构建一个模型，根据鸢尾花的花萼大小和花瓣大小将其分为三种不同的品种：<br><img src="https://ai-studio-static-online.cdn.bcebos.com/3576ab90c3704a5e896cb36657ca570b286df1d93419407db16474e1c35162bc#pic_center" alt=""></p><h2 id="1-2-数据集简介-4">1.2. 数据集简介</h2><p>数据集共包含150行数据，每一行数据由四个特征值及一个目标值组成。<br>其中，四个特征值分别为：萼片长度、萼片宽度、花瓣长度、花瓣宽度；<br>目标值是鸢尾花的类别，即：Iris Setosa、Iris Versicolour、Iris Virginica。</p><blockquote><p>这是数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/2301">鸢尾花数据集 - AI Studio</a></p></blockquote><hr><h1>2. 实验步骤</h1><h2 id="2-0-导入模块">2.0.导入模块</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h2 id="2-1-数据准备-2">2.1. 数据准备</h2><ul><li><strong>数据编码</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">iris_type</span>(<span class="params">s</span>):   <span class="comment"># 将鸢尾花的种类以整数形式表示，便于数据加载</span></span><br><span class="line">    it = &#123;</span><br><span class="line">        <span class="string">b&#x27;Iris-setosa&#x27;</span>: <span class="number">0</span>,      <span class="comment"># 山鸢尾</span></span><br><span class="line">        <span class="string">b&#x27;Iris-versicolor&#x27;</span>: <span class="number">1</span>,  <span class="comment"># 变色鸢尾</span></span><br><span class="line">        <span class="string">b&#x27;Iris-virginica&#x27;</span>: <span class="number">2</span>    <span class="comment"># 维吉尼亚鸢尾</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> it[s]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data_path = <span class="string">&#x27;iris.data&#x27;</span></span><br><span class="line">data = np.loadtxt(</span><br><span class="line">    data_path,                  <span class="comment"># 数据文件的路径</span></span><br><span class="line">    dtype=<span class="built_in">float</span>,                <span class="comment"># 数据类型</span></span><br><span class="line">    delimiter=<span class="string">&#x27;,&#x27;</span>,              <span class="comment"># 数据分隔符</span></span><br><span class="line">    converters=&#123;<span class="number">4</span>: iris_type&#125;   <span class="comment"># 将第5列数据用iris_type进行转换</span></span><br><span class="line">)   <span class="comment"># data为二维数组，且data.shape=(150, 5)</span></span><br></pre></td></tr></table></figure><ul><li><strong>数据分割</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x, y = np.split(</span><br><span class="line">    data,       <span class="comment"># 要切分的数组</span></span><br><span class="line">    (<span class="number">4</span>, ),      <span class="comment"># 沿轴切分的位置，前4列为x，第5列开始往后为y</span></span><br><span class="line">    axis=<span class="number">1</span>      <span class="comment"># 1代表纵向按列分割；默认0代表横向按行分割</span></span><br><span class="line">)</span><br><span class="line">x = x[:, <span class="number">0</span>:<span class="number">2</span>]   <span class="comment"># 为方便后期画图更直观，我们取x中的前两列作为特征</span></span><br></pre></td></tr></table></figure><ul><li><strong>数据集划分</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x_train, x_test, y_train, y_test = train_test_split(</span><br><span class="line">    x,                <span class="comment"># 要划分的样本特征集</span></span><br><span class="line">    y,                <span class="comment"># 要划分的样本结果集</span></span><br><span class="line">    random_state=<span class="number">1</span>,   <span class="comment"># 随机数种子</span></span><br><span class="line">    test_size=<span class="number">0.3</span>     <span class="comment"># 测试样本占比</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="2-2-模型搭建">2.2. 模型搭建</h2><ul><li><strong>惩罚系数 C</strong></li></ul><blockquote><ul><li>C值大，对误分类的惩罚增大，这样趋向于训练集测试的准确率很高，但泛化能力弱</li><li>C值小，对误分类的惩罚减小，允许容错，泛化能力较强</li></ul></blockquote><ul><li><strong>内核 kernel</strong></li></ul><blockquote><ul><li>“linear”代表“线性核”，“rbf”代表“高斯核”。</li></ul></blockquote><ul><li><em>高斯核函数参数 gamma</em> *</li></ul><blockquote><ul><li>gamma是选择rbf函数作为kernel后，该函数的一个参数，它隐含地决定了数据映射到新的特征空间后的分布。</li><li>gamma越小，分类界面越连续；gamma越大，分类界面越“散”，分类效果越好，但可能过拟合。</li></ul></blockquote><ul><li><strong>划分方法 decision_function_shape</strong></li></ul><blockquote><ul><li>“ovr”代表“one v rest”，即一个类别与其他类别进行划分；</li><li>“ovo”代表“one v one”，即将类别两两之间进行划分，用二分类的方法模拟多分类的结果。</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 高斯核的svm分类器：</span></span><br><span class="line"><span class="comment"># clf = svm.SVC(C=0.8, kernel=&#x27;rbf&#x27;, gamma=50, decision_function_shape=&#x27;ovr&#x27;)</span></span><br><span class="line"><span class="comment"># 线性核的svm分类器：</span></span><br><span class="line">clf = svm.SVC(C=<span class="number">0.5</span>, kernel=<span class="string">&#x27;linear&#x27;</span>, decision_function_shape=<span class="string">&#x27;ovr&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="2-3-模型训练-2">2.3. 模型训练</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">clf.fit(x_train,            <span class="comment"># 训练集特征向量</span></span><br><span class="line">        y_train.ravel())    <span class="comment"># 训练集目标值；ravel()函数可将矩阵转变成一维数组</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-4-模型评估-2">2.4. 模型评估</h2><ul><li><strong>评分与准确率</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">show_accuracy</span>(<span class="params">a, b, tip</span>):   <span class="comment"># 判断a和b是否相等，并计算准确率的均值</span></span><br><span class="line">    acc = a.ravel() == b.ravel()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s上的准确率 \t %.3f&quot;</span> % (tip, np.mean(acc)))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集上的评分 \t %.3f&quot;</span> % clf.score(x_train, y_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集上的评分 \t %.3f&quot;</span> % clf.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line">show_accuracy(clf.predict(x_train), y_train, <span class="string">&quot;训练集&quot;</span>)</span><br><span class="line">show_accuracy(clf.predict(x_test), y_test, <span class="string">&quot;测试集&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">训练集上的评分  0.819</span><br><span class="line">测试集上的评分  0.778</span><br><span class="line">训练集上的准确率  0.819</span><br><span class="line">测试集上的准确率  0.778</span><br></pre></td></tr></table></figure><ul><li><strong>决策函数的值</strong><br>决策函数的值表示x到各分割平面的距离。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">values = clf.decision_function(x_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Iris-setosa \t Iris-versicolor \t Iris-virginica&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> lt <span class="keyword">in</span> values:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%9.6f \t %9.6f \t\t %9.6f&quot;</span> % <span class="built_in">tuple</span>(lt))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">Iris-setosa  Iris-versicolor  Iris-virginica</span><br><span class="line">-0.500000   1.208873   2.291127</span><br><span class="line"> 2.063288  -0.076968   1.013680</span><br><span class="line"> 2.166750   0.917028  -0.083778</span><br><span class="line"> 2.114278   0.997652  -0.111931</span><br><span class="line"> 0.992554   2.063921  -0.056475</span><br><span class="line"> 2.117430   0.952555  -0.069985</span><br><span class="line"> 2.056150  -0.041847   0.985697</span><br><span class="line">-0.318666   1.026860   2.291806</span><br><span class="line">-0.271663   1.091503   2.180159</span><br><span class="line">-0.378276   1.142604   2.235671</span><br><span class="line">-0.221507   1.111050   2.110458</span><br><span class="line">-0.183312   2.100667   1.082645</span><br><span class="line">-0.054450   0.999278   2.055172</span><br><span class="line">-0.469778   1.178538   2.291240</span><br><span class="line">-0.057601   2.044375   1.013226</span><br><span class="line"> 2.174723   0.936981  -0.111704</span><br><span class="line">-0.133157   2.120214   1.012943</span><br><span class="line">-0.217521   2.121026   1.096495</span><br><span class="line"> 2.114278   0.997652  -0.111931</span><br><span class="line"> 2.163598   0.962125  -0.125724</span><br><span class="line">-0.210383   1.085906   2.124477</span><br><span class="line"> 2.212918   0.926599  -0.139517</span><br><span class="line">-0.133992   1.065140   2.068852</span><br><span class="line">-0.180161   1.055570   2.124590</span><br><span class="line">-0.233467   1.081121   2.152346</span><br><span class="line">-0.087824   2.074710   1.013113</span><br><span class="line">-0.203245   1.050785   2.152460</span><br><span class="line">-0.114894   1.059949   2.054945</span><br><span class="line"> 2.177874  -0.108116   0.930242</span><br><span class="line">-0.235784   2.181291   1.054492</span><br><span class="line">-0.206396   1.095882   2.110514</span><br><span class="line">-0.210383   1.085906   2.124477</span><br><span class="line">-0.029695   2.114210   0.915486</span><br><span class="line">-0.126854   1.030020   2.096834</span><br><span class="line">-0.094962   2.109831   0.985131</span><br><span class="line"> 2.105470  -0.077374   0.971904</span><br><span class="line"> 2.110292   0.987676  -0.097968</span><br><span class="line"> 2.204110  -0.148428   0.944318</span><br><span class="line">-0.203245   1.050785   2.152460</span><br><span class="line"> 2.190669   0.976887  -0.167556</span><br><span class="line">-0.160228   2.105452   1.054776</span><br><span class="line">-0.236619   1.126218   2.110401</span><br><span class="line">-0.095797   2.054758   1.041039</span><br><span class="line"> 2.113443  -0.057421   0.943978</span><br><span class="line"> 2.102319   0.967723  -0.070042</span><br><span class="line">-0.122032   2.095070   1.026963</span><br><span class="line"> 2.110292   0.987676  -0.097968</span><br><span class="line">-0.412485   1.162964   2.249521</span><br><span class="line">-0.168201   1.085499   2.082701</span><br><span class="line">-0.420458   1.143011   2.277447</span><br><span class="line">-0.248578   1.096288   2.152290</span><br><span class="line">-0.277966   2.181698   1.096268</span><br><span class="line">-0.092645   1.009660   2.082985</span><br><span class="line">-0.253400   1.031238   2.222161</span><br><span class="line">-0.053615   2.054351   0.999263</span><br><span class="line"> 2.153955  -0.167975   1.014019</span><br><span class="line">-0.122032   2.095070   1.026963</span><br><span class="line"> 2.065793   1.088253  -0.154046</span><br><span class="line">-0.110073   2.124999   0.985074</span><br><span class="line">-0.271663   1.091503   2.180159</span><br><span class="line"> 2.136527   0.947364  -0.083891</span><br><span class="line">-0.297898   1.131815   2.166083</span><br><span class="line"> 2.151639   0.932196  -0.083835</span><br><span class="line"> 2.174723   0.936981  -0.111704</span><br><span class="line">-0.111743   1.014852   2.096891</span><br><span class="line">-0.068726   2.069519   0.999207</span><br><span class="line">-0.237454   1.071144   2.166309</span><br><span class="line"> 2.121416   0.962532  -0.083948</span><br><span class="line"> 2.162763  -0.092948   0.930185</span><br><span class="line">-0.065574   1.024422   2.041152</span><br><span class="line"> 2.167585   0.972102  -0.139687</span><br><span class="line">-0.122032   2.095070   1.026963</span><br><span class="line"> 2.129389   0.982485  -0.111874</span><br><span class="line">-0.210383   1.085906   2.124477</span><br><span class="line"> 2.019625   1.078683  -0.098307</span><br><span class="line"> 2.182696   0.956934  -0.139630</span><br><span class="line">-0.161063   1.050379   2.110684</span><br><span class="line"> 2.209767   0.971696  -0.181462</span><br><span class="line">-0.038504   2.039183   0.999320</span><br><span class="line"> 2.175558   0.992055  -0.167613</span><br><span class="line">-0.110073   2.124999   0.985074</span><br><span class="line">-0.075029   2.159713   0.915316</span><br><span class="line"> 2.132541   0.937388  -0.069928</span><br><span class="line"> 2.095180   1.002844  -0.098024</span><br><span class="line"> 1.004513   2.093851  -0.098364</span><br><span class="line"> 2.243141   0.896263  -0.139403</span><br><span class="line">-0.095797   2.054758   1.041039</span><br><span class="line">-0.149103   1.080308   2.068795</span><br><span class="line"> 2.136527   0.947364  -0.083891</span><br><span class="line">-0.233467   1.081121   2.152346</span><br><span class="line">-0.072712   2.059543   1.013170</span><br><span class="line">-0.273979   2.191674   1.082305</span><br><span class="line">-0.275649   1.081527   2.194122</span><br><span class="line">-0.122032   2.095070   1.026963</span><br><span class="line"> 2.060137  -0.031871   0.971734</span><br><span class="line"> 2.076083   1.008035  -0.084118</span><br><span class="line">-0.194437   2.125811   1.068625</span><br><span class="line">-0.164214   2.095476   1.068739</span><br><span class="line">-0.344067   1.122245   2.221822</span><br><span class="line">-0.118046   2.105046   1.013000</span><br><span class="line">-0.202410   1.105859   2.096551</span><br><span class="line">-0.176174   1.065547   2.110627</span><br><span class="line">-0.247743   2.151362   1.096381</span><br><span class="line">-0.233467   1.081121   2.152346</span><br><span class="line"> 2.110292   0.987676  -0.097968</span><br></pre></td></tr></table></figure><h2 id="2-5-可视化展示">2.5. 可视化展示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x1_min, x1_max = x[:, <span class="number">0</span>].<span class="built_in">min</span>(), x[:, <span class="number">0</span>].<span class="built_in">max</span>()   <span class="comment"># 第0列的最小值和最大值</span></span><br><span class="line">x2_min, x2_max = x[:, <span class="number">1</span>].<span class="built_in">min</span>(), x[:, <span class="number">1</span>].<span class="built_in">max</span>()   <span class="comment"># 第1列的最小值和最大值</span></span><br><span class="line">x1, x2 = np.mgrid[x1_min:x1_max:<span class="number">200j</span>, x2_min:x2_max:<span class="number">200j</span>]   <span class="comment"># 生成网格采样点</span></span><br><span class="line"></span><br><span class="line">grid_test = np.stack((x1.flat, x2.flat), axis=<span class="number">1</span>)    <span class="comment"># 分别在第0维和第2维加入数组</span></span><br><span class="line">z = clf.decision_function(grid_test)                <span class="comment"># 样本到决策面的距离</span></span><br><span class="line">grid_hat = clf.predict(grid_test)                   <span class="comment"># 预测鸢尾花类别，得到分类值</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=[<span class="number">9</span>, <span class="number">6</span>])</span><br><span class="line">plt.title(<span class="string">&quot;svm in iris data classification&quot;</span>, fontsize=<span class="number">25</span>)</span><br><span class="line">tags = [<span class="string">&#x27;sepal length&#x27;</span>, <span class="string">&#x27;sepal width&#x27;</span>, <span class="string">&#x27;petal length&#x27;</span>, <span class="string">&#x27;petal width&#x27;</span>]   <span class="comment"># 特征标签</span></span><br><span class="line">plt.xlabel(tags[<span class="number">0</span>], fontsize=<span class="number">18</span>)</span><br><span class="line">plt.ylabel(tags[<span class="number">1</span>], fontsize=<span class="number">18</span>)</span><br><span class="line">plt.xlim(x1_min, x1_max)      <span class="comment"># x轴的上下限</span></span><br><span class="line">plt.ylim(x2_min, x2_max)      <span class="comment"># y轴的上下限</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制背景：</span></span><br><span class="line">cm_light = ListedColormap([<span class="string">&#x27;#FFB0B0&#x27;</span>, <span class="string">&#x27;#B0FFB0&#x27;</span>, <span class="string">&#x27;#B0B0FF&#x27;</span>])   <span class="comment"># 背景颜色</span></span><br><span class="line">grid_hat = grid_hat.reshape(x1.shape)         <span class="comment"># 使得grid_hat和x1的形状一致</span></span><br><span class="line">plt.pcolormesh(x1, x2, grid_hat, cmap=cm_light)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制样本点和测试点：</span></span><br><span class="line">cm_dark = ListedColormap([<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;blue&#x27;</span>])   <span class="comment"># 数据点颜色</span></span><br><span class="line">plt.scatter(x[:, <span class="number">0</span>], x[:, <span class="number">1</span>], c=np.squeeze(y), edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">50</span>, cmap=cm_dark)</span><br><span class="line">plt.scatter(x_test[:, <span class="number">0</span>], x_test[:, <span class="number">1</span>], s=<span class="number">120</span>, facecolor=<span class="string">&quot;none&quot;</span>, zorder=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/388e9d10720c46358a3884a1e201749a.png#pic_center" alt=""></p><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/709323?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 分类问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【线性回归】商品销量预测</title>
      <link href="/2020/08/05/%E3%80%90%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%91%E5%95%86%E5%93%81%E9%94%80%E9%87%8F%E9%A2%84%E6%B5%8B/"/>
      <url>/2020/08/05/%E3%80%90%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E3%80%91%E5%95%86%E5%93%81%E9%94%80%E9%87%8F%E9%A2%84%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<h1>1. 项目准备</h1><h2 id="1-1-回归问题">1.1. 回归问题</h2><p>回归模型可以理解为：存在一个点集，用一条曲线去拟合它分布的过程。<br>如果拟合曲线是一条直线，则称为线性回归。如果是一条二次曲线，则被称为二次回归。</p><h2 id="1-2-问题导入">1.2. 问题导入</h2><p>请根据以往在每件商品的广告费用和实际销量，预测未来商品的销量。</p><h2 id="1-3-数据集简介">1.3. 数据集简介</h2><p>数据共4列200行，每一行为一个特定的商品，前3列为输入特征，最后一列为输出特征。</p><ul><li><em>输入特征</em><br>TV：该商品用于电视上的广告费用（以千元为单位，下同）<br>Radio：在广播媒体上投资的广告费用<br>Newspaper：用于报纸媒体上的广告费用</li><li><em>输出特征</em><br>Sales：该商品的销量</li></ul><blockquote><p>这是数据集的下载链接：<a href="https://aistudio.baidu.com/aistudio/datasetdetail/48663">商品广告费与销量数据集 - AI Studio</a></p></blockquote><hr><h1>2. 实验步骤</h1><h2 id="2-0-导入模块-2">2.0.导入模块</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h2 id="2-1-数据获取">2.1. 数据获取</h2><ul><li><strong>获取并处理数据集</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&quot;Advertising.csv&quot;</span>)     <span class="comment"># 读取数据集</span></span><br><span class="line">x = df.drop(<span class="string">&quot;Sales&quot;</span>, axis=<span class="number">1</span>)  <span class="comment"># 提取特征值（除“Sales”外的所有字段的值）</span></span><br><span class="line">y = df[<span class="string">&quot;Sales&quot;</span>]               <span class="comment"># 提取目标值（字段“Sales”对应的字段值）</span></span><br></pre></td></tr></table></figure><ul><li><strong>数据的描述性统计分析</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(df.describe().T)    <span class="comment"># T代表转置矩阵</span></span><br><span class="line"><span class="comment"># 表头：特征数据个数，平均值，标准差，最小值，1/4中位数，1/2中位数，3/4中位数，最大值</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">           count      mean        std  min     25%     50%      75%    max</span><br><span class="line">TV         200.0  147.0425  85.854236  0.7  74.375  149.75  218.825  296.4</span><br><span class="line">Radio      200.0   23.2640  14.846809  0.0   9.975   22.90   36.525   49.6</span><br><span class="line">Newspaper  200.0   30.5540  21.778621  0.3  12.750   25.75   45.100  114.0</span><br><span class="line">Sales      200.0   14.0225   5.217457  1.6  10.375   12.90   17.400   27.0</span><br></pre></td></tr></table></figure><ul><li><strong>数据的相关性分析</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 相关系数绝对值越大，表示相关性越大；相关系数为正，表示正相关；相关系数为负，表示负相关</span></span><br><span class="line"><span class="built_in">print</span>(df.corr())</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">                 TV     Radio  Newspaper     Sales</span><br><span class="line">TV         1.000000  0.054809   0.056648  0.782224</span><br><span class="line">Radio      0.054809  1.000000   0.354104  0.576223</span><br><span class="line">Newspaper  0.056648  0.354104   1.000000  0.228299</span><br><span class="line">Sales      0.782224  0.576223   0.228299  1.000000</span><br></pre></td></tr></table></figure><h2 id="2-2-数据预处理">2.2. 数据预处理</h2><p>数据的预处理包括：数据的采样、数据的清洗、特征选择、特征降维、特征编码、规范化、数据集拆分等过程。<br>因为是已经清洗过的数据，因此我们下一步是进行训练集和测试集的划分，将整个数据集拆分成：训练集和测试集。<br>如果我们将其直接划分为训练集和数据集，那么就会造成数据分布不均的问题。好在sklearn为我们提供了划分训练集和数据集的方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[x_train, x_test,    <span class="comment"># 特征值x的训练集和测试集</span></span><br><span class="line"> y_train, y_test     <span class="comment"># 目标值y的训练集和测试集</span></span><br><span class="line">] = train_test_split(x, y, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="2-3-模型训练与预测">2.3. 模型训练与预测</h2><ul><li><strong>构建并训练模型</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr = LinearRegression()          <span class="comment"># 采用默认参数构造模型</span></span><br><span class="line">lr.fit(x_train, y_train)         <span class="comment"># 用训练集进行模型训练</span></span><br></pre></td></tr></table></figure><ul><li><strong>进行模型预测</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">lr_infer = lr.predict(x_test)    <span class="comment"># 用测试集进行模型预测</span></span><br><span class="line">lr_truth = <span class="built_in">list</span>(y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Round\t Truth \t Infer&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(lr_infer)):   <span class="comment"># 输出实际值和预测值</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%2s\t %5.2f \t %8.5f&quot;</span> % (i+<span class="number">1</span>, lr_truth[i], lr_infer[i]))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">Round Truth  Infer</span><br><span class="line"> 1 23.80  21.70910</span><br><span class="line"> 2 16.60  16.41055</span><br><span class="line"> 3  9.50   7.60955</span><br><span class="line"> 4 14.80  17.80770</span><br><span class="line"> 5 17.60  18.61464</span><br><span class="line"> 6 25.50  23.83574</span><br><span class="line"> 7 16.90  16.32489</span><br><span class="line"> 8 12.90  13.43226</span><br><span class="line"> 9 10.50   9.17173</span><br><span class="line">10 17.10  17.33385</span><br><span class="line">11 14.50  14.44479</span><br><span class="line">12 11.30   9.83512</span><br><span class="line">13 17.40  17.18798</span><br><span class="line">14 16.70  16.73087</span><br><span class="line">15 13.40  15.05529</span><br><span class="line">16 15.90  15.61434</span><br><span class="line">17 12.90  12.42542</span><br><span class="line">18 12.80  17.17716</span><br><span class="line">19  9.50  11.08828</span><br><span class="line">20 18.40  18.00538</span><br><span class="line">21 10.70   9.28439</span><br><span class="line">22 12.50  12.98458</span><br><span class="line">23  8.50   8.79951</span><br><span class="line">24 11.50  10.42382</span><br><span class="line">25 11.90  11.38465</span><br><span class="line">26 14.90  14.98083</span><br><span class="line">27 10.10   9.78853</span><br><span class="line">28 18.90  19.39643</span><br><span class="line">29 19.60  18.18100</span><br><span class="line">30 15.90  17.12808</span><br><span class="line">31 23.20  21.54670</span><br><span class="line">32 11.90  14.69809</span><br><span class="line">33 17.30  16.24641</span><br><span class="line">34 11.70  12.32115</span><br><span class="line">35 20.20  19.92423</span><br><span class="line">36 15.50  15.32499</span><br><span class="line">37 11.50  13.88727</span><br><span class="line">38 11.00  10.03162</span><br><span class="line">39 22.30  20.93106</span><br><span class="line">40  7.60   7.44937</span><br><span class="line">41  5.30   3.64696</span><br><span class="line">42  8.70   7.22020</span><br><span class="line">43  6.70   5.99628</span><br><span class="line">44 19.00  18.43382</span><br><span class="line">45  5.50   8.39408</span><br><span class="line">46 14.60  14.08371</span><br><span class="line">47 14.60  15.02196</span><br><span class="line">48 21.50  20.35836</span><br><span class="line">49 22.60  20.57036</span><br><span class="line">50 19.70  19.60637</span><br></pre></td></tr></table></figure><ul><li><strong>绘制真实值和预测值对比图</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=[<span class="number">8</span>, <span class="number">6</span>])</span><br><span class="line">plt.title(<span class="string">&quot;Commodity Sales&quot;</span>, fontsize=<span class="number">25</span>)</span><br><span class="line">x = np.arange(<span class="number">5</span>, <span class="number">25</span>)</span><br><span class="line">plt.plot(x, x)      <span class="comment"># 绘制x-y等值线</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;ground truth&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;infer result&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.scatter(lr_truth, lr_infer, color=<span class="string">&quot;green&quot;</span>, label=<span class="string">&quot;sales&quot;</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/f62ebb662c434f29b90093cb95101995.png#pic_center" alt=""></p><h2 id="2-4-模型评价">2.4. 模型评价</h2><p>对于分类问题，评价测度是准确率，但这种方法不适用于回归问题，回归问题需要使用针对连续数值的评价测度。<br>以下三种都可以，但我们一般选用第三种方法（<strong>均方根误差，Root Mean Squared Error，RMSE</strong>）。<br><img src="https://img-blog.csdnimg.cn/e7ffb578dcaa42ada44d5fbd780442c0.jpeg#pic_center" alt=""></p><ul><li><strong>输出模型的相关信息</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cols = [<span class="string">&quot;TV&quot;</span>, <span class="string">&quot;Radio&quot;</span>, <span class="string">&quot;Newspaper&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> i, val <span class="keyword">in</span> <span class="built_in">enumerate</span>(lr.coef_):   <span class="comment"># 输出各列的权重</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s 的权重\t %.5f&quot;</span> % (cols[i], val))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;截距\t\t %.5f&quot;</span> % lr.intercept_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集上的评分\t %.5f&quot;</span> % lr.score(x_train, y_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集上的评分\t %.5f&quot;</span> % lr.score(x_test, y_test))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TV 的权重 0.04656</span><br><span class="line">Radio 的权重 0.17916</span><br><span class="line">Newspaper 的权重 0.00345</span><br><span class="line">截距 2.87697</span><br><span class="line">训练集上的评分 0.89031</span><br><span class="line">测试集上的评分 0.91562</span><br></pre></td></tr></table></figure><ul><li><strong>输出模型的评价测度</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mae_infer = metrics.mean_absolute_error(y_test, lr_infer)   <span class="comment"># MAE：平均绝对误差</span></span><br><span class="line">mse_infer = metrics.mean_squared_error(y_test, lr_infer)    <span class="comment"># MSE：均方差</span></span><br><span class="line">rmse_infer = np.sqrt(mse_infer)                  <span class="comment"># RMSE：均方根差，即MSE的平方根</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MAE：%.6f \t MSE：%.6f \t RMSE：%.6f&quot;</span> % (mae_infer, mse_infer, rmse_infer))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAE：1.066892  MSE：1.973046  RMSE：1.404651</span><br></pre></td></tr></table></figure><h2 id="2-5-模型优化">2.5. 模型优化</h2><p>由于Newspaper和销量之间的相关性非常小 (约0.00345)，因此我们可以移除这个特征，然后看看线性回归模型预测结果的RMSE如何。</p><ul><li><strong>处理数据集</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = df[[<span class="string">&quot;TV&quot;</span>, <span class="string">&quot;Radio&quot;</span>]]    <span class="comment"># 提取新的特征值x（“TV”和“Radio”字段的值）</span></span><br><span class="line">y = df[<span class="string">&quot;Sales&quot;</span>]            <span class="comment"># 提取新的目标值y（字段“Sales”的值）</span></span><br><span class="line">[x_train, x_test,     <span class="comment"># 特征值x的训练集和测试集</span></span><br><span class="line"> y_train, y_test      <span class="comment"># 目标值y的训练集和测试集</span></span><br><span class="line">] = train_test_split(x, y, random_state=<span class="number">1</span>)   <span class="comment"># 划分训练集和测试集</span></span><br></pre></td></tr></table></figure><ul><li><strong>训练和测试模型</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nlr = LinearRegression()          <span class="comment"># 采用默认参数构建线性回归模型</span></span><br><span class="line">nlr.fit(x_train, y_train)         <span class="comment"># 用训练集进行模型训练</span></span><br><span class="line">nlr_infer = nlr.predict(x_test)   <span class="comment"># 用测试集进行模型预测</span></span><br><span class="line">nlr_truth = <span class="built_in">list</span>(y_test)          <span class="comment"># 获取实际数据</span></span><br></pre></td></tr></table></figure><ul><li><strong>绘制真实值和预测值对比图</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=[<span class="number">8</span>, <span class="number">6</span>])</span><br><span class="line">plt.title(<span class="string">&quot;Commodity Sales&quot;</span>, fontsize=<span class="number">25</span>)</span><br><span class="line">x = np.arange(<span class="number">5</span>, <span class="number">25</span>)</span><br><span class="line">plt.plot(x, x)      <span class="comment"># 绘制x-y等值线</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;ground truth&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;infer result&quot;</span>, fontsize=<span class="number">18</span>)</span><br><span class="line">plt.scatter(lr_truth, lr_infer, <span class="number">30</span>, color=<span class="string">&quot;green&quot;</span>, label=<span class="string">&quot;old sales data&quot;</span>)</span><br><span class="line">plt.scatter(nlr_truth, nlr_infer, <span class="number">25</span>, color=<span class="string">&quot;red&quot;</span>, label=<span class="string">&quot;new sales data&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;upper left&quot;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/a2c5dfba6ee049079d5af8efa058d437.png#pic_center" alt=""></p><ul><li><strong>输出模型的相关信息</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vals = <span class="built_in">list</span>(nlr.coef_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;TV列的权重\t %.5f&quot;</span> % vals[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Radio列的权重\t %.5f&quot;</span> % vals[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;截距\t\t %.5f&quot;</span> % nlr.intercept_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集上的评分\t %.5f&quot;</span> % nlr.score(x_train, y_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集上的评分\t %.5f&quot;</span> % nlr.score(x_test, y_test))</span><br><span class="line"></span><br><span class="line">mse_infer = metrics.mean_squared_error(y_test, nlr_infer)  <span class="comment"># MSE：均方误差</span></span><br><span class="line">rmse_infer = np.sqrt(mse_infer)                         <span class="comment"># RMSE：均方根误差</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;评价测度(RMSE)\t %.6f&quot;</span> % rmse_infer)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">TV列的权重 0.04660</span><br><span class="line">Radio列的权重 0.18118</span><br><span class="line">截距 2.92724</span><br><span class="line">训练集上的评分 0.89015</span><br><span class="line">测试集上的评分 0.91762</span><br><span class="line">评价测度(RMSE) 1.387903</span><br></pre></td></tr></table></figure><hr><h1>3. 优化结论</h1><ul><li>由上面的结果可以看出，移除相关性较弱的特征后，均方根误差RMES会变得更小一点，模型的拟合效果也会更好。</li><li>机器学习中有“奥卡姆剃刀”的原理，如果能够用简单模型解决问题，那么就不使用复杂模型，因为复杂模型往往增加了不确定性，造成过多的人力和物力成本，且容易过拟合。</li></ul><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/697188?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 回归问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>新冠疫情可视化分析</title>
      <link href="/2020/04/23/%E6%96%B0%E5%86%A0%E7%96%AB%E6%83%85%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90/"/>
      <url>/2020/04/23/%E6%96%B0%E5%86%A0%E7%96%AB%E6%83%85%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 项目准备</h1><h2 id="1-1-问题导入-12">1.1. 问题导入</h2><p>数据可视化，是一种利用计算机图形学和图像处理技术，将数据转换成图像在屏幕上显示出来，再进行交互处理的理论、方法和技术。<br>本次实践基于丁香园公开的统计数据，实现新冠疫情可视化，包括疫情地图、疫情增长趋势图、疫情分布图等。</p><h2 id="1-2-Pyecharts模块">1.2. Pyecharts模块</h2><p>我们使用的数据可视化模块是Pyecharts，具体使用方法可参考&gt;&gt; <a href="https://pyecharts.org/#/zh-cn/">Pyecharts 中文手册</a></p><ul><li><strong>安装pyecharts</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pyecharts</span><br></pre></td></tr></table></figure><ul><li><strong>pyecharts 配置项</strong></li></ul><blockquote><ul><li><strong>系列配置组件</strong><br>系列配置项 set_series_opts(),可配置图元样式、文字样式、标签样式、点线样式等</li><li><strong>全局配置组件</strong><br>全局配置项 set_global_opts()，可配置标题、动画、坐标轴、图例等<br><img src="https://img-blog.csdnimg.cn/7c381070fa4c4aad9c467735d8fb0816.png#pic_center" alt=""></li></ul></blockquote><hr><h1>2. 实验步骤</h1><h2 id="2-1-爬取疫情数据">2.1. 爬取疫情数据</h2><ul><li><strong>爬虫过程</strong><br>模拟浏览器 → 往目标站点发送请求 → 接收响应数据 → 提取有用的数据 → 保存到本地/数据库</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 爬取丁香园实时统计数据，保存到data目录的JSON文件中，以当前日期作为文件名</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crawlCurrentData</span>():</span><br><span class="line">    resp = requests.get(<span class="string">&#x27;https://ncov.dxy.cn/ncovh5/view/pneumonia&#x27;</span>)</span><br><span class="line">    resp.encoding = resp.apparent_encoding</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        content = re.search(<span class="string">r&quot;window.getAreaStat = (.*?)&#125;]&#125;catch&quot;</span>, resp.text, re.S)</span><br><span class="line">        texts = content.group()          <span class="comment"># 获取匹配正则表达式的整体结果</span></span><br><span class="line">        string = texts.replace(<span class="string">&quot;window.getAreaStat = &quot;</span>, <span class="string">&quot;&quot;</span>).replace(<span class="string">&quot;&#125;catch&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">        json_data = json.loads(string)   <span class="comment"># 转化为dict类型</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;data/%s.json&quot;</span> % today, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            json.dump(json_data, f, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;&lt;Response [%s]&gt;: https://ncov.dxy.cn/ncovh5/view/pneumonia&#x27;</span> % resp.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取各个省份的历史统计数据，保存到data目录的JSON文件中</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crawlStatisticsData</span>():</span><br><span class="line">    data = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;data/%s.json&quot;</span> % today, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        array = json.loads(f.read())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> province <span class="keyword">in</span> array:</span><br><span class="line">        resp = requests.get(province[<span class="string">&#x27;statisticsData&#x27;</span>])   <span class="comment"># 获取省份的历史统计数据</span></span><br><span class="line">        resp.encoding = resp.apparent_encoding</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data[province[<span class="string">&quot;provinceShortName&quot;</span>]] = json.loads(resp.text)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&lt;Response [%s]&gt;：[%s]&#x27;</span> % (resp.status_code, province[<span class="string">&#x27;statisticsData&#x27;</span>]))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;data/history.json&quot;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(data, f, ensure_ascii=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">today = datetime.date.today().strftime(<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">crawlCurrentData()</span><br><span class="line">crawlStatisticsData()</span><br></pre></td></tr></table></figure><h2 id="2-2-绘制疫情地图">2.2. 绘制疫情地图</h2><h3 id="1-全国疫情地图">(1) 全国疫情地图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Map</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createChinaMap</span>(<span class="params">data, title</span>):    <span class="comment"># 创建中国疫情地图</span></span><br><span class="line">    <span class="comment"># (1) 创建Map对象并配置数据：</span></span><br><span class="line">    m = Map(</span><br><span class="line">        init_opts=opts.InitOpts(width=<span class="string">&#x27;1400px&#x27;</span>, height=<span class="string">&#x27;700px&#x27;</span>)   <span class="comment"># 设置图像的长和宽</span></span><br><span class="line">    )   <span class="comment"># 创建Map对象</span></span><br><span class="line">    m.add(title, [<span class="built_in">list</span>(z) <span class="keyword">for</span> z <span class="keyword">in</span> data.items()], <span class="string">&#x27;china&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># (2) 设置系列配置项：</span></span><br><span class="line">    m.set_series_opts(</span><br><span class="line">        label_opts=opts.LabelOpts(font_size=<span class="number">12</span>),   <span class="comment"># 设置标签的字体样式</span></span><br><span class="line">        is_show=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># (3) 设置全局配置项：</span></span><br><span class="line">    pieces = [</span><br><span class="line">        &#123;<span class="string">&#x27;min&#x27;</span>: <span class="number">10000</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#6F171F&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;max&#x27;</span>: <span class="number">9999</span>, <span class="string">&#x27;min&#x27;</span>: <span class="number">1000</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#9c1414&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;max&#x27;</span>: <span class="number">999</span>, <span class="string">&#x27;min&#x27;</span>: <span class="number">500</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#d92727&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;max&#x27;</span>: <span class="number">499</span>, <span class="string">&#x27;min&#x27;</span>: <span class="number">100</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#E35B52&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;max&#x27;</span>: <span class="number">99</span>, <span class="string">&#x27;min&#x27;</span>: <span class="number">10</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#F39E86&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;max&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;min&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#FDEBD0&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;min&quot;</span>: <span class="number">0</span>, <span class="string">&quot;max&quot;</span>: <span class="number">0</span>, <span class="string">&quot;color&quot;</span>: <span class="string">&quot;#f0f0f0&quot;</span>&#125;</span><br><span class="line">    ]   <span class="comment"># 自定义每个区间的范围及其特殊样式</span></span><br><span class="line">    m.set_global_opts(</span><br><span class="line">        title_opts=opts.TitleOpts(</span><br><span class="line">            title = <span class="string">&#x27;全国%s病例分布图&#x27;</span> % title,</span><br><span class="line">            subtitle = <span class="string">&quot;更新时间：&quot;</span> + today</span><br><span class="line">        ),    <span class="comment"># 设置地图的一级标题和二级标题</span></span><br><span class="line">        legend_opts=opts.LegendOpts(is_show=<span class="literal">False</span>),  <span class="comment"># 不显示图例</span></span><br><span class="line">        visualmap_opts=opts.VisualMapOpts(</span><br><span class="line">            is_piecewise=<span class="literal">True</span>,     <span class="comment"># 分段显示数据</span></span><br><span class="line">            pieces=pieces,         <span class="comment"># 各区间的显示样式</span></span><br><span class="line">            is_show=<span class="literal">True</span>           <span class="comment"># 是否显示视觉映射配置</span></span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># (4) 保存疫情地图：</span></span><br><span class="line">    m.render(path=<span class="string">&quot;data/国内疫情地图-%s.html&quot;</span> % title)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------ 1. 读取初始数据文件 ------</span></span><br><span class="line">today = datetime.date.today().strftime(<span class="string">&quot;%Y-%m-%d&quot;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/%s.json&#x27;</span> % today, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json_array = json.loads(f.read())</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 2. 提取全国确诊数据 ------</span></span><br><span class="line">cn_confirm = &#123;<span class="string">&quot;count&quot;</span>: &#123;&#125;, <span class="string">&quot;current&quot;</span>: &#123;&#125;&#125;   <span class="comment"># count：累计确诊；current：现存确诊</span></span><br><span class="line"><span class="keyword">for</span> province <span class="keyword">in</span> json_array:</span><br><span class="line">    name = province[<span class="string">&quot;provinceShortName&quot;</span>]    <span class="comment"># 省级行政区名</span></span><br><span class="line">    cn_confirm[<span class="string">&quot;count&quot;</span>][name] = province[<span class="string">&quot;confirmedCount&quot;</span>]</span><br><span class="line">    <span class="comment"># cn_confirm[&quot;current&quot;][name] = province[&quot;currentConfirmedCount&quot;]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;累计确诊：&quot;</span>, cn_confirm[<span class="string">&quot;count&quot;</span>])</span><br><span class="line"><span class="comment"># print(&quot;现存确诊：&quot;, cn_confirm[&quot;current&quot;])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 3. 绘制全国疫情地图 ------</span></span><br><span class="line">createChinaMap(cn_confirm[<span class="string">&quot;count&quot;</span>], <span class="string">&quot;累计确诊&quot;</span>)</span><br><span class="line"><span class="comment"># createChinaMap(cn_confirm[&quot;current&quot;], &quot;现存确诊&quot;)</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">累计确诊： &#123;&#x27;香港&#x27;: 4657, &#x27;新疆&#x27;: 902, &#x27;上海&#x27;: 875, &#x27;山东&#x27;: 830, &#x27;台湾&#x27;: 487, &#x27;广东&#x27;: 1725, &#x27;陕西&#x27;: 360, &#x27;四川&#x27;: 628, &#x27;辽宁&#x27;: 261, &#x27;天津&#x27;: 216, &#x27;江苏&#x27;: 665, &#x27;浙江&#x27;: 1277, &#x27;福建&#x27;: 371, &#x27;河北&#x27;: 354, &#x27;云南&#x27;: 195, &#x27;江西&#x27;: 935, &#x27;北京&#x27;: 935, &#x27;内蒙古&#x27;: 260, &#x27;湖北&#x27;: 68139, &#x27;黑龙江&#x27;: 948, &#x27;河南&#x27;: 1276, &#x27;湖南&#x27;: 1019, &#x27;安徽&#x27;: 991, &#x27;重庆&#x27;: 583, &#x27;广西&#x27;: 255, &#x27;山西&#x27;: 201, &#x27;海南&#x27;: 171, &#x27;甘肃&#x27;: 169, &#x27;吉林&#x27;: 157, &#x27;贵州&#x27;: 147, &#x27;宁夏&#x27;: 75, &#x27;澳门&#x27;: 46, &#x27;青海&#x27;: 18, &#x27;西藏&#x27;: 1&#125;</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/ad8ced28f1f642de886b574e7e66e866.jpeg#pic_center" alt=""></p><h3 id="2-省级疫情地图">(2) 省级疫情地图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Map</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">formatCityName</span>(<span class="params">name, defined_cities</span>):   <span class="comment"># 规范化城市名</span></span><br><span class="line">    <span class="keyword">for</span> city <span class="keyword">in</span> defined_cities:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>((<span class="built_in">set</span>(city) &amp; <span class="built_in">set</span>(name))) == <span class="built_in">len</span>(name):</span><br><span class="line">            <span class="keyword">if</span> city.endswith(<span class="string">&quot;市&quot;</span>) <span class="keyword">or</span> city.endswith(<span class="string">&quot;区&quot;</span>) <span class="keyword">or</span> city.endswith(<span class="string">&quot;县&quot;</span>) <span class="keyword">or</span> city.endswith(<span class="string">&quot;自治州&quot;</span>):</span><br><span class="line">                <span class="keyword">return</span> city</span><br><span class="line">            <span class="keyword">return</span> city + <span class="string">&quot;市&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createProvinceMap</span>(<span class="params">data, province, title</span>):    <span class="comment"># 创建省级疫情地图</span></span><br><span class="line">    <span class="comment"># (1) 创建Map对象并配置数据：</span></span><br><span class="line">    m = Map(</span><br><span class="line">        init_opts=opts.InitOpts(width=<span class="string">&#x27;1400px&#x27;</span>, height=<span class="string">&#x27;700px&#x27;</span>)   <span class="comment"># 设置图像的长和宽</span></span><br><span class="line">    )   <span class="comment"># 创建Map对象</span></span><br><span class="line">    m.add(title, [<span class="built_in">list</span>(z) <span class="keyword">for</span> z <span class="keyword">in</span> data.items()], province)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># (2) 设置系列配置项：</span></span><br><span class="line">    m.set_series_opts(</span><br><span class="line">        label_opts=opts.LabelOpts(font_size=<span class="number">12</span>),   <span class="comment"># 设置标签的字体样式</span></span><br><span class="line">        is_show=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># (3) 设置全局配置项：</span></span><br><span class="line">    pieces = [</span><br><span class="line">        &#123;<span class="string">&#x27;min&#x27;</span>: <span class="number">10000</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#6F171F&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;max&#x27;</span>: <span class="number">9999</span>, <span class="string">&#x27;min&#x27;</span>: <span class="number">1000</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#9c1414&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;max&#x27;</span>: <span class="number">999</span>, <span class="string">&#x27;min&#x27;</span>: <span class="number">500</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#d92727&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;max&#x27;</span>: <span class="number">499</span>, <span class="string">&#x27;min&#x27;</span>: <span class="number">100</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#E35B52&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;max&#x27;</span>: <span class="number">99</span>, <span class="string">&#x27;min&#x27;</span>: <span class="number">10</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#F39E86&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&#x27;max&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;min&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;color&#x27;</span>: <span class="string">&#x27;#FDEBD0&#x27;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;min&quot;</span>: <span class="number">0</span>, <span class="string">&quot;max&quot;</span>: <span class="number">0</span>, <span class="string">&quot;color&quot;</span>: <span class="string">&quot;#f0f0f0&quot;</span>&#125;</span><br><span class="line">    ]   <span class="comment"># 自定义每个区间的范围及其特殊样式</span></span><br><span class="line">    m.set_global_opts(</span><br><span class="line">        title_opts=opts.TitleOpts(</span><br><span class="line">            title = <span class="string">&#x27;%s%s病例分布图&#x27;</span> % (province, title),</span><br><span class="line">            subtitle = <span class="string">&quot;更新时间：&quot;</span> + today</span><br><span class="line">        ),    <span class="comment"># 设置地图的一级标题和二级标题</span></span><br><span class="line">        legend_opts=opts.LegendOpts(is_show=<span class="literal">False</span>),  <span class="comment"># 不显示图例</span></span><br><span class="line">        visualmap_opts=opts.VisualMapOpts(</span><br><span class="line">            is_piecewise=<span class="literal">True</span>,     <span class="comment"># 分段显示数据</span></span><br><span class="line">            pieces=pieces,         <span class="comment"># 各区间的显示样式</span></span><br><span class="line">            is_show=<span class="literal">True</span>           <span class="comment"># 是否显示视觉映射配置</span></span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># (4) 保存疫情地图：</span></span><br><span class="line">    m.render(path=<span class="string">&quot;data/%s疫情地图-%s.html&quot;</span> % (province, title))</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------ 1. 读取初始数据文件 ------</span></span><br><span class="line">today = datetime.date.today().strftime(<span class="string">&quot;%Y-%m-%d&quot;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/%s.json&#x27;</span> % today, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json_list = json.loads(f.read())</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;data/data24815/pycharts_city.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;UTF-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    defined_cities = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> f.readlines()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 2. 处理所选省份的确诊数据 ------</span></span><br><span class="line">province_name = <span class="string">&#x27;湖北&#x27;</span></span><br><span class="line">confirm = &#123;<span class="string">&quot;count&quot;</span>: &#123;&#125;, <span class="string">&quot;current&quot;</span>: &#123;&#125;&#125;   <span class="comment"># count：累计确诊；current：现存确诊</span></span><br><span class="line"><span class="keyword">for</span> province <span class="keyword">in</span> json_list:</span><br><span class="line">    <span class="keyword">if</span> province[<span class="string">&quot;provinceShortName&quot;</span>] == province_name:</span><br><span class="line">        city_array = province[<span class="string">&#x27;cities&#x27;</span>]   <span class="comment"># 获取所辖城市的疫情数据</span></span><br><span class="line">        <span class="keyword">for</span> city <span class="keyword">in</span> city_array:</span><br><span class="line">            city_name = formatCityName(city[<span class="string">&quot;cityName&quot;</span>], defined_cities)</span><br><span class="line">            confirm[<span class="string">&quot;count&quot;</span>][city_name] = city[<span class="string">&quot;confirmedCount&quot;</span>]           <span class="comment"># 累计确诊</span></span><br><span class="line">            confirm[<span class="string">&quot;current&quot;</span>][city_name] = city[<span class="string">&quot;currentConfirmedCount&quot;</span>]  <span class="comment"># 现存确诊</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;%s累计确诊：&quot;</span> % province_name, confirm[<span class="string">&quot;count&quot;</span>])</span><br><span class="line">        <span class="comment"># print(&quot;%s现存确诊：&quot; % province_name, confirm[&quot;current&quot;])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 3. 绘制省级疫情地图 ------</span></span><br><span class="line">createProvinceMap(confirm[<span class="string">&quot;count&quot;</span>], province_name, <span class="string">&quot;累计确诊&quot;</span>)</span><br><span class="line"><span class="comment"># createProvinceMap(confirm[&quot;current&quot;], province_name, &quot;现存确诊&quot;)</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">湖北累计确诊： &#123;&#x27;武汉市&#x27;: 50344, &#x27;孝感市&#x27;: 3518, &#x27;黄冈市&#x27;: 2907, &#x27;荆州市&#x27;: 1580, &#x27;鄂州市&#x27;: 1394, &#x27;随州市&#x27;: 1307, &#x27;襄阳市&#x27;: 1175, &#x27;黄石市&#x27;: 1015, &#x27;宜昌市&#x27;: 931, &#x27;荆门市&#x27;: 928, &#x27;咸宁市&#x27;: 836, &#x27;十堰市&#x27;: 672, &#x27;仙桃市&#x27;: 575, &#x27;天门市&#x27;: 496, &#x27;恩施土家族苗族自治州&#x27;: 252, &#x27;潜江市&#x27;: 198, &#x27;神农架林区&#x27;: 11&#125;</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/0482f34e6f5f4fe8bdf62c5fae337c53.jpeg#pic_center" alt=""></p><h2 id="2-3-绘制疫情趋势图">2.3. 绘制疫情趋势图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Line</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 1. 读取原始数据文件 ------</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;data/history.json&quot;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json_dict = json.loads(f.read())</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 2. 提取各省份新增确诊数据 ------</span></span><br><span class="line">history = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> province <span class="keyword">in</span> json_dict:    <span class="comment"># 提取各省份2月1日至4月7日的新增确诊数据</span></span><br><span class="line">    history[province] = []</span><br><span class="line">    <span class="keyword">for</span> day <span class="keyword">in</span> json_dict[province][<span class="string">&quot;data&quot;</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="number">20200201</span> &lt;= day[<span class="string">&quot;dateId&quot;</span>] &lt;= <span class="number">20200407</span>:</span><br><span class="line">            history[province].append(day[<span class="string">&quot;confirmedIncr&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 3.1.获取日期列表 ------</span></span><br><span class="line">dates = [<span class="string">&quot;%s-%s&quot;</span> % (<span class="built_in">str</span>(d[<span class="string">&quot;dateId&quot;</span>])[<span class="number">4</span>:<span class="number">6</span>], <span class="built_in">str</span>(d[<span class="string">&quot;dateId&quot;</span>])[<span class="number">6</span>:<span class="number">8</span>])</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> json_dict[<span class="string">&quot;湖北&quot;</span>][<span class="string">&quot;data&quot;</span>] <span class="keyword">if</span> <span class="number">20200201</span>&lt;=d[<span class="string">&quot;dateId&quot;</span>]&lt;=<span class="number">20200407</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 3.2.提取全国新增确诊数据 ------</span></span><br><span class="line">cn_history = np.array([<span class="number">0</span>] * <span class="built_in">len</span>(dates))   <span class="comment"># 初始化一个长度为len(dates)的数组</span></span><br><span class="line"><span class="keyword">for</span> province <span class="keyword">in</span> history:</span><br><span class="line">    cn_history += np.array(history[province])</span><br><span class="line">cn_history = cn_history.tolist()   <span class="comment"># 将numpy数组转化成列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 3.3.提取湖北及其他省份的数据 ------</span></span><br><span class="line">hb_history = history[<span class="string">&quot;湖北&quot;</span>]</span><br><span class="line">ot_history = [cn_history[i]-hb_history[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(dates))]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 4. 绘制新增确诊趋势图 ------</span></span><br><span class="line">line = Line(</span><br><span class="line">    init_opts=opts.InitOpts(width=<span class="string">&#x27;1500px&#x27;</span>, height=<span class="string">&#x27;700px&#x27;</span>)  <span class="comment"># 设置图像的长和宽</span></span><br><span class="line">)                         <span class="comment"># 创建Line对象</span></span><br><span class="line">line.add_xaxis(dates)     <span class="comment"># 添加横轴数据</span></span><br><span class="line">line.add_yaxis(</span><br><span class="line">    <span class="string">&quot;全国新增确诊病例&quot;</span>, cn_history, is_smooth=<span class="literal">True</span>,      <span class="comment"># 图例、数据、是否平滑曲线</span></span><br><span class="line">    linestyle_opts=opts.LineStyleOpts(width=<span class="number">3</span>, color=<span class="string">&quot;#B44038&quot;</span>),  <span class="comment"># 线条样式配置项</span></span><br><span class="line">    itemstyle_opts=opts.ItemStyleOpts(</span><br><span class="line">        color=<span class="string">&#x27;#B44038&#x27;</span>, border_color=<span class="string">&quot;#B44038&quot;</span>, border_width=<span class="number">6</span></span><br><span class="line">    )   <span class="comment"># 图元样式设置项</span></span><br><span class="line">)</span><br><span class="line">line.add_yaxis(</span><br><span class="line">    <span class="string">&quot;湖北新增确诊病例&quot;</span>, hb_history, is_smooth=<span class="literal">True</span>,</span><br><span class="line">    linestyle_opts=opts.LineStyleOpts(width=<span class="number">2</span>, color=<span class="string">&quot;#4E87ED&quot;</span>),</span><br><span class="line">    label_opts=opts.LabelOpts(position=<span class="string">&quot;bottom&quot;</span>),    <span class="comment"># 设置数据标签的位置</span></span><br><span class="line">    itemstyle_opts=opts.ItemStyleOpts(</span><br><span class="line">        color=<span class="string">&quot;#4E87ED&quot;</span>, border_color=<span class="string">&quot;#4E87ED&quot;</span>, border_width=<span class="number">4</span></span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line">line.add_yaxis(</span><br><span class="line">    <span class="string">&quot;其他省份新增确诊&quot;</span>, ot_history, is_smooth=<span class="literal">True</span>,</span><br><span class="line">    linestyle_opts=opts.LineStyleOpts(width=<span class="number">2</span>, color=<span class="string">&quot;#F1A846&quot;</span>),</span><br><span class="line">    label_opts=opts.LabelOpts(position=<span class="string">&quot;bottom&quot;</span>),</span><br><span class="line">    itemstyle_opts=opts.ItemStyleOpts(</span><br><span class="line">        color=<span class="string">&quot;#F1A846&quot;</span>, border_color=<span class="string">&quot;#F1A846&quot;</span>, border_width=<span class="number">4</span></span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line">line.set_global_opts(</span><br><span class="line">    title_opts=opts.TitleOpts(title=<span class="string">&quot;新增确诊趋势图&quot;</span>, subtitle=<span class="string">&quot;数据来源：丁香园&quot;</span>),</span><br><span class="line">    yaxis_opts=opts.AxisOpts(</span><br><span class="line">        max_=<span class="number">16000</span>, min_=<span class="number">1</span>, type_=<span class="string">&quot;log&quot;</span>,                  <span class="comment"># 坐标轴配置项</span></span><br><span class="line">        splitline_opts=opts.SplitLineOpts(is_show=<span class="literal">True</span>),  <span class="comment"># 分割线配置项</span></span><br><span class="line">        axisline_opts=opts.AxisLineOpts(is_show=<span class="literal">True</span>)     <span class="comment"># 坐标轴刻度线配置项</span></span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line">line.render(<span class="string">&quot;data/国内新增确诊数趋势图.html&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/46f5fe2ffe004d6985e0194013b93bba.jpeg#pic_center" alt=""></p><h2 id="2-4-绘制疫情分布饼图">2.4. 绘制疫情分布饼图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Pie</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createPieGraph</span>(<span class="params">data, title</span>):</span><br><span class="line">    pie = Pie(</span><br><span class="line">        init_opts=opts.InitOpts(width=<span class="string">&#x27;900px&#x27;</span>, height=<span class="string">&#x27;600px&#x27;</span>)  <span class="comment"># 设置图像的长和宽</span></span><br><span class="line">    )    <span class="comment"># 创建Pie对象</span></span><br><span class="line">    data_pair = [<span class="built_in">list</span>(z) <span class="keyword">for</span> z <span class="keyword">in</span> data.items()]</span><br><span class="line">    data_pair.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    pie.add(title, data_pair,</span><br><span class="line">            center=[<span class="string">&quot;45%&quot;</span>, <span class="string">&quot;65%&quot;</span>],  <span class="comment"># 饼图圆心坐标：前者相对于宽度，后者相对于高度</span></span><br><span class="line">            radius=<span class="string">&quot;180&quot;</span>)           <span class="comment"># 饼图的半径</span></span><br><span class="line">    pie.set_series_opts(</span><br><span class="line">        label_opts=opts.LabelOpts(formatter=<span class="string">&quot;&#123;b&#125;: &#123;c&#125;&quot;</span>,   <span class="comment"># 标签格式</span></span><br><span class="line">                                  font_size=<span class="number">15</span>)           <span class="comment"># 字体大小</span></span><br><span class="line">    )   <span class="comment"># 系列配置项</span></span><br><span class="line">    pie.set_global_opts(</span><br><span class="line">        title_opts=opts.TitleOpts(title=<span class="string">&quot;国内%s分布饼图&quot;</span> % title,</span><br><span class="line">                                  subtitle=<span class="string">&quot;更新时间：%s&quot;</span> % today),   <span class="comment"># 设置标题</span></span><br><span class="line">        legend_opts=opts.LegendOpts(pos_top=<span class="string">&quot;20%&quot;</span>,       <span class="comment"># 图例离顶部的距离</span></span><br><span class="line">                                    pos_left=<span class="string">&quot;80%&quot;</span>,      <span class="comment"># 图例离左侧的距离</span></span><br><span class="line">                                    orient=<span class="string">&quot;vertical&quot;</span>)   <span class="comment"># 图例的布局朝向</span></span><br><span class="line">    )   <span class="comment"># 全局配置项</span></span><br><span class="line">    pie.render(<span class="string">&quot;data/国内%s分布饼图.html&quot;</span> % title)   <span class="comment"># 保存图像至文件</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------ 1. 读取原始数据文件 ------</span></span><br><span class="line">today = datetime.date.today().strftime(<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;data/%s.json&quot;</span> % today, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json_list = json.loads(f.read())</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 2. 提取全国确诊数据 ------</span></span><br><span class="line">cn_confirm = &#123;<span class="string">&quot;count&quot;</span>: &#123;&#125;, <span class="string">&quot;current&quot;</span>: &#123;&#125;&#125;   <span class="comment"># count：累计确诊；current：现存确诊</span></span><br><span class="line"><span class="keyword">for</span> province <span class="keyword">in</span> json_array:</span><br><span class="line">    name = province[<span class="string">&quot;provinceShortName&quot;</span>]    <span class="comment"># 省级行政区名</span></span><br><span class="line">    cn_confirm[<span class="string">&quot;count&quot;</span>][name] = province[<span class="string">&quot;confirmedCount&quot;</span>]</span><br><span class="line">    <span class="comment"># cn_confirm[&quot;current&quot;][name] = province[&quot;currentConfirmedCount&quot;]</span></span><br><span class="line"><span class="comment"># print(&quot;累计确诊：&quot;, cn_confirm[&quot;count&quot;])</span></span><br><span class="line"><span class="comment"># print(&quot;现存确诊：&quot;, cn_confirm[&quot;current&quot;])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ------ 3. 绘制疫情分布饼图 ------</span></span><br><span class="line">createPieGraph(cn_confirm[<span class="string">&quot;count&quot;</span>], <span class="string">&quot;累计确诊&quot;</span>)</span><br><span class="line"><span class="comment"># createPieGraph(cn_confirm[&quot;current&quot;], &quot;现存确诊&quot;)</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/21d9b46741a54ec48802b3a5c53d679d.jpeg#pic_center" alt=""></p><hr><blockquote><h1>写在最后</h1><ul><li>如果您发现项目存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>这是本项目的链接：<a href="https://aistudio.baidu.com/aistudio/projectdetail/746534?shared=1">实验项目 - AI Studio</a>，点击<code>fork</code>可直接在AI Studio运行~</li><li>这是我的个人主页：<a href="https://aistudio.baidu.com/aistudio/personalcenter/thirdview/118633">个人主页 - AI Studio</a>，来AI Studio互粉吧，等你哦~</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 程序设计笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 数据可视化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用的内部排序算法</title>
      <link href="/2020/02/09/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%86%85%E9%83%A8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"/>
      <url>/2020/02/09/%E5%B8%B8%E7%94%A8%E7%9A%84%E5%86%85%E9%83%A8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<span id="more"></span><h1>1. 算法概述</h1><h2 id="1-1-基本概念">1.1. 基本概念</h2><p>（1）外部排序和内部排序</p><blockquote><ul><li><strong>内部排序</strong>：指在排序期间数据对象所有存放在内存的排序。<strong>（本文所讨论的都是内部排序算法）</strong></li><li><strong>外部排序</strong>：指在排序期间所有对象占用的空间太大，以致于不能在同一时间内存放在内存中，这些对象必须依据排序过程，不断在内、外存间移动已完成外部排序。</li></ul></blockquote><p>（2）排序算法的稳定性</p><blockquote><ul><li><strong>稳定</strong>：如果a原本在b前面，而a=b，排序之后a仍然在b的前面。</li><li><strong>不稳定</strong>：如果a原本在b的前面，而a=b，排序之后 a 可能会出现在 b 的后面。</li></ul></blockquote><p>（3）算法的时空复杂度</p><blockquote><ul><li><strong>时间复杂度</strong> 是指执行算法所需要的计算工作量。</li><li><strong>空间复杂度</strong> 是指执行这个算法所需要的内存空间。</li></ul></blockquote><h2 id="1-2-算法分类">1.2. 算法分类</h2><p>常见排序算法可以分为两大类：</p><blockquote><ul><li><strong>比较类排序</strong>：通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)因此也称为非线性时间比较类排序。</li><li><strong>非比较类排序</strong>：不通过比较元素间的相对次序，它可以突破基于比较排序的时间下界，以线性时间运行，因此也称为线性时间非比较类排序。</li></ul></blockquote><p><img src="https://img-blog.csdnimg.cn/20210209160011642.png#pic_center" alt=""></p><h2 id="1-3-算法复杂度">1.3. 算法复杂度</h2><p><img src="https://img-blog.csdnimg.cn/60096e47582d4605bf5e10fb66ecf35b.png#pic_center" alt=""></p><hr><h1>2. 交换排序</h1><h2 id="2-1-冒泡排序（Bubble-Sort）">2.1. 冒泡排序（Bubble Sort）</h2><p>冒泡排序是一种简单的排序算法，它的基本思想是：重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来；走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端（升序或降序排列），就如同碳酸饮料中二氧化碳的气泡最终会上浮到顶端一样，故名“冒泡排序”。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/e6fb675dc04f36ea888e4232f1ebe95d.gif" alt=""></p><p>（1）算法思路：</p><blockquote><p>① 比较相邻的元素。如果第一个比第二个大，就交换它们两个；<br>② 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；<br>③ 针对所有的元素重复以上的步骤，除了最后一个；<br>④ 重复步骤①②③，直到排序完成。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bubbleSort</span>(<span class="params">numList</span>):    <span class="comment"># 冒泡排序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(numList)-<span class="number">1</span>):</span><br><span class="line">        isSorted = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(numList)-i-<span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> numList[j]&gt;numList[j+<span class="number">1</span>]:</span><br><span class="line">                numList[j], numList[j+<span class="number">1</span>] = numList[j+<span class="number">1</span>], numList[j]</span><br><span class="line">                isSorted = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> isSorted==<span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">break</span>   <span class="comment"># 若一轮排序后仍不发生元素交换，则说明排序已完成</span></span><br><span class="line">    <span class="keyword">return</span> numList</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(<span class="number">0</span>, <span class="number">100</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;冒泡排序前：&quot;</span>, numList)</span><br><span class="line">    numList = bubbleSort(numList)   <span class="comment"># 冒泡排序</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;冒泡排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">冒泡排序前： [73, 21, 53, 76, 62, 35, 59, 21, 19, 43]</span><br><span class="line">冒泡排序后： [19, 21, 21, 35, 43, 53, 59, 62, 73, 76]</span><br></pre></td></tr></table></figure><h2 id="2-2-快速排序（Quick-Sort）">2.2. 快速排序（Quick Sort）</h2><p>快速排序由C. A. R. Hoare在1960年提出，是对冒泡排序算法的一种改进，它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。</p><p><img src="https://images2017.cnblogs.com/blog/849589/201710/849589-20171015230936371-1413523412.gif" alt=""></p><p>（1）算法思路：</p><blockquote><p>① 从数列中挑出一个元素，称为 “基准”；<br>② 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；<br>③ 递归地把小于基准值元素的子数列和大于基准值元素的子数列排序。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">partition</span>(<span class="params">numList, left, right</span>):</span><br><span class="line">    standard = numList[left]</span><br><span class="line">    <span class="keyword">while</span> left&lt;right :</span><br><span class="line">        <span class="keyword">while</span> left&lt;right <span class="keyword">and</span> standard&lt;=numList[right] :</span><br><span class="line">            right -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> left&lt;right <span class="keyword">and</span> standard&gt;numList[right] :</span><br><span class="line">            numList[left] = numList[right]</span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left&lt;right <span class="keyword">and</span> standard&gt;=numList[left] :</span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> left&lt;right <span class="keyword">and</span> standard&lt;numList[left] :</span><br><span class="line">            numList[right] = numList[left]</span><br><span class="line">            right -= <span class="number">1</span></span><br><span class="line">    numList[left] = standard</span><br><span class="line">    <span class="keyword">return</span> left</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">quickSort</span>(<span class="params">numList, left, right</span>):    <span class="comment"># 快速排序</span></span><br><span class="line">    <span class="keyword">if</span> left&lt;right :</span><br><span class="line">        mid = partition(numList, left, right)</span><br><span class="line">        numList = quickSort(numList, left, mid-<span class="number">1</span>)</span><br><span class="line">        numList = quickSort(numList, mid+<span class="number">1</span>, right)</span><br><span class="line">    <span class="keyword">return</span> numList</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(<span class="number">0</span>, <span class="number">100</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;快速排序前：&quot;</span>, numList)</span><br><span class="line">    numList = quickSort(numList, <span class="number">0</span>, <span class="built_in">len</span>(numList)-<span class="number">1</span>)     <span class="comment"># 快速排序</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;快速排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">快速排序前： [87, 57, 15, 93, 88, 100, 13, 18, 7, 67]</span><br><span class="line">快速排序后： [7, 13, 15, 18, 57, 67, 87, 88, 93, 100]</span><br></pre></td></tr></table></figure><hr><h1>3. 选择排序</h1><h2 id="3-1-直接选择排序（Straight-Selection-Sort）">3.1. 直接选择排序（Straight Selection Sort）</h2><p>直接 (简单) 选择排序是一个简单直观的选择排序算法，它的基本思想是：在待排记录中依次选择关键字最小的记录作为有序序列的最后一条记录，逐渐缩小范围，直至全部记录选择完毕。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/c0f5d93f066a022eda9540fa7d53bacf.gif" alt=""></p><p>（1）算法思路：</p><blockquote><p>① 设array一个需要排序的数组，最初时的未排序序列unsortedArray为整个数组array。<br>② 首先从前向后扫描整个未排序序列，在未排序序列中找到最小元素，与该序列的首元素进行交换。每次遍历后，未排序序列中的最小元素将被移动到已排序序列末尾，并且已确定位置的数据不需要再参与排序，这样一来就缩小了未排序序列unsortedArray。<br>③ 重复步骤②，直到所有元素均排序完毕。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">selectSort</span>(<span class="params">numList</span>):    <span class="comment"># 简单选择排序</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(numList)-<span class="number">1</span>):</span><br><span class="line">        index = i   <span class="comment"># 指向待排序序列中最小元素的下标</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, <span class="built_in">len</span>(numList)):</span><br><span class="line">            <span class="keyword">if</span> numList[index]&gt;numList[j]:</span><br><span class="line">                index = j</span><br><span class="line">        numList[index], numList[i] = numList[i], numList[index]      </span><br><span class="line">    <span class="keyword">return</span> numList</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(<span class="number">0</span>, <span class="number">100</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;简单选择排序前：&quot;</span>, numList)</span><br><span class="line">    numList = selectSort(numList)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;简单选择排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">简单选择排序前： [52, 2, 25, 77, 80, 52, 51, 67, 72, 0]</span><br><span class="line">简单选择排序后： [0, 2, 25, 51, 52, 52, 67, 72, 77, 80]</span><br></pre></td></tr></table></figure><h2 id="3-2-堆排序（Heap-Sort）">3.2. 堆排序（Heap Sort）</h2><p>堆排序是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。</p><p><img src="https://upload-images.jianshu.io/upload_images/1940317-64e671a84ec27769.gif?imageMogr2/auto-orient/strip" alt=""></p><p>（1）算法思路：</p><blockquote><p>① 将初始待排序关键字序列(R1,R2….Rn)构建成大顶堆，此堆为初始的无序区；<br>② 将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,……Rn-1)和新的有序区(Rn),且满足R[1,2…n-1]&lt;=R[n]；<br>③ 由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,……Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2….Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">maxHeapify</span>(<span class="params">heap, start, end</span>):</span><br><span class="line">    parent, son = start, start*<span class="number">2</span> + <span class="number">1</span>    <span class="comment"># 设置初始值</span></span><br><span class="line">    <span class="keyword">while</span> son&lt;=end :</span><br><span class="line">        <span class="keyword">if</span> son&lt;end <span class="keyword">and</span> heap[son]&lt;heap[son+<span class="number">1</span>] :</span><br><span class="line">            son += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> heap[son]&lt;=heap[parent] :</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        heap[parent], heap[son] = heap[son], heap[parent]</span><br><span class="line">        parent, son = son, <span class="number">2</span>*son + <span class="number">1</span>    <span class="comment"># 更新数据值</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">heapSort</span>(<span class="params">heap</span>):     <span class="comment"># 堆排序</span></span><br><span class="line">    size = <span class="built_in">len</span>(heap)</span><br><span class="line">    <span class="keyword">for</span> start <span class="keyword">in</span> <span class="built_in">range</span>(size//<span class="number">2</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">        maxHeapify(heap, start-<span class="number">1</span>, size-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> end <span class="keyword">in</span> <span class="built_in">range</span>(size-<span class="number">1</span>, <span class="number">0</span>, -<span class="number">1</span>):</span><br><span class="line">        heap[<span class="number">0</span>], heap[end] = heap[end], heap[<span class="number">0</span>]</span><br><span class="line">        maxHeapify(heap, <span class="number">0</span>, end-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> heap</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(<span class="number">0</span>, <span class="number">100</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;堆排序前：&quot;</span>, numList)</span><br><span class="line">    numList = heapSort(numList)   <span class="comment"># 堆排序</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;堆排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">堆排序前： [52, 50, 6, 80, 1, 88, 28, 81, 25, 51]</span><br><span class="line">堆排序后： [1, 6, 25, 28, 50, 51, 52, 80, 81, 88]</span><br></pre></td></tr></table></figure><hr><h1>4. 插入排序</h1><h2 id="4-1-直接插入排序（Straight-Insertion-Sort）">4.1. 直接插入排序（Straight Insertion Sort）</h2><p>直接插入排序是一种最简单的排序方法，其基本操作是将一条记录插入到已排好的有序表中，从而得到一个新的有序表。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/ffcc308c919e3578ab93db466118a294.gif" alt=""></p><p>（1）算法思路：</p><blockquote><p>① 从第一个元素开始，该元素可以认为已经被排序；<br>② 取出下一个元素，在已经排序的元素序列中从后向前扫描；<br>③ 如果该已排序元素大于新元素，将该元素移到下一位置；<br>④ 重复步骤③，直到找到已排序的元素小于或者等于新元素的位置；<br>⑤ 将新元素插入到该位置后；<br>⑥ 重复步骤②~⑤，直到排序完成。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">insertSort</span>(<span class="params">numList</span>):    <span class="comment"># 直接插入排序</span></span><br><span class="line">    <span class="keyword">for</span> no <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(numList)):</span><br><span class="line">        index = no - <span class="number">1</span>      <span class="comment"># 指向当前插入点</span></span><br><span class="line">        num = numList[no]   <span class="comment"># 当前待插入的元素</span></span><br><span class="line">        <span class="keyword">while</span> index&gt;=<span class="number">0</span> <span class="keyword">and</span> numList[index]&gt;num :</span><br><span class="line">            numList[index+<span class="number">1</span>] = numList[index]</span><br><span class="line">            index -= <span class="number">1</span></span><br><span class="line">        numList[index+<span class="number">1</span>] = num</span><br><span class="line">    <span class="keyword">return</span> numList</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(<span class="number">0</span>, <span class="number">100</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;直接插入排序前：&quot;</span>, numList)</span><br><span class="line">    numList = insertSort(numList)   <span class="comment"># 直接插入排序</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;直接插入排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">直接插入排序前： [57, 65, 35, 11, 39, 10, 13, 10, 67, 72]</span><br><span class="line">直接插入排序后： [10, 10, 11, 13, 35, 39, 57, 65, 67, 72]</span><br></pre></td></tr></table></figure><h2 id="4-2-折半插入排序（Binary-Insertion-Sort）">4.2. 折半插入排序（Binary Insertion Sort）</h2><p>折半插入排序是对直接插入排序算法的一种改进，由于排序过程就是不断的依次将元素插入前面已排好序的序列中，并且数列的前半部分为已排好序的数列，这样我们不用按顺序依次寻找插入点，可以采用折半查找的方法来加快寻找插入点的速度。</p><p>（1）算法思路：</p><blockquote><p>① 设现有一个数组a需要排序，从第一个元素开始，该元素可以认为已经被排序；<br>② 将待插入区域的首元素下标为 left，末元素下标记为 right，mid = (left+right)/2；取出下一个元素next，比较 next 和 a[mid] 的大小；<br>③ 如果 next 大于 a[mid]，选择 a[mid+1] 到 a[right] 为新的插入区域（即令 left = mid+1 ）；否则选择a[left]到a[m-1]为新的插入区域(即令 right = mid-1 )；<br>④ 重复步骤③，直至 left &gt; right 为止，接着将 right 位置之后所有元素向后移一位，并将新元素next插入 a[high+1]；<br>⑤ 重复步骤②③④，直到排序完成。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">insertSort</span>(<span class="params">numList</span>):    <span class="comment"># 折半插入排序</span></span><br><span class="line">    <span class="keyword">for</span> no <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(numList)):</span><br><span class="line">        num = numList[no]   <span class="comment"># 当前待插入的元素</span></span><br><span class="line">        <span class="comment"># left、right代表已排序的序列的首、尾元素下标</span></span><br><span class="line">        left, right = <span class="number">0</span>, no-<span class="number">1</span></span><br><span class="line">        <span class="comment"># 找到插入点的下标</span></span><br><span class="line">        <span class="keyword">while</span> left&lt;=right:</span><br><span class="line">            mid = (left + right) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">if</span> numList[mid]&gt;num :</span><br><span class="line">                right = mid - <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left = mid + <span class="number">1</span></span><br><span class="line">        <span class="comment"># 插入数据</span></span><br><span class="line">        index = no - <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> index&gt;=left:</span><br><span class="line">            numList[index+<span class="number">1</span>] = numList[index]</span><br><span class="line">            index -= <span class="number">1</span></span><br><span class="line">        numList[index+<span class="number">1</span>] = num</span><br><span class="line">    <span class="keyword">return</span> numList</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(<span class="number">0</span>, <span class="number">100</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;折半插入排序前：&quot;</span>, numList)</span><br><span class="line">    numList = insertSort(numList)   <span class="comment"># 折半插入排序</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;折半插入排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">折半插入排序前： [59, 15, 29, 0, 89, 45, 25, 26, 51, 86]</span><br><span class="line">折半插入排序后： [0, 15, 25, 26, 29, 45, 51, 59, 86, 89]</span><br></pre></td></tr></table></figure><h2 id="4-3-希尔排序（Shell-Sort）">4.3. 希尔排序（Shell Sort）</h2><p>希尔排序，又称“缩小增量排序”（Diminishing Increment Sort），是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法，该方法因 D.L.Shell 于 1959 年提出而得名。希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至 1 时，整个文件恰被分成一组，算法便终止。</p><p><img src="https://img-blog.csdnimg.cn/c343f976d4184275b1fc106444bfe63e.gif" alt=""></p><p>（1）算法思路：</p><blockquote><p>设现有一个待排序数组，span（初值为数组长度的一半）为增量值：<br>① 根据增量值span把整个数组划分为span个子序列（其中，每个子数组相邻俩元素的下标相差span，然后对各个子序列进行直接插入排序，接着将span缩小为原来的一半。<br>② 重复步骤①，直到span小于1。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">shellSort</span>(<span class="params">numList</span>):     <span class="comment"># 希尔排序</span></span><br><span class="line">    span = <span class="built_in">len</span>(numList)//<span class="number">2</span>  <span class="comment"># 跨度值</span></span><br><span class="line">    <span class="keyword">while</span> span&gt;=<span class="number">1</span> :</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(span, <span class="built_in">len</span>(numList)):</span><br><span class="line">            temp = numList[i]   <span class="comment"># 当前待排序的元素</span></span><br><span class="line">            index = i - span    <span class="comment"># 已排序序列尾元素的下标</span></span><br><span class="line">            <span class="keyword">while</span> index&gt;=<span class="number">0</span> <span class="keyword">and</span> numList[index]&gt;temp :</span><br><span class="line">                numList[index + span] = numList[index]</span><br><span class="line">                index -= span</span><br><span class="line">            numList[index + span] = temp</span><br><span class="line">        span //= <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> numList</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(<span class="number">0</span>, <span class="number">100</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;希尔排序前：&quot;</span>, numList)</span><br><span class="line">    numList = shellSort(numList)    <span class="comment"># 希尔排序</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;希尔排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">希尔排序前： [25, 64, 87, 3, 20, 92, 96, 6, 35, 51]</span><br><span class="line">希尔排序后： [3, 6, 20, 25, 35, 51, 64, 87, 92, 96]</span><br></pre></td></tr></table></figure><hr><h1>5. 归并排序</h1><h2 id="5-1-二路归并排序（Binary-Merge-Sort）">5.1. 二路归并排序（Binary Merge Sort）</h2><p>归并排序是建立在归并操作上的一种有效的排序算法，它是采用分治法的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为二路归并。</p><p><img src="https://images2017.cnblogs.com/blog/849589/201710/849589-20171015230557043-37375010.gif" alt=""></p><p>（1）算法思路：</p><blockquote><p>① 设现有一个待排序数组，将数组均分成左部子数组left和右部子数组right。如果子数组内部数据是无序的，则对子数组递归进行二分，直至分解出的小组只有一个元素，此时认为该小组内部有序。<br>② 合并两个有序子数组，比较两个子数组的最前面的数，谁小就先取谁，该数组的指针往后移一位。<br>③ 重复步骤②，直至一个数组为空，然后把另一个数组的剩余部分复制过来即可。<br>④ 重复步骤②③，直至所有子数组归并成一个数组。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Merge</span>(<span class="params">left, right</span>):    <span class="comment"># 归并序列</span></span><br><span class="line">    result = []</span><br><span class="line">    i, j = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i&lt;<span class="built_in">len</span>(left) <span class="keyword">and</span> j&lt;<span class="built_in">len</span>(right) :</span><br><span class="line">        <span class="keyword">if</span> left[i]&lt;right[j] :</span><br><span class="line">            result.append(left[i])</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result.append(right[j])</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> i&lt;<span class="built_in">len</span>(left):</span><br><span class="line">        result.extend(left[i : ])</span><br><span class="line">    <span class="keyword">if</span> j&lt;<span class="built_in">len</span>(right):</span><br><span class="line">        result.extend(right[j : ])</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mergeSort</span>(<span class="params">numList</span>):   <span class="comment"># 二路归并排序</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(numList)&lt;=<span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> numList</span><br><span class="line">    size = (<span class="built_in">len</span>(numList)) // <span class="number">2</span></span><br><span class="line">    left = mergeSort(numList[:size])</span><br><span class="line">    right = mergeSort(numList[size:])</span><br><span class="line">    result = Merge(left, right)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(<span class="number">0</span>, <span class="number">100</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;二路归并排序前：&quot;</span>, numList)</span><br><span class="line">    numList = mergeSort(numList)       <span class="comment"># 二路归并排序</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;二路归并排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">二路归并排序前： [46, 77, 12, 91, 78, 6, 100, 86, 60, 2]</span><br><span class="line">二路归并排序后： [2, 6, 12, 46, 60, 77, 78, 86, 91, 100]</span><br></pre></td></tr></table></figure><hr><h1>6. 非比较类排序</h1><h2 id="6-1-基数排序（Radix-Sort）">6.1. 基数排序（Radix Sort）</h2><p>基数排序属于“分配式排序”（distribution sort），又称“桶子法”（bucket sort 或 bin sort），顾名思义，它是透过键值的部份资讯，将要排序的元素分配至某些“桶”中，藉以达到排序的作用，基数排序法是属于稳定性的排序，其时间复杂度为O (nlog®m)，其中r为所采取的基数，而m为堆数，在某些时候，基数排序法的效率高于其它的稳定性排序法。</p><p><img src="https://upload-images.jianshu.io/upload_images/1940317-28a71f3fdbd60b9e.gif?imageMogr2/auto-orient/strip" alt=""></p><p>（1）算法思路：</p><blockquote><p>① 将所有待比较的整数统一为同样的数位长度，数位较短的数前面补零；<br>② 从最低位开始，依次进行一次排序；<br>③ 从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">radixSort</span>(<span class="params">numList</span>):     <span class="comment"># 基数排序</span></span><br><span class="line">    <span class="comment"># (1) 找出最大值并求出其位数：</span></span><br><span class="line">    max_digit, maxium = <span class="number">1</span>, <span class="built_in">max</span>(numList)</span><br><span class="line">    <span class="keyword">while</span> maxium &gt;= <span class="number">10</span>**max_digit:</span><br><span class="line">        max_digit += <span class="number">1</span></span><br><span class="line">    <span class="comment"># (2) 从个位开始，每研究一个数位就进行一次排序：</span></span><br><span class="line">    digit = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> digit &lt; max_digit:</span><br><span class="line">        cur, temp = <span class="number">0</span>, <span class="number">10</span>**digit</span><br><span class="line">        table = [[] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">19</span>)]     <span class="comment"># 记录某位出现-9~9的整数</span></span><br><span class="line">        <span class="comment"># (2-1) 根据整数某位的取值对号入座：</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> numList:</span><br><span class="line">            <span class="comment"># （因为余数始终为正数，这里需讨论正负性）</span></span><br><span class="line">            <span class="keyword">if</span> num &gt;= <span class="number">0</span>:</span><br><span class="line">                index = num // temp % <span class="number">10</span> + <span class="number">9</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                index = <span class="number">9</span> - (-num) // temp % <span class="number">10</span></span><br><span class="line">            table[index].append(num)</span><br><span class="line">        <span class="comment"># (2-2) 重新写回原数组，完成一次排序：</span></span><br><span class="line">        <span class="keyword">for</span> lt <span class="keyword">in</span> table:</span><br><span class="line">            <span class="keyword">for</span> num <span class="keyword">in</span> lt:</span><br><span class="line">                numList[cur] = num</span><br><span class="line">                cur += <span class="number">1</span></span><br><span class="line">        digit += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> numList</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(-<span class="number">200</span>, <span class="number">200</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;基数排序前：&quot;</span>, numList)</span><br><span class="line">    numList = radixSort(numList)       <span class="comment"># 基数排序</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;基数排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">基数排序前： [-46, 45, 32, -92, 18, 52, -31, -9, -50, -132]</span><br><span class="line">基数排序后： [-92, -50, -46, -132, -31, -9, 18, 32, 45, 52]</span><br></pre></td></tr></table></figure><h2 id="6-2-计数排序（Counting-Sort）">6.2. 计数排序（Counting Sort）</h2><p>计数排序是一个非基于比较的排序算法，该算法于1954年由 Harold H. Seward 提出。它的优势在于在对一定范围内的整数排序时，它的时间复杂度（Ο(n+k)，其中k是待排序整数的范围）是低于任何比较排序算法。 当然这是一种牺牲空间换取时间的做法，而且当O(k) &gt; O(n*log(n))的时候其效率反而不如基于比较的排序。</p><p><img src="https://images2017.cnblogs.com/blog/849589/201710/849589-20171015231740840-6968181.gif" alt=""></p><p>（1）算法思路：</p><blockquote><p>① 找出待排序的数组中最大和最小的元素；<br>② 统计数组中介于最值之间的每个值的元素出现的次数；<br>③ 依据统计的出现次数将数值反向填充目标数组。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">countingSort</span>(<span class="params">numList</span>):</span><br><span class="line">    <span class="comment"># (1) 找出数组numList中的最值：</span></span><br><span class="line">    maxium, minium = <span class="built_in">max</span>(numList), <span class="built_in">min</span>(numList)</span><br><span class="line">    <span class="comment"># (2) 建立一个列表统计最值间每个整数出现的次数：</span></span><br><span class="line">    tabLen = maxium - minium + <span class="number">1</span></span><br><span class="line">    table = [<span class="number">0</span>] * tabLen</span><br><span class="line">    <span class="comment"># (3) 统计最值间每个整数出现的次数：</span></span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> numList:</span><br><span class="line">        index = num - minium    <span class="comment"># 找出num对应的容器下标</span></span><br><span class="line">        table[index] += <span class="number">1</span>       <span class="comment"># num出现的次数加 1</span></span><br><span class="line">    <span class="comment"># (4) 反向填充目标数组：</span></span><br><span class="line">    cur = <span class="number">0</span>                 <span class="comment"># 当前应填充的数组元素下标</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(tabLen):</span><br><span class="line">        <span class="keyword">while</span> table[idx] &gt; <span class="number">0</span>:</span><br><span class="line">            numList[cur] = idx + minium</span><br><span class="line">            cur += <span class="number">1</span></span><br><span class="line">            table[idx] -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> numList</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(-<span class="number">200</span>, <span class="number">200</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;计数排序前：&quot;</span>, numList)</span><br><span class="line">    numList = countingSort(numList)       <span class="comment"># 计数排序</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;计数排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">计数排序前： [-32, 71, -86, 61, -123, 7, -138, -188, 49, 150]</span><br><span class="line">计数排序后： [-188, -138, -123, -86, -32, 7, 49, 61, 71, 150]</span><br></pre></td></tr></table></figure><h2 id="6-3-桶排序（Bucket-Sort）">6.3. 桶排序（Bucket Sort）</h2><p>桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排）。</p><p><img src="https://upload-images.jianshu.io/upload_images/1940317-3d1c77fe4c71ce1a.gif?imageMogr2/auto-orient/strip" alt=""></p><p>（1）算法思路：</p><blockquote><p>① 设置固定数量的空桶；<br>② 把数据放到对应的桶中；<br>③ 对每个不为空的桶中数据进行排序；<br>④ 拼接不为空的桶中数据，得到结果。</p></blockquote><p>（2）算法实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> randint</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">insertionSort</span>(<span class="params">array</span>):   <span class="comment"># 直接插入排序</span></span><br><span class="line">    <span class="keyword">for</span> no <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(array)):</span><br><span class="line">        cur = no - <span class="number">1</span>        <span class="comment"># 指向当前插入点</span></span><br><span class="line">        num = array[no]     <span class="comment"># 当前待插入的元素</span></span><br><span class="line">        <span class="keyword">while</span> cur &gt;= <span class="number">0</span> <span class="keyword">and</span> array[cur] &gt; num:</span><br><span class="line">            array[cur+<span class="number">1</span>] = array[cur]</span><br><span class="line">            cur -= <span class="number">1</span></span><br><span class="line">        array[cur+<span class="number">1</span>] = num</span><br><span class="line">    <span class="keyword">return</span> array</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bucketSort</span>(<span class="params">numList</span>):</span><br><span class="line">    <span class="comment"># (1) 设置桶的数量（默认为5）：</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(numList) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    bucketNum = <span class="number">5</span> <span class="keyword">if</span> <span class="built_in">len</span>(numList) &gt; <span class="number">5</span> <span class="keyword">else</span> <span class="built_in">len</span>(numList)</span><br><span class="line">    bucketList = [[] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bucketNum)]</span><br><span class="line">    <span class="comment"># (2) 找出数组numList中的最值，设置好桶内间隔：</span></span><br><span class="line">    maxium, minium = <span class="built_in">max</span>(numList), <span class="built_in">min</span>(numList)</span><br><span class="line">    gap = (maxium - minium)//bucketNum + <span class="number">1</span>  <span class="comment"># 桶内数字的间隔</span></span><br><span class="line">    <span class="comment"># (3) 将数字装入桶中：</span></span><br><span class="line">    <span class="keyword">for</span> num <span class="keyword">in</span> numList:</span><br><span class="line">        index = (num - minium)//gap   <span class="comment"># 获取num所属桶的编号</span></span><br><span class="line">        bucketList[index].append(num)</span><br><span class="line">    <span class="comment"># (4) 为每个桶里面的数字进行排序：</span></span><br><span class="line">    cur = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> bucket <span class="keyword">in</span> bucketList:</span><br><span class="line">        bucket = insertionSort(bucket)  <span class="comment"># 插入排序</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> bucket:</span><br><span class="line">            numList[cur] = num</span><br><span class="line">            cur += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> numList</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    numList = [randint(-<span class="number">100</span>, <span class="number">100</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>)]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;桶排序前：&quot;</span>, numList)</span><br><span class="line">    numList = bucketSort(numList)   <span class="comment"># 桶排序</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;桶排序后：&quot;</span>, numList)</span><br></pre></td></tr></table></figure><p>实验结果：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">桶排序前： [54, 62, 82, 96, -61, -82, -15, -55, 35, -49]</span><br><span class="line">桶排序后： [-82, -61, -55, -49, -15, 35, 54, 62, 82, 96]</span><br></pre></td></tr></table></figure><hr><h1>写在最后</h1><blockquote><ul><li>如果您发现文章存在问题，或者如果您有更好的建议，欢迎在下方评论区中留言讨论~</li><li>本文参考文章：<a href="https://www.cnblogs.com/fivestudy/p/10064969.html">十大经典排序算法动画，看我就够了！</a></li><li>推荐一个算法可视化网站：<a href="http://www.cs.usfca.edu/~galles/visualization/Algorithms.html">旧金山大学算法可视化平台</a></li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> 程序设计笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 算法分析 </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
